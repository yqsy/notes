---
title: 高性能mysql
date: 2017-12-3 15:52:21
categories: [读书笔记]
---

<!-- TOC -->

- [1. p5-锁粒度](#1-p5-锁粒度)
    - [1.1. 表锁（table lock)](#11-表锁table-lock)
    - [1.2. 行级锁（row lock)](#12-行级锁row-lock)
- [2. p6-ACID](#2-p6-acid)
    - [2.1. 原子性（atomicity)](#21-原子性atomicity)
    - [2.2. 一致性(consistency)](#22-一致性consistency)
    - [2.3. 隔离性(iso lation)](#23-隔离性iso-lation)
    - [2.4. 持久性(durability)](#24-持久性durability)
- [3. p7-是否需要事务处理](#3-p7-是否需要事务处理)
- [4. p8-隔离级别](#4-p8-隔离级别)
    - [4.1. READ UNCOmiTTED (未提交读）](#41-read-uncomitted-未提交读)
    - [4.2. READ COMMITTBD (提交读）](#42-read-committbd-提交读)
    - [4.3. REPEATABLE READ (可重复读）](#43-repeatable-read-可重复读)
    - [4.4. SERIALIZABLE (可串行化)](#44-serializable-可串行化)
- [5. p9-死锁](#5-p9-死锁)
- [6. p10-事务曰志](#6-p10-事务曰志)
- [7. p10-MySQL 中的事务](#7-p10-mysql-中的事务)
- [8. p12-多版本并发控制(MVCC)](#8-p12-多版本并发控制mvcc)
- [9. p13-MySQL的存储引擎](#9-p13-mysql的存储引擎)
    - [9.1. InnoDB 存储引擎](#91-innodb-存储引擎)
    - [9.2. MylSAM存储引擎](#92-mylsam存储引擎)
    - [9.3. Archive 引擎](#93-archive-引擎)
    - [9.4. Blackhole 引擎](#94-blackhole-引擎)
    - [9.5. CSV 引擎](#95-csv-引擎)
    - [9.6. Federated 引擎](#96-federated-引擎)
    - [9.7. Memory 引擎](#97-memory-引擎)
    - [9.8. Merge 引擎](#98-merge-引擎)
    - [9.9. NDB 集群引擎](#99-ndb-集群引擎)
    - [9.10. 其他引擎](#910-其他引擎)
- [10. p24-选择合适的引擎](#10-p24-选择合适的引擎)
- [11. p35-基准测试（benchmark)](#11-p35-基准测试benchmark)
- [12. p38-测试何种指标](#12-p38-测试何种指标)
    - [12.1. 吞吐量](#121-吞吐量)
    - [12.2. 响应时间或者延迟](#122-响应时间或者延迟)
    - [12.3. 并发性](#123-并发性)
    - [12.4. 可扩展性](#124-可扩展性)
- [13. p49-集成式测试工具](#13-p49-集成式测试工具)
- [14. p50-单组件式测试工具](#14-p50-单组件式测试工具)
- [15. p67-cpu利用率上升不意味性能下降](#15-p67-cpu利用率上升不意味性能下降)
- [16. p67-把时间花在测量问题上](#16-p67-把时间花在测量问题上)
- [17. p71-理解性能剖析](#17-p71-理解性能剖析)
    - [17.1. 值得优化的查询（worthwhile query)](#171-值得优化的查询worthwhile-query)
    - [17.2. 被掩藏的细节](#172-被掩藏的细节)
- [18. p78-分析查询日志](#18-p78-分析查询日志)
- [19. p81-剖析单条查询](#19-p81-剖析单条查询)
    - [19.1. 使用SHOW PROFILE](#191-使用show-profile)
    - [19.2. 使用SHOW STATUS](#192-使用show-status)
    - [19.3. 使用慢查询曰志](#193-使用慢查询曰志)
    - [19.4. Performance Schema](#194-performance-schema)
- [20. p88-诊断间歇性问题](#20-p88-诊断间歇性问题)
- [21. p89-单条查询问题还是服务器问题](#21-p89-单条查询问题还是服务器问题)
    - [21.1. SHOW GLOBAL STATUS](#211-show-global-status)
    - [21.2. SHOW PROCESSLIST](#212-show-processlist)
    - [21.3. 使用查询曰志](#213-使用查询曰志)
- [22. p92-理解发现的问题](#22-p92-理解发现的问题)
- [23. p111-选择优化的数据类型](#23-p111-选择优化的数据类型)
    - [23.1. 更小的通常更好](#231-更小的通常更好)
    - [23.2. 简单就好](#232-简单就好)
    - [23.3. 尽量避免NULL](#233-尽量避免null)
- [24. p114-DECIMAL使用场景](#24-p114-decimal使用场景)
- [25. p117-VARCHAR和CHAR](#25-p117-varchar和char)
- [26. p122-TIMESTAMP](#26-p122-timestamp)
- [27. p126-避免使用字符串类型作为标识列](#27-p126-避免使用字符串类型作为标识列)
- [28. p126-ORM的性能问题](#28-p126-orm的性能问题)
- [29. p127-ip地址使用整数存储](#29-p127-ip地址使用整数存储)
- [30. p129-范式和反范式](#30-p129-范式和反范式)
    - [30.1. 范式的优缺点](#301-范式的优缺点)
    - [30.2. 反范式的优点和缺点](#302-反范式的优点和缺点)
    - [30.3. 混用范式化和反范式化](#303-混用范式化和反范式化)
    - [30.4. 缓存表和汇总表](#304-缓存表和汇总表)
- [31. p136-更快地读,更慢的写](#31-p136-更快地读更慢的写)
- [32. p140-Schema与数据类型优化总结](#32-p140-schema与数据类型优化总结)
- [33. p141-创建高性能的索引](#33-p141-创建高性能的索引)
    - [33.1. 如果使用的是ORM, 是否还需要关心索引？](#331-如果使用的是orm-是否还需要关心索引)
    - [33.2. 索引的类型](#332-索引的类型)
    - [33.3. 索引查询方式](#333-索引查询方式)
    - [33.4. 索引限制](#334-索引限制)
    - [33.5. 哈希索引](#335-哈希索引)
    - [33.6. 创建自定义哈希索引](#336-创建自定义哈希索引)
    - [33.7. 空间数据索引(R-Tree)](#337-空间数据索引r-tree)
    - [33.8. 全文索引](#338-全文索引)
- [34. p152-索引的优点](#34-p152-索引的优点)
- [35. p152-索引并不是最好的解决方案](#35-p152-索引并不是最好的解决方案)
- [36. p153-高性能的索引策略](#36-p153-高性能的索引策略)
    - [36.1. 独立的列](#361-独立的列)
    - [36.2. 前缀索引](#362-前缀索引)
    - [36.3. 多列索引](#363-多列索引)
    - [36.4. 选择合适的索引列顺序](#364-选择合适的索引列顺序)
    - [36.5. 聚簇索引](#365-聚簇索引)
    - [36.6. 覆盖索引](#366-覆盖索引)
    - [36.7. 未来的改进(5.6版本索引条件推送)](#367-未来的改进56版本索引条件推送)
    - [36.8. 使用索引扫描来做排序](#368-使用索引扫描来做排序)
    - [36.9. 压缩（前缀压缩）索引](#369-压缩前缀压缩索引)
    - [36.10. 冗余和重复索引](#3610-冗余和重复索引)
- [37. p192-选择索引时记住三个原则](#37-p192-选择索引时记住三个原则)
- [38. p198-简单的衡量查询开销的三个指标](#38-p198-简单的衡量查询开销的三个指标)
- [39. p204-mysql请求应答的流程](#39-p204-mysql请求应答的流程)
- [40. p207-查询状态](#40-p207-查询状态)
- [41. p259-分区表](#41-p259-分区表)
- [42. p270-视图](#42-p270-视图)
- [43. p275-外键约束](#43-p275-外键约束)
- [44. p276-在MySQL内部存储代码](#44-p276-在mysql内部存储代码)
- [45. p283-游标](#45-p283-游标)
- [46. p284-绑定变量](#46-p284-绑定变量)
- [47. p309-查询缓存](#47-p309-查询缓存)
- [48. p321-特性总结](#48-p321-特性总结)
    - [48.1. 分区表](#481-分区表)
    - [48.2. 视图](#482-视图)
    - [48.3. 外键](#483-外键)
    - [48.4. 存储过程](#484-存储过程)
    - [48.5. 绑定变量](#485-绑定变量)
    - [48.6. 插件](#486-插件)
    - [48.7. 字符集](#487-字符集)
    - [48.8. 全文索引](#488-全文索引)
    - [48.9. XA 事务](#489-xa-事务)
    - [48.10. 查询缓存](#4810-查询缓存)
- [49. p331-MySQL配置入门](#49-p331-mysql配置入门)
- [50. p349-配置MySQL 的I/O 行为](#50-p349-配置mysql-的io-行为)
- [51. p350-InnoDB事务日志](#51-p350-innodb事务日志)
- [52. p367-InnoDB表空间](#52-p367-innodb表空间)
- [53. p369-基本配置](#53-p369-基本配置)
- [54. p371-安全和稳定的设置](#54-p371-安全和稳定的设置)
- [55. p383-随机I/O和顺序I/O](#55-p383-随机io和顺序io)
- [56. p385-预写日志](#56-p385-预写日志)
- [57. p386-缓存命中率](#57-p386-缓存命中率)
- [58. p389-固态存储的好处](#58-p389-固态存储的好处)
- [59. p394-用SSD 做RAID](#59-p394-用ssd-做raid)
- [60. p405-RAID等级之间的比较](#60-p405-raid等级之间的比较)
- [61. p414-mysql创建的多种类型的文件](#61-p414-mysql创建的多种类型的文件)
- [62. p418-修改配置提高tcp的吞吐量](#62-p418-修改配置提高tcp的吞吐量)
- [63. p421-常见文件系统对比](#63-p421-常见文件系统对比)
- [64. p428-操作系统性能诊断工具](#64-p428-操作系统性能诊断工具)
- [65. p431-操作系统以及硬件优化总结](#65-p431-操作系统以及硬件优化总结)
- [66. p433-mysql复制概述](#66-p433-mysql复制概述)
- [67. p434-复制解决的问题](#67-p434-复制解决的问题)
- [68. p442-服务器克隆备份的方法](#68-p442-服务器克隆备份的方法)
- [69. p445-基于语句的复制的优缺点](#69-p445-基于语句的复制的优缺点)
- [70. p446-基于行的复制的优缺点](#70-p446-基于行的复制的优缺点)
- [71. p446-哪种方式更优?](#71-p446-哪种方式更优)
- [72. p452-一主库多备库](#72-p452-一主库多备库)
- [73. p469-测量备库延迟](#73-p469-测量备库延迟)
- [74. p469-确定主备一致(日常工作)](#74-p469-确定主备一致日常工作)
- [75. p496-其他复制技术](#75-p496-其他复制技术)
- [76. p501-什么是可扩展性](#76-p501-什么是可扩展性)
- [77. p509-向上扩展](#77-p509-向上扩展)
- [78. p501-向外扩展](#78-p501-向外扩展)
    - [78.1. 按功能拆分](#781-按功能拆分)
    - [78.2. 数据分片](#782-数据分片)
    - [78.3. 选择分区键(partitioning key)](#783-选择分区键partitioning-key)
    - [78.4. 多个分区键](#784-多个分区键)
    - [78.5. 跨分片查询](#785-跨分片查询)
    - [78.6. 分配数据、分片和节点](#786-分配数据分片和节点)
    - [78.7. 在节点上部署分片](#787-在节点上部署分片)
    - [78.8. 固定分配](#788-固定分配)
    - [78.9. 动态分配](#789-动态分配)
    - [78.10. 混合动态分配和固定分配](#7810-混合动态分配和固定分配)
    - [78.11. 显式分配](#7811-显式分配)
    - [78.12. 重新均衡分片数据](#7812-重新均衡分片数据)
    - [78.13. 生成全局唯一ID](#7813-生成全局唯一id)
    - [78.14. 分片工具](#7814-分片工具)
- [79. p525-通过多实例扩展](#79-p525-通过多实例扩展)
- [80. p549-通过集群扩展](#80-p549-通过集群扩展)
    - [80.1. NDB Cluster](#801-ndb-cluster)
    - [80.2. Clustrix](#802-clustrix)
    - [80.3. ScaleBase](#803-scalebase)
    - [80.4. GenieDB](#804-geniedb)
    - [80.5. Akiban](#805-akiban)
- [81. p530-内向扩展](#81-p530-内向扩展)
    - [81.1. 保持活跃数据独立](#811-保持活跃数据独立)
- [82. p532-负载均衡](#82-p532-负载均衡)
- [83. p538-负载均衡器](#83-p538-负载均衡器)
- [84. p538-负载均衡算法](#84-p538-负载均衡算法)
- [85. p541-一天不能建成fb](#85-p541-一天不能建成fb)
- [86. p564-云的优点和缺点](#86-p564-云的优点和缺点)
- [87. p582-应用层优化-缓存](#87-p582-应用层优化-缓存)
- [88. p584-应用层缓存的策略](#88-p584-应用层缓存的策略)
    - [88.1. 本地缓存](#881-本地缓存)
    - [88.2. 本地共享内存缓存](#882-本地共享内存缓存)
    - [88.3. 分布式内存缓存](#883-分布式内存缓存)
- [89. p593-备份和恢复](#89-p593-备份和恢复)
    - [89.1. 为什么需要备份](#891-为什么需要备份)
- [90. p596-设计MySQL备份方案](#90-p596-设计mysql备份方案)
- [91. p598-逻辑备份还是物理备份](#91-p598-逻辑备份还是物理备份)
    - [91.1. 逻辑备份](#911-逻辑备份)
    - [91.2. 物理备份](#912-物理备份)
- [92. p601-备份什么](#92-p601-备份什么)
- [93. p633-备份和恢复工具](#93-p633-备份和恢复工具)
- [94. p634-备份经验](#94-p634-备份经验)
- [95. p635-MySQL用户工具](#95-p635-mysql用户工具)
    - [95.1. 接口工具](#951-接口工具)
    - [95.2. 命令行工具](#952-命令行工具)
    - [95.3. SQL实用集](#953-sql实用集)
    - [95.4. 开源的监控工具](#954-开源的监控工具)
    - [95.5. 商业的监控工具](#955-商业的监控工具)

<!-- /TOC -->


<a id="markdown-1-p5-锁粒度" name="1-p5-锁粒度"></a>
# 1. p5-锁粒度
<a id="markdown-11-表锁table-lock" name="11-表锁table-lock"></a>
## 1.1. 表锁（table lock)
表锁是M ySQL 中最基本的锁策略，并且是开销最小的策略。表锁非常类似于前文描述
的邮箱加锁机制：**它会锁定整张表**。一个用户在对表进行写操作（插入、删除、更新等）
前，需要先获得写锁，这会**阻塞其他用户对该表的所有读写操作。只有没有写锁时，其
他读取的用户才能获得读锁，读锁之间是不相互阻塞的。**
**在特定的场景中，表锁也可能有良好的性能**。例如，READ LOCAL表锁支持某些类型的并
发写操作。另外，写锁也比读锁有更高的优先级，因此一个写锁请求可能会被插入到读
锁队列的前面**（写锁可以插入到锁队列中读锁的前面，反之读锁则不能插入到写锁的前
面）。**

<a id="markdown-12-行级锁row-lock" name="12-行级锁row-lock"></a>
## 1.2. 行级锁（row lock)
行级锁可以最大程度地支持并发处理（同时也带来了最大的锁开销）。. 众所周知，**在
InnoDB 和X traDB ，以及其他一些存储引擎中实现了行级锁**。**行级锁只在存储引擎层实
现**，而M ySQL 服务器层（如有必要，请回顾前文的逻辑架构图）没有实现。服务器层
完全不了解存储引擎中的锁实现。在本章的后续内容以及全书中，所有的存储引擎都以
自己的方式显现了锁机制。


<a id="markdown-2-p6-acid" name="2-p6-acid"></a>
# 2. p6-ACID
ACID 表示
  * 原子性(atomicity)
  * 一致性(consistency)
  * 隔离性(isolation)
  * 持久性(durability)。
一个运行良好的事务处理系统，必须具备这些标准特征。


<a id="markdown-21-原子性atomicity" name="21-原子性atomicity"></a>
## 2.1. 原子性（atomicity)
一个事务必须被视为一个**不可分割的最小工作单元**，整个事务中的所有操作**要么全
部提交成功，要么全部失败回滚**，对于一个事务来说， 不可能只执行其中的一部分
操作，这就是事务的原子性
<a id="markdown-22-一致性consistency" name="22-一致性consistency"></a>
## 2.2. 一致性(consistency)
数据库**总是从一个一致性的状态转换到另外一个一致性的状态**。在前面的例子中，
一致性确保了，即使在执行第三、四条语句之间时系统崩溃， 支票账户中也不会损
失200 美元，**因为事务最终没有提交，所以事务中所做的修改也不会保存到数据库中**。
<a id="markdown-23-隔离性iso-lation" name="23-隔离性iso-lation"></a>
## 2.3. 隔离性(iso lation)
通常来说，**一个事务所做的修改在最终提交以前，对其他事务是不可见的**。在前面
的例子中，当执行完第三条语句、第四条语句还未开始时，此时有另外一个账户汇
总程序开始运行，则其看到的支票账户的余额并没有被减去200 美元。后面我们讨
**论隔离级别（Isolation level )**的时候，会发现为什么我们要说“通常来说”是不可见的。
<a id="markdown-24-持久性durability" name="24-持久性durability"></a>
## 2.4. 持久性(durability)
**一旦事务提交，则其所做的修改就会永久保存到数据库中**。此时即使系统崩溃，修
改的数据也不会丢失。持久性是个有点模糊的概念，因为实际上持久性也分很多
不同的级別。有些持久性策略能够提供非常强的安全保障，而有些则未必。~且
不可能有能做到100% 的持久性保证的策略（ 如果数据库本身就能做到真正的#久
性，那么备份又怎么能增加持久性呢？）。

<a id="markdown-3-p7-是否需要事务处理" name="3-p7-是否需要事务处理"></a>
# 3. p7-是否需要事务处理
一个实现了ACID 的数据库，相比没有实现ACID 的数
据库，**通常会需要更强的CPU 处理能力、更大的内存和更多的磁盘空间**。正如本章不断
重复的，这也正是MySQL 的存储引擎架构可以发挥优势的地方。**用户可以根据业务是
否需要事务处理，来选择合适的存储引擎。**对于一些不需要事务的査询类应用，选择
一个非事务型的存储'引擎，可以获得更髙的性能。**即使存储引擎不支持事务，也可以
通过LOCK TABLES 语句为应用提供一定程度的保护**，这些选择用户都可以自主决定。

<a id="markdown-4-p8-隔离级别" name="4-p8-隔离级别"></a>
# 4. p8-隔离级别
<a id="markdown-41-read-uncomitted-未提交读" name="41-read-uncomitted-未提交读"></a>
## 4.1. READ UNCOmiTTED (未提交读）
在READ UNCOMMITTED级别，**事务中的修改，即使没有提交，对其他事务也都是可见
的**。事务可以读取未提交的数据，这也被称为**脏读（Dirty Read)**。这个级别会导致
很多问题，**从性能上来说，READ UNCO剛ITTED不会比其他的级别好太多，但却缺乏
其他级别的很多好处， 除非真的有非常必要的理由，在实际应用中一般很少使用。**
<a id="markdown-42-read-committbd-提交读" name="42-read-committbd-提交读"></a>
## 4.2. READ COMMITTBD (提交读）
**大多数数据库系统的默认隔离级别都是READ COMMITTED (但MySQL 不是）**。READ
COMMITTED满足前面提到的隔离性的简单定义：一个事务开始时，只能“看见”已
经提交的事务所做的修改。换句话说，一个事务从开始直到提交之前，所做的任何
修改对其他事务都是不可见的。**这个级别有时候也叫做不可重复读（nonrepeatable
read), 因为两次执行同样的査询，可能会得到不一样的结果。**
<a id="markdown-43-repeatable-read-可重复读" name="43-repeatable-read-可重复读"></a>
## 4.3. REPEATABLE READ (可重复读）
REPEATABLE READ解决了脏读的问题。该**级别保证了在同一个事务中多次读取同样
记录的结果是一致的**。但是理论上，可重复读隔离级别还是无法解决另外一个幻读
(Phantom Read) 的问题。所谓幻读，**指的是当某个事务在读取某个范围内的记录时，
另外一个事务又在该范围内插入了新的记录，当之前的事务再次读取该范围的记录
时，会产生幻行（PhantomRow)。**InnoDB 和XtraDB 存储引擎通过多版本并发控
制（MVCC, Multiversion Concurrency Control ) 解决了幻读的问题。本章稍后会做
进一步的讨论。
**可重复读是MySQL 的默认事务隔离级别。**
<a id="markdown-44-serializable-可串行化" name="44-serializable-可串行化"></a>
## 4.4. SERIALIZABLE (可串行化)
**SERIALIZABLE是最高的隔离级别**。它通过强制事务串行执行，**避免了前面说的幻读
的问题**。简单来说，SERIALIZABLE会在读取的毎一行数据上都加锁，所以可能导致
大量的超时和锁争用的问题。实际应用中也很少用到这个隔离级别，只有在非常需
要确保数据的一致性而且可以接受没有并发的情况下，才考虑采用该级别。

隔离级别  | 脏读可能性  | 不可重复读可能性  | 幻读可能性  | 加锁读 
-|-|-|-|-
READ UNCOMMITTED      |Yes        |Yes           |Yes           |No
READ COMMITTED |No |Yes |Yes |No
REPEATABLE READ |No |No |Yes |No
SERIALIZABLE |No |No |No |Yes

<a id="markdown-5-p9-死锁" name="5-p9-死锁"></a>
# 5. p9-死锁
**死锁是指两个或者多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而
导致恶性循环的现象。**当多个事务试图以不同的顺序锁定资源时，就可能会产生死锁。
多个事务同时锁定同一个资源时，也会产生死锁


事务1
```
START TRANSACTION;
UPDATE StockPrice SET close = 45.50 WHERE stock_id = 4 and date = '2002-05-0 1 '；
UPDATE StockPrice SET close = 19.80 WHERE stock~id = B and date = '2002-05-0 2 ';
COMMIT;
```
事务2
```
START TRANSACTION;
UPDATE StockPrice SET high = 20.12 WHERE stock_id = 3 and date = '2002-05-02';
UPDATE StockPrice SET high = 47.20 WHERE stock_id = 4 and date = '2002-05-0 1 '；
COMMIT;
```


如果凑巧，两个事务都执行了第一条UPDATE 语句，更新了一行数据，同时也锁定了该行
数据，接着每个事务都尝试去执行第二条UPDATE 语句，却发现该行已经被对方锁定，**然
后两个事务都等待对方释放锁，同时又持有对方需要的锁， 则陷入死循环。除非有外部
因素介入才可能解除死锁。**


为了解决这种问题，数据库系统实现了各种死锁检测和死锁超时机制。越复杂的系统，
比如InnoD B 存储引擎，**越能检测到死锁的循环依赖，并立即返回一个错误**。这种解决
方式很有效，否则死锁会导致出现非常慢的査询。还有一种解决方式，就是当査询的时
间达到锁等待超时的设定后放弃锁请求，这种方式通常来说不太好。In noD B 目前处理
死锁的方法是，**将持有最少行级排他锁的事务进行回滚**（ 这是相对比较简单的死锁回
滚算法）。


锁的行为和顺序是和存储引擎相关的。以同样的顺序执行语句，有些存储引擎会产生死
锁，有些则不会。死锁的产生有双重原因：
  * 有些是因为真正的数据冲突， 这种情况通常很难避免
  * 但有些则完全是由于存储引擎的实现方式导致的

<a id="markdown-6-p10-事务曰志" name="6-p10-事务曰志"></a>
# 6. p10-事务曰志
事务日志可以帮助提高事务的效率。**使用事务日志，存储引擎在修改表的数据时只需要
修改其内存拷贝，再把该修改行为记录到持久在硬盘上的事务日志中，而不用毎次都将
修改的数据本身持久到磁盘**。事务日志采用的是追加的方式，**因此写日志的操作是磁盘
上一小块区域内的顺序I/O**, 而不像随机I/O 需要在磁盘的多个地方移动磁头，所以采用
事务日志的方式相对来说要快得多。事务日志持久以后，内存中被修改的数据在后台可
以慢慢地刷回到磁盘。目前大多数存储引擎都是这样实现的，我们通常称之为预写式日
志（Write-Ahead Logging), 修改数据需要写两次磁盘。
**如果数据的修改已经记录到事务日志并持久化，但数据本身还没有写回磁盘，此时系统
崩溃，存储引擎在重启时能够自动恢复这部分修改的数据。具体的恢复方式则视存储引
擎而定。
**

<a id="markdown-7-p10-mysql-中的事务" name="7-p10-mysql-中的事务"></a>
# 7. p10-MySQL 中的事务
自动提交（AUTOCOMMIT)

MySQL 默认采用自动提交（AUT0C0MMIT) 模式。也就是说，如**果不是显式地开始一
个事务，则每个査询都被当作一个事务执行提交操作**。在当前连接中，可以通过设置
AUTOcomrr 变量来启用或者禁用自动提交模式：
```
SHOM VARIABLES LIKE 'AUT0C0MMIT';
SET AUTOCOMMIT = 1；
```
1 或者ON 表示启用， 0 或者OFF表示禁用。**当AUTOCOMMI T=0 时，所有的査询都是在一个
事务中，直到显式地执行COMMIT 提交或者ROLLBACK 回滚，**该事务结束，同时又开始了
另一个新事务。修改AUTOCOMMIT对非事务型的表，**比如MylSAM 或者内存表，不会有
任何影响。对这类表来说，没有COMMIT或者ROLLBACK的概**念，也可以说是相当于一直
处于AUT0C0MMIT启用的模式。


<a id="markdown-8-p12-多版本并发控制mvcc" name="8-p12-多版本并发控制mvcc"></a>
# 8. p12-多版本并发控制(MVCC)
MySQL 的大多数事务型存储引擎实现的都不是简单的行级锁。基**于提升并发性能的考
虑，它们一般都同时实现了多版本并发控制（MVCC)**。不仅是MySQL, 包括Oracle、
PostgreSQL 等其他数据库系统也都实现了MVCC, 但各自的实现机制不尽相同，因为
**MVCC 没有一个统一的实现标准。**
**可以认为MVCC 是行级锁的一个变种**，**但是它在很多情况下避免了加锁操作**，因此开
销更低。虽然实现机制有所不同，但大都实现了非阻塞的读操作，写操作也只锁定必要
的行。
MVCC 的实现，是通过保存数据在某个时间点的快照来实现的。也就是说，**不管需要执
行多长时间，每个事务看到的数据都是一致的。根据事务开始的时间不同，毎个事务对
同一张表，同一时刻看到的数据可能是不一样的**。如果之前没有这方面的概念，这句话
听起来就有点迷惑。熟悉了以后会发现，这句话食实还是很容易理解的。


InnoDB 的MVCC, 是通过在毎行记录后面保存两个隐藏的列来实现的。**这两个列，一
个保存了行的创建时间，一个保存行的过期时间（或删除时间**h 当然存储的并不是实
际的时间值，而是系统版本号（system version number)。每开始一个新的事务，系统版
本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和査询到的
每行记录的版本号进行比较。**下面看一下在REPEATABLE READ 隔离级别下，MVCC 具体
是如何操作的。**


MVCC 只在**REPEATABLE READ** 和**READ COMMITTED** 两个隔离级别下工作。其他两个隔离
级别都和MVCC 不兼容a4，因为READ UNCOMMITTED 总是读取最新的数据行，而不是符合
当前事务版本的数据行。而SERIALIZABLE 则会对所有读取的行都加锁。

<a id="markdown-9-p13-mysql的存储引擎" name="9-p13-mysql的存储引擎"></a>
# 9. p13-MySQL的存储引擎
<a id="markdown-91-innodb-存储引擎" name="91-innodb-存储引擎"></a>
## 9.1. InnoDB 存储引擎
InnoDB 是MySQL 的默认事务型引擎，也是**最重要、使用最广泛的存储引擎**。它被设计
用来**处理大量的短期（short-li ved) 事务**，短期事务大部分情况是正常提交的，很少会
被回滚。InnoDB 的性能和自动崩溃恢复特性，使得它在非事务型存储的需求中也很流
行。除非有非常特别的原因需要使用其他的存储引擎，否则**应该优先考虑InnoDB 引擎**。
如果要学习存储引擎， InnoDB 也是一个非常好的值得花最多的时间去深入学习的对象，
收益肯定比将时间平均花在每个存储引擎的学习上要髙得多。

概览
  * InnoDB 的数据存储在表空间（tab lespace) 中，
  * InnoDB 采用MVCC 来支持高并发，并且实现了四个标准的隔离级别。其默认级别是REPEATABLE READ (可重复读）， 并且通过间隙锁（next-key locking) 策略防止幻读的出现。
  * InnoDB 表是基于聚簇索引建立的,对主键査询有很高的性能。不过它的二级索引（secondar y index, 非主键索引）中必须包含主键列
  * InnoDB 内部做了很多优化，包括从磁盘读取数据时采用的可预测性预读，能够自动在内存中创建hash 索引以加速读操作的自适应哈希索引
  * InnoDB 的行为是非常复杂的，不容易理解。如果使用了InnoDB 引擎，笔者强烈建议阅读官方手册中的“InnoDB 事务模型和锁”一节
  * 如果应用程序基于InnoDB 构建，则事先了解一下InnoDB 的MVCC 架构带来的一些微妙和细节之处是非常有必要的
  * 作为事务型的存储引擎，InnoDB 通过一些机制和工具支持真正的热备份， Oracle 提供的MySQL Enterprise Backup、Percona 提供的开源的XtraBackup 都可以做到这一点。MySQL 的其他存储引擎不支持热备份，要获取一致性视图需要停止对所有表的写入,而在读写混合场景中，停止写入可能也意味着停止读取。

<a id="markdown-92-mylsam存储引擎" name="92-mylsam存储引擎"></a>
## 9.2. MylSAM存储引擎
在MySQL5.1及之前的版本，MyISAM是默认的存储引擎,但MylSAM 不支持事务和行级锁，而且有一个毫无疑问的缺陷就是崩溃后无法安全恢复.对于只读的数据，或者表比较小、可以忍受修复（repair) 操作.， 则依然可以继续使用MylSAM (**但请不要默认使用MylSAM, 而是应当默认使用InnoDB**)。

特性
  * 加锁与并发,**MylSAM 对整张表加锁，而不是针对行**
  * 索引特性,对于MylSAM表，即使是BLOB和TEXT等长字段，也可以基于其前500 个字符创建索引.**MylSAM也支持全文索引**，这是一种基于分词创建的索引，可以支持复杂的査询。
  * 延迟更新索引键（Delayed Key Write),创建MylSAM 表的时候，如果指定了DELAY_KEY_WRI TE选项，**在每次修改执行完成时，不会立刻将修改的索引数据写入磁盘，而是会写到内存中的键缓冲区（in-memorykey buffer)**,这种方式可以极大地提升写入性能，但是在数据库或者主机崩溃时会造成索引损坏，需要执行修复操作

MylSAM 压缩表
如果表在创建并导入数据以后，不会再进行修改操作，那么这样的表或许适合采用-MylSAM 压缩表。**压缩表可以极大地减少磁盘空间占用，因此也可以减少磁盘I/O, 从而提升査询性能。压缩表也支持索引， 但索引也是只读的。**

MylSAM 性能
但Myl SAM
最典型的性能问题还是表锁的问题， 如果你发现所有的査询都长期处于“Locked”状态，那么毫无疑问**表锁**就是罪魁祸首。


<a id="markdown-93-archive-引擎" name="93-archive-引擎"></a>
## 9.3. Archive 引擎
Archive 引擎支持行级锁和专用的缓冲区，所以可以**实现髙并发的插入**。在一个査询开始直到返回表中存在的所有行数之前，**Archive 引擎会阻止其他的SELECT执行，以实现一致性读。**Archive 引擎不是一个事务型的引擎，而是一个针对高速插入和压缩做了优化的简单引擎。

<a id="markdown-94-blackhole-引擎" name="94-blackhole-引擎"></a>
## 9.4. Blackhole 引擎
Blackhole 引擎没有实现任何的存储机制，它会丢弃所有插入的数据， 不做任何保存。但是服务器会记录Blackhole 表的日志，**所以可以用于复制数据到备库，或者只是简单地记录到日志。**

<a id="markdown-95-csv-引擎" name="95-csv-引擎"></a>
## 9.5. CSV 引擎
CSV 引擎可以将普通的CSV 文件（逗号分割值的文件） 作为MySQL 的表来处理，但**这种表不支持索引**,可以将Excel等电子表格软件中的数据存储为CSV 文件，然后复制到MySQL 数据目录下，就能在MySQL 中打开使用。。同样，如果将数据写入到一个CSV 引擎表，其他的外部程序也能立即从表的数据文件中读取CSV 格式的数据。因**此CSV 引擎可以作为一种数据交换的机制，非常有用**。

<a id="markdown-96-federated-引擎" name="96-federated-引擎"></a>
## 9.6. Federated 引擎
Federated 引擎是访问其他MySQL 服务器的一个代理，它会创建一个到远程MySQL 服务器的客户端连接，并将査询传输到远程服务器执行，然后提取或者发送需要的数据。尽管该引擎看起来提供了一种很好的跨服务器的灵活性，但也经常带来问题， **因此默认是禁用的**。MadaDB 使用了它的一个后续改进版本，叫做FederatedX。

<a id="markdown-97-memory-引擎" name="97-memory-引擎"></a>
## 9.7. Memory 引擎
如果需要快速地访问数据，并且这些数据不会被修改，重启以后丢失也没有关系，那么使用Memory 表（以前也叫做HEAP表）是非常有用的。Memory 表至少比MylSAM 表要快一个数量级，因为所有的数据都保存在内存中，不需要进行磁盘I/O。Memory 表的结构在重启以后还会保留，但数据会丢失.

Memroy 表在很多场景可以发挥好的作用：
  * 用于査找（lookup) 或者映射（mapping) 表，例如将邮编和州名映射的表。
  * 用于缓存周期性聚合数据（periodically aggregated data) 的结果。
  * 用于保存数据分析中产生的中间数据。

**Memory 表支持Hash 索引，因此査找操作非常快**。虽然Memory 表的速度非常快，但还
是无法取代传统的基于磁盘的表。**Memroy 表是表级锁，因此并发写人的性能较低**。它
不支持BLOB或TEXT类型的列，**并且每行的长度是固定的，所以即使指定了VARCHAR列，
实际存储时也会转换成CHAR, 这可能导致部分内存的浪费**（其中一些限制在Percona 版
本已经解决）。

<a id="markdown-98-merge-引擎" name="98-merge-引擎"></a>
## 9.8. Merge 引擎
Merge 引擎是MylSAM 引擎的一个变种。Merge 表是由多个MylSAM 表合并而来的虚
拟表。如果将MySQL 用于日志或者数据仓库类应用，该引擎可以发挥作用。但是引入
分区功能后，该**引擎已经被放弃**。

<a id="markdown-99-ndb-集群引擎" name="99-ndb-集群引擎"></a>
## 9.9. NDB 集群引擎
2003 年，当时的MySQL AB 公司从索尼爱立信公司收购了NDB 数据库，然后开发了
NDB 集群存储引擎，作为SQL 和NDB 原生协议之间的接口。MySQL 服务器、NDB 集
群存储引擎，以及分布式的、share-nothing 的、容灾的、高可用的NDB 数据库的组合，
被称为MySQL 集群（MySQL Cluster)。

<a id="markdown-910-其他引擎" name="910-其他引擎"></a>
## 9.10. 其他引擎
  * Infobright 是最有名的面向列的存储引擎。在非常大的数据量（数十TB) 时，该引擎工作良好

  * Aria 是MySQL 创建者计划用来替代MylSAM 的一款引擎。MariaDB 包含了该引擎，之前计划开发的很多特性，有些因为在MariaDB 服务器层实现，所以引擎层就取消了
  * Groonga 是一款全文索引引擎，号称可以提供准确而高效的全文索引。
  * OQGraph 支持图操作（比如査找两点之间的最短路径）， 用SQL很难实现该类操作。
  * Q4M 该引擎在MySQL 内部实现了队列操作，而用SQL 很难在一个语句实现这类队列操作。
  * SphinxSE 该引擎为Sphinx 全文索引搜索服务器提供了SQL 接口
  * Spider 该引擎可以将数据切分成不同的分区，比较髙效透明地实现了分片（shard) , 并且可以针对分片执行并行査询（分片可以分布在不同的服务器上）。
  * VPForMySQL 该引擎支持垂直分区，通过一系列的代理存储引擎实现。垂直分区指的是可以将表分成不同列的组合，并且单独存储。但对査询来说，看到的还是一张表


<a id="markdown-10-p24-选择合适的引擎" name="10-p24-选择合适的引擎"></a>
# 10. p24-选择合适的引擎
**大部分情况下， InnoDB 都是正确的选择**，所以Oracle在MySQL 5.5 版本时终于将InnoDB 作为默认的存储引擎了。


对于如何选择存储引擎，可以简单地归纳为一句话：“**除非需要用到某些InnoDB 不具备的特性，并且没有其他办法可以替代，否则都应该优先选择InnoDB 引擎**"

<a id="markdown-11-p35-基准测试benchmark" name="11-p35-基准测试benchmark"></a>
# 11. p35-基准测试（benchmark)
基准测试（benchmark) 是MySQL 新手和专家都需要掌握的一项基本技能。简单地说，**基准测试是针对系统设计的一种压力测试。**

  * 验证基于系统的一些假设，确认这些假设是否符合实际情况。
  * 重现系统中的某些异常行为，以解决这些异常。
  * 测试系统当前的运行情况。如果不清楚系统当前的性能，就无法确认某些优化的效果如何。也可以利用历史的基准测试结果来分析诊断一些无法预测的问题。
  * 模拟比当前系统更髙的负载，以找出系统随着压力增加而可能遇到的扩展性瓶颈。
  * 规划未来的业务增长。基准测试可以评估在项目未来的负载下，需要什么样的硬件，需要多大容量的网络，以及其他相关资源。这有助于降低系统升级和重大变更的风险。
  * 测试应用适应可变环境的能力。例如，通过基准测试，可以发现系统在随机的并发峰值下的性能表现，或者是不同配置的服务器之间的性能表现。基准测试也可以测试系统对不同数据分布的处理能力。
  * 测试不同的硬件、软件和操作系统配置。比如RAID 5 还是RAID 10 更适合当前的系统？如果系统从ATA 硬盘升级到SAN 存储，对于随机写性能有什么帮助？ Linux2.4 系列的内核会比2.6系列的可扩展性更好吗？升级MySQL的版本能改善性能吗？为当前的数据采用不同的存储引擎会有什么效果？所有这类问题都可以通过专门的基准测试来获得答案。
  * 证明新采购的设备是否配置正确。笔者曾经无数次地通过基准测试来对新系统进行压测，发现了很多错误的配置，以及硬件组件的失效等问题。因此在新系统正式上线到生产环境之前进行基准测试是一个好习惯，永远不要相信主机提供商或者硬件供应商的所谓系统已经安装好，并且能运行多快的说法。如果可能，执行实际的基准测试永远是一个好主意。

<a id="markdown-12-p38-测试何种指标" name="12-p38-测试何种指标"></a>
# 12. p38-测试何种指标

<a id="markdown-121-吞吐量" name="121-吞吐量"></a>
## 12.1. 吞吐量
吞吐量指的是**单位时间内的事务处理数**。这一直是经典的数据库应用测试指标。一
些标准的基准测试被广泛地引用， 而且很多数
据库厂商都努力争取在这些测试中取得好成绩。这类基准测试主要针对在线事务处
理（OLTP) 的吞吐量，非常适用于多用户的交互式应用。**常用的测试单位是每秒事
务数（TPS), 有些也采用每分钟事务数（TPM)。**


<a id="markdown-122-响应时间或者延迟" name="122-响应时间或者延迟"></a>
## 12.2. 响应时间或者延迟
通常可以使用百分比响应时间（percentile response
time ) 来替代最大响应时间。例如，**如果95% 的响应时间都是5 毫秒，则表示任务
在95% 的时间段内都可以在5 毫秒之内完成。**

<a id="markdown-123-并发性" name="123-并发性"></a>
## 12.3. 并发性
数据库的并发性还是需要测量的。可以通过 **sysbench**
指定32、64 或者128 个线程的测试，然后在测试期间记录MySQL 数据库
的Threads running 状态值。

<a id="markdown-124-可扩展性" name="124-可扩展性"></a>
## 12.4. 可扩展性
或者说，**给系统增加
一倍的资源（比如两倍的CPU 数）， 就可以获得两倍的吞吐量**。当然，同时性能（响
应时间) 也必须在可以接受的范围内。**大多数系统是无法做到如此理想的线性扩展的**,
随着压力的变化，吞吐量和性能都可能越来越差。

<a id="markdown-13-p49-集成式测试工具" name="13-p49-集成式测试工具"></a>
# 13. p49-集成式测试工具
工具|说明
-|-
 ab         | ab 是一个Apache HTTP 服务器基准测试工具。它可以测试**HTTP 服务器毎秒最多 可以处理多少请求**。如果测试的是Web 应用服务，这个结果可以转换成整个应用 毎秒可以满足多少请求。这是个非常简单的工具，用途也有限，只能针对单个URL 进行尽可能快的压力测试                                                                                  
 http_load  | 这个工具概念上和以类似,也被设计为对Web 服务器进行测试，但比要更加灵活。 **可以通过一个输入文件提供多个URL, 在这些URL 中随机选择进行测试。 也可以定制使其按照时间比率进行测试， 而不仅仅是测试最大请求处理 能力**                                                                                                        
 JMeter     | JMeter 是一个Java 应用程序，可以加载其他应用并测试_性能。它虽然是设计用来 测试Web 应用的， 但也可以用于测试其他诸如FTP 服务器，或者通过JDBC 进行数 据库査询测试。JMeter 比和ab和http_load都要复杂得多。例如， **它可以通过控制预热时间等参数， 更加灵活地模拟真实用户的访问**。JMeter 拥有绘图接口（带有内置的图形化处理的 功能）， 还可以对测试进行记录，然后离线重演测试结果。  


<a id="markdown-14-p50-单组件式测试工具" name="14-p50-单组件式测试工具"></a>
# 14. p50-单组件式测试工具

工具|说明
-|-
 mysqlslap                          | 巧认模似服务器 的负载，并输出计时信息。它包含在MySQL 5.1 的发行包中，应该在MySQL 4 .1 或者更新的版本中都可以使用。测试时可以执行并发连接数，并指定SQL 语句（可 以在命令行上执行，也可以把SQL 语句写入到参数文件中）                                                   
 MySQL Benchmark Suite (sql-bench)  | 在MySQL 的发行包中也提供了一款自己的基准测试套件，可以用于在不同数据库 服务器上进行比较测试。它是单线程的，主要用于测试服务器执行査询的速度。结 果会显示啷种类型的操作在服务器上执行得更快。                                                                            
 Super Smack                        | Super Smack 是一款用于MySQL 和PostgreSQL 的基准测试工具，可以提供**压力测试和负载生成**。这是一个复杂而强大的工具，可 以模拟多用户访问，可以加载测试数据到数据库，并支持使用随机数据填充测试表。 测试定义在“smack”文件中， smack 文件使用一种简单的语法定义测试的客户端、 表、査询等测试要素。  
 Database Test Suite                | 之前本书作者经常使用该工具，不过现在已经使用自己研发的专用于MySQL 的测试工具替 代了。                                                                                                                                  
 Percona’s TPCC-MySQL Tool          | 在评估大压力下MySQL 的一些行为时，我们经常会利用这个工具进行 测试（简单的测试，一般会采用udencA 替代）。                                                                                                                     
 sysbench                           | 可以根据影响数据库服务器性能的各种因素来评估系统的性能。例如，可以用来测试文件 I/O、操作系统调度器、内存分配和传输速度、POSIX 线程，以及数据库服务器等                                                                                                


<a id="markdown-15-p67-cpu利用率上升不意味性能下降" name="15-p67-cpu利用率上升不意味性能下降"></a>
# 15. p67-cpu利用率上升不意味性能下降
很多时候将使用老版本IrnioDB 引擎的MySQL 升级到新版本后，CPU
利用率会上升得很厉害，这并不代表性能出现了问题，**反而说明新版本的InnoDB 对资
源的利用率上升了**。査询的响应时间则更能体现升级后的性能是不是变得更好。版本升
级有时候会带来一些bug, 比如不能利用某些索引从而导致CPU 利用率上升。CPU 利用
率只是一种现象，而不是很好的可度量的目标。


<a id="markdown-16-p67-把时间花在测量问题上" name="16-p67-把时间花在测量问题上"></a>
# 16. p67-把时间花在测量问题上
我们观察到，**很多人在优化时，都将精力放在修改一些东西上，却很少去进行精确的测量。**
**我们的做法完全相反， 将花费非常多，甚至90% 的时间来测量响应时间花在哪里**。如果
通过测量没有找到答案，那要么是测量的方式错了，要么是测量得不够完整。如果测量
了系统中完整而且正确的数据，性能问题一般都能暴露出来，对症下药的解决方案也就
比较明了。测量是一项很有挑战性的工作，并且分析结果也同样有挑战性，测出时间花
在哪里，和知道为什么花在那里，是两码事。


2,8原则,性能问题往往出现在20%的代码上.
举个例子，在Percona Server 5.0 中，慢査询日志揭露了一些性能低下的原因， **如磁盘I/O
等待或者行级锁等待。如果日志中显示一条査询花费10 秒，其中9.6 秒在等待磁盘I/O,

那么追究其他4% 的时间花费在哪里就没有意义，磁盘I/O 才是最重要的原因。**

<a id="markdown-17-p71-理解性能剖析" name="17-p71-理解性能剖析"></a>
# 17. p71-理解性能剖析
<a id="markdown-171-值得优化的查询worthwhile-query" name="171-值得优化的查询worthwhile-query"></a>
## 17.1. 值得优化的查询（worthwhile query)
性能剖析不会自动给出哪些査询值得花时间去优化。这把我们带回到优化的本意，
如果你读过Cary Millsap 的书，对此就会有更多的理解。这里我们要再次强调两点：
第一，一些只占总响应时间比重很小的査询是不值得优化的。**根据阿姆达尔定律
(Amdahl’s Law)， 对一个占总响应时间不超过5% 的査询进行优化，无论如何努力，
收益也不会超过5%** 。第二，如果花费了1 000 美元去优化一个任务， 但业务的收入
没有任何增加，那么可以说反而导致业务被逆优化了1 000 美元。**如果优化的成本
大于收益，就应当停止优化。**

<a id="markdown-172-被掩藏的细节" name="172-被掩藏的细节"></a>
## 17.2. 被掩藏的细节
**性能剖析无法显示所有响应时间的分布。只相信平均值是非常危险的**，它会隐藏很
多信息，而且无法表达全部情况。Peter 经常举例说医院所有病人的平均体温没有任
何价值假如在前面的性能剖析的例子的第一项中，如果有两次査询的响应时间是
1 秒，而另外12 771 次査询的响应时间是几十微秒，结果会怎样？只从平均值里是
无法发现两次1 秒的査询的。要做出最好的决策，需要为性能剖析里输出的这一行
中包含的12 773 次査询提供更多的信息，**尤其是更多响应时间的信息，比如直方图、
' 百分比、标准差、偏差指数等**

<a id="markdown-18-p78-分析查询日志" name="18-p78-分析查询日志"></a>
# 18. p78-分析查询日志

强烈建议大家从现在起就利用慢査询日志捕获服务器上的所有査询，并且进行分析。可
以在一些典型的时间窗口如业务髙峰期的一个小时内记录査询。如果业务趋势比较均衡，
那么一分钟甚至更短的时间内捕获需要优化的低效査询也是可行的。

**不要直接打开整个慢査询日志进行分析，这样做只会浪费时间和金钱。首先应该生成一
个剖析报告，**如果需要，则可以再査看日志中需要特别关注的部分。自顶向下是比较好
的方式，否则有可能像前面提到的，反而导致业务的逆优化。

从慢査询日志中生成剖析报告需要有一款好工具，这里我们建议使用 **pt-query-digest**
这毫无疑问是分析MySQL 査询日志最有力的工具。该工具功能强大，包括可以将査询报告保存到数据库中，以及追踪工作负载随时间的变化。

<a id="markdown-19-p81-剖析单条查询" name="19-p81-剖析单条查询"></a>
# 19. p81-剖析单条查询
在实际应用中，除了**SHOW PROFILE、SHOW STATUS、检査慢査询日志的条
目**（这还要求必须是Percona Server, 官方MySQL 版本的慢査询日志缺失了很多附加信
息）这三种方法外就没有什么更好的办法了。


<a id="markdown-191-使用show-profile" name="191-使用show-profile"></a>
## 19.1. 使用SHOW PROFILE
**在服务器上执行的所有语句，都会测量其耗费的时间和其他一些査询执行状态变
更相关的数据**。这个功能有一定的作用，而且最初的设计功能更强大，但**未来版本中可
能会被Performance Schema 所取代**。

```
SET profiling = 1；
```

当一条査询提交给服务器时，此工具会记录剖析信息到一张临时表，并且给査询赋予一
个从1开始的整数标识符。

详细看p84

尽管剖析报告能帮助我们定位到哪些活动花费了最多的时间，但并不会告诉我们为什么
会这样。要弄清楚为什么复制数据到临时表要花费这么多时间，就需要深入下去，继续
剖析这一步的子任务。

<a id="markdown-192-使用show-status" name="192-使用show-status"></a>
## 19.2. 使用SHOW STATUS
SHOW STATUS 是一个有用的工具，但并不是一款剖析工具ftl2。SHOW STATUS 的大部分结果
都只是一个计数器，**可以显示某些活动如读索引的频繁程度，**但无法给出消耗了多少时
间。SHOW STATUS 的结果中只有一条指的是操作的时间, 而且
只能是全局级的，所以还是无法测量会话级别的工作。

<a id="markdown-193-使用慢查询曰志" name="193-使用慢查询曰志"></a>
## 19.3. 使用慢查询曰志
另外也可以看到，**慢査询日志中详细记录的条目包含了SHOW PROFILE和SHOW STATUS 所
有的输出**，并且还有更多的信息。所以通过声出gew 发现“坏”査询后，在慢査
询日志中可以获得足够有用的信息

<a id="markdown-194-performance-schema" name="194-performance-schema"></a>
## 19.4. Performance Schema
在MySQL 5.6 或者以后的版本中，Performance Schema 将会包含更多的功能， 再加上
一些方便使用的工具，这样就更“爽”了。而且Oracle 将其实现成表的形式，可以通过
SQL 访问，这样用户可以方便地访问有用的数据。**但其目前还无法立即取代慢査询日志
等其他工具用于服务器和査询的性能优化。**

<a id="markdown-20-p88-诊断间歇性问题" name="20-p88-诊断间歇性问题"></a>
# 20. p88-诊断间歇性问题
有些幻影问题只在没有注意到
的时候才发生，而且无法确认如何重现，诊断这样的问题往往要花费很多时间，有时候
甚至需要好几个月
  * 应用通过从一个运行得很慢的外部服务来获取汇率报价的数据
  * memcached缓存中的一些重要条目过期，导致大量请求落到MySQL 以重新生成缓存条目。
  * DNS 査询偶尔会有超时现象。
  * 可能是由于互斥锁争用，或者内部删除査询缓存的算法效率太低的缘故，MySQL 的査询缓存有时候会导致服务有短暂的停顿。
  * 当并发度超过某个阈值时，InnoDB 的扩展性限制导致査询计划的优化需要很长的时间。

<a id="markdown-21-p89-单条查询问题还是服务器问题" name="21-p89-单条查询问题还是服务器问题"></a>
# 21. p89-单条查询问题还是服务器问题
那么**如何判断是单条査询问题还是服务器问题呢？**如果问题不停地周期性出现， 那么可
以在某次活动中观察到，或者整夜运行脚本收集数据,•第二天来分析结果。大多数情况
下都可以通过三种技术来解决，下面将一一道来。

<a id="markdown-211-show-global-status" name="211-show-global-status"></a>
## 21.1. SHOW GLOBAL STATUS
这个方法实际上就是以较高的频率比如**一秒执行一次SHOW GLOBAL STATUS 命令捕
获数据**，问题出现时，则可以通过某些计数器（比如Th「e ads_「unning、Th「eads_
connected、Questions 和Queries) 的“尖刺”或者“凹陷”来发现。

**这个命令每秒输出一行数据， 可以运行几个小时或者几天，**然后将结果**绘制成图形**，这
样就可以方便地发现是否有趋势的突变。如果问题确实是间歇性的， 发生的频率又较低，
也可以根据需要尽可能长时间地运行此命令，直到发现问题再回头来看输出结果。**大多
数情况下，通过输出结果都可以更明确地定位问题。**

<a id="markdown-212-show-processlist" name="212-show-processlist"></a>
## 21.2. SHOW PROCESSLIST
这个方法是通过不停地捕获SHOW PROCESSLIST 的输出，来观察是否有大量线程处于不正
常的状态或者有其他不正常的特征。

<a id="markdown-213-使用查询曰志" name="213-使用查询曰志"></a>
## 21.3. 使用查询曰志
如果要通过査询日志发现问题，**需要开启慢査询日志并在全局级别设置long_query_
time 为0** , 并且要确认所有的连接都采用了新的设置。这可能需要重置所有连接以使新
的全局设置生效；或者使用Percona Server 的一个特性，可以在不断开现有连接的情况
下动态地使设置强制生效。

再重申一次，**好的工具可以帮助诊断这类问题，否则要人工去几百GB 的査询日志中找
原因。**

<a id="markdown-22-p92-理解发现的问题" name="22-p92-理解发现的问题"></a>
# 22. p92-理解发现的问题
可视化的数据最具有说服力。上面只演示了很少的几个例子，但在实际情况中，利用上
面的工具诊断时可能产生大量的输出结果。可以**选择用gnuplot或R** 或者其他绘图工
具将结果绘制成图形。这些绘图工具速度很快，比电子表格要快得多，而且可以对图上
的一些异常的地方进行缩放，这比在终端中通过滚动条翻看文字要好用得多，除非你是
“黑客帝国”中的矩阵观察者

我们建议诊断问题时**先使用前两种方法：SHOW STATUS 和SHOW PROCESSLIST**。这两种方
法的开销很低， **而且可以通过简单的shell 脚本或者反复执行的査询来交互式地收集数
据**。分析慢査询日志则相对要困难一些，经常会发现一些蛛丝马迹，但仔细去研究时可能又消失了。这样我们很容易会认为其实没有问题。

<a id="markdown-23-p111-选择优化的数据类型" name="23-p111-选择优化的数据类型"></a>
# 23. p111-选择优化的数据类型

<a id="markdown-231-更小的通常更好" name="231-更小的通常更好"></a>
## 23.1. 更小的通常更好
一般情况下，应该尽量使用可以正确存储数据的最小数据类型。更小的数据类型通常更快，因为它们占用更少的磁盘、内存和cpu 缓存，并且处理时需要的cpu 周期也更少。
但是要确保没有低估需要存储的值的范围，因为在schema 中的多个地方增加数据类
型的范围是一个非常耗时和痛苦的操作。如果无法确定哪个数据类型是最好的，就
**选择你认为不会超过范围的最小类型**。（如果系统不是很忙或者存储的数据量不多，
或者是在可以轻易修改设计的早期阶段，那之后修改数据类型也比较容易） 。

<a id="markdown-232-简单就好" name="232-简单就好"></a>
## 23.2. 简单就好
简单数据类型的操作通常需要更少的CPU 周期。例如，**整型比字符操作代价更低**，
**因为字符集和校对规则(排序规则)使字符比较比整型比较更复杂**。这里有两个例子：
一个是应该使用MySQL 内建的类型而不是字符串来存储日期和时间，另外一个
是**应该用整型存储IP 地址**。

<a id="markdown-233-尽量避免null" name="233-尽量避免null"></a>
## 23.3. 尽量避免NULL
很多表都包含可为NULL (空值） 的列，即使应用程序并不需要保存NULL也是如此，
这是因为可为NULL是列的默认属性S3。**通常情况下最好指定列为NOT NULL, 除非真
的需要存储NULL值。**
如**果査询中包含可为NULL的列，对MySQL 来说更难优化，因为可为NULL的列使
得索引、索引统计和值比较都更复杂。**可为NULL的列会使用更多的存储空间，在
MySQL 里也需要特殊处理。当可为NULL的列被索引时，每个索引记录需要一个额
外的字节，在MylSAM 里甚至还可能导致固定大小的索引（例如只有一个整数列的
索引）变成可变大小的索引。
**通常把可为NULL的列改为NOT NULL带来的性能提升比较小，所以（调优时）没有
必要首先在现有schema 中査找并修改掉这种情况**，除非确定这会导致问题。但是，
如果计划在列上建索引，就应该尽量避免设计成可为NULL的列。


<a id="markdown-24-p114-decimal使用场景" name="24-p114-decimal使用场景"></a>
# 24. p114-DECIMAL使用场景
因为需要额外的空间和计算开销，**所以应该尽量只在对小数进行精确计算时才使用
DECIMAL** 例如存储财务数据。但在数据量比较大的时候， 可以考虑使用**BIGINT代替
DECIMAL, 将需要存储的货币单位根据小数的位数乘以相应的倍数即可**。假设要存储财
务数据精确到万分之一分，则可以把所有金额乘以一百万，然后将结果存储在BIGINT 里，
**这样可以同时避免浮点存储计算不精确和DECIMAL精确计算代价高的问题。**

<a id="markdown-25-p117-varchar和char" name="25-p117-varchar和char"></a>
# 25. p117-VARCHAR和CHAR
例|如，**CHAR非常适合存储密码的MD5 值，因为这是一个定长的值。**对于经常变更的数据，**CHAR也比
VARCHAR更好，因为定长的CHAR类型不容易产生碎片**。对于非常短的列，**CHAR比
VARCHAR在存储空间上也更有效率**。**例如用CHAR(l ) 来存储只有Y和N的值，如果
采用单字节字符集只需要一个字节，但是VARCHAR(l ) 却需要两个字节，因为还有
一个记录长度的额外字节。**

**更长的列会消耗更多的内存**，因为MySQL 通常会分配固
定大小的内存块来保存内部值。尤其是使用内存临时表进行排序或操作时会特别糟
糕。在利用磁盘临时表进行排序时也同样糟糕。
**所以最好的策略是只分配真正需要的空间**

<a id="markdown-26-p122-timestamp" name="26-p122-timestamp"></a>
# 26. p122-TIMESTAMP
就像它的名字一样，TI M E T A MP 类型保存了**从1970 年1 月1 日午夜（ 格林尼治标准
时间）以来的秒数**，它和UN I X 时间戳相同。TIMESTAMP 只使用4 个字节的存储空间，
因此它的范围比DATETIME 小得多：**只能表示从19 7 0 年到2038 年**。

**除了特殊行为之外，通常也应该尽量使用TIMESTAMP**, **因为它比DATETIME 空间效率更高。**
有时候人们会将Uni x 时间截存储为整数值，但这不会带来任何收益。用整数保存时间
截的格式通常不方便处理，所以我们不推荐这样做。

如果需要存储比秒更小粒度的日期和时间值怎么办？MySQL 目前没有提供合适的数据
类型，**但是可以使用自己的存储格式：可以使用BI G I NT 类型存储微秒级别的时间截，或
者使用DOUBLE 存储秒之后的小数部分。**这两种方式都可以，或者也可以使用MariaDB
替代MySQL。

<a id="markdown-27-p126-避免使用字符串类型作为标识列" name="27-p126-避免使用字符串类型作为标识列"></a>
# 27. p126-避免使用字符串类型作为标识列
如果可能，应该避免使用字符串类型作为标识列，**因为它们很消耗空间，并且通常比数字类型慢。**尤其是在MylSAM表里使用字符串作为标识列时要特别小心。MylSAM默认对字符串使用压缩索引， 这会导致査询慢得多.

<a id="markdown-28-p126-orm的性能问题" name="28-p126-orm的性能问题"></a>
# 28. p126-ORM的性能问题
对象关系映射（ORM) 系统（以及使用它们的“框架”）是另一种常见的性能噩梦。
一些ORM 系统会**存储任意类型的数据到任意类型的后端数据存储中**，这通常意味
着其没有设计使用更优的数据类型来存储。有时会为每个对象的每个属性使用单独
的行，甚至使用基于时间戮的版本控制，导致单个属性会有多个版本存在.
这种设计对开发者有吸引力，因为这使得他们可以用面向对象的方式工作，不需
要考虑数据是怎么存储的。然而，“对开发者隐藏复杂性”的应用通常不能很好地
扩展。我们**建议在用性能交换开发人员的效率之前仔细考虑，并且总是在真实大小
的数据集上做测试，这样就不会太晚才发现性能问题。**

<a id="markdown-29-p127-ip地址使用整数存储" name="29-p127-ip地址使用整数存储"></a>
# 29. p127-ip地址使用整数存储
另一个例子是一个IPv4 地址。**人们经常使用VARCHAR( 15) 列来存储IP 地址**。然而，它
们实际上是32 位无符号整数，不是字符串。用小数点将地址分成四段的表示方法只是
为了让人们阅读容易。**所以应该用无符号整数存储IP 地址**。MySQL 提供INET_ATON()
和INET_NTOA() 函数在这两种表示方法之间转换。

<a id="markdown-30-p129-范式和反范式" name="30-p129-范式和反范式"></a>
# 30. p129-范式和反范式
对于任何给定的数据通常都有很多种表示方法，**从完全的范式化到完全的反范式化，以
及两者的折中**。**在范式化的数据库中，毎个事实数据会出现并且只出现一次**。相反，在**
反范式化的数据库中， 信息是冗余的，可能会存储在多个地方**
<a id="markdown-301-范式的优缺点" name="301-范式的优缺点"></a>
## 30.1. 范式的优缺点
  * 范式化的更新操作通常比反范式化要快。
  * 当数据较好地范式化时，就只有很少或者没有重复数据，所以只需要修改更少的数据。
  * 范式化的表通常更小，可以更好地放在内存里，所以执行操作会更快
  * 很少有多余的数据意味着检索列表数据时更少需要DISTINCT 或者GROUP BY 语句。

范式化设计的schema 的缺点是**通常需要关联**。**稍微复杂一些的査询语句在符合范式的
schema 上都可能需要至少一次关联，也许更多**。这不但代价昂贵，也可能使一些索引策
略无效。例如，范式化可能将列存放在不同的表中，而这些列如果在一个表中本可以属
于同一个索引。

<a id="markdown-302-反范式的优点和缺点" name="302-反范式的优点和缺点"></a>
## 30.2. 反范式的优点和缺点
反范式化的schema 因为所有数据都在一张表中，可以很好地避免关联

如果不需要关联表，则对大部分査询最差的情况——即使表没有使用**索引**——是全表扫
描。**当数据比内存大时这可能比关联要快得多，因为这样避免了随机i/o。**


<a id="markdown-303-混用范式化和反范式化" name="303-混用范式化和反范式化"></a>
## 30.3. 混用范式化和反范式化
范式化和反范式化的schema 各有优劣，怎么选择最佳的设计？

在实际应用中经常需要混用，可能使用部分范式化的schema、缓存表，以及其他技巧。

<a id="markdown-304-缓存表和汇总表" name="304-缓存表和汇总表"></a>
## 30.4. 缓存表和汇总表
有时提升性能最好的方法是在**同一张表中保存衍生的冗余数据**。然而，**有时也需要创建
一张完全独立的汇总表或缓存表**（ 特别是为满足检索的需求时）。如果能容许少量的脏
数据，这是非常好的方法，但是有时确实没有选择的余地（例如， 需要避免复杂、昂贵
的实时更新操作）。

<a id="markdown-31-p136-更快地读更慢的写" name="31-p136-更快地读更慢的写"></a>
# 31. p136-更快地读,更慢的写
为了提升读查询的速度，经常会需要**建一些额外索引，增加冗余列，甚至是创建缓
存表和汇总表**。这些方法会增加写查询的负担，也需要额外的维护任务，但在设计
高性能数据库时，这些都是常见的技巧：**虽然写操作变得更慢了，但更显著地提高
了读操作的性能。**
然而，写操作变慢并不是读操作变得更快所付出的唯一代价，**还可能同时增加了读
操作和写操作的开发难度。**


<a id="markdown-32-p140-schema与数据类型优化总结" name="32-p140-schema与数据类型优化总结"></a>
# 32. p140-Schema与数据类型优化总结
  * 尽量避免过度设计，例如会导致极其复杂査询的schema 设计，或者有很多列的表设计（很多的意思是介于有点多和非常多之间）。
  * 使用小而简单的合适数据类型，除非真实数据模型中有确切的需要，否则应该尽可能地避免使用NULL值。
  * 尽量使用相同的数据类型存储相似或相关的值，尤其是要在关联条件中使用的列。
  * 注意可变长字符串，其在临时表和排序时可能导致悲观的按最大长度分配内存。
  * 尽量使用整型定义标识列。
  * 避免使用MySQL 已经遗弃的特性，例如指定浮点数的精度，或者整数的显示宽度。
  * 小心使用ENUM和SET。虽然它们用起来很方便，但是不要滥用，否则有时候会变成陷阱。最好避免使用BIT。
  * 范式是好的，但是反范式（大多数情况下意味着重复数据）有时也是必需的，并且能带来好处
  * ALTER TABLE是让人痛苦的操作(备机执行ALTER并在完成后把它切换为主库) 奇淫巧技见p136


<a id="markdown-33-p141-创建高性能的索引" name="33-p141-创建高性能的索引"></a>
# 33. p141-创建高性能的索引
索引（在MySQL 中也叫做“键（key)”） 是存储引擎用于快速找到记录的一种数据结构。
这是索引的基本功能，除此之外，本章还将讨论索引其他一些方面有用的属性。
**索引对于良好的性能非常关键。尤其是当表中的数据量越来越大时，索引对性能的影响
愈发重要。**在数据量较小且负载较低时，不恰当的索引对性能的影响可能还不明显，**但
当数据量逐渐增大时，性能则会急剧下降.**

索引优化应该是对査询性能优化最有效的手段了。**索引能够轻易将査询性能提高几个数
量级，“最优”的索引有时比一个“好的”索引性能要好两个数量级。**创建一个真正“最
优”的索引经常需要重写査询.

<a id="markdown-331-如果使用的是orm-是否还需要关心索引" name="331-如果使用的是orm-是否还需要关心索引"></a>
## 33.1. 如果使用的是ORM, 是否还需要关心索引？
简而言之：是的，仍然需要理解索引，即使是使用对象关系映射（ORM) 工具。
ORM 工具能够生产符合逻辑的、合法的查询（多数时候）， 除非只是生成非常基本
的查询（例如仅是根据主键查询），** 否则它很难生成适合索引的查询**。无论是多么
复杂的ORM 工具，在精妙和复杂的索引面前都是“浮云”。读完本章后面的内容
以后，你就会同意这个观点的！**很多时候，即使是查询优化技术专家也很难兼顾到
各种情况，更别说ORM 了。**

<a id="markdown-332-索引的类型" name="332-索引的类型"></a>
## 33.2. 索引的类型
当人们谈论索引的时候，如果没有特别指明类型，那多半说的是B-Tree 索引，它使用
**B-Tree** 数据结构来存储数据S2。大多数MySQL 引擎都支持这种索引。

不过，底层的存储引擎也可能使用不同的存储结构，例如， **NDB 集群存储引擎内部实际
上使用了T-Tree 结构存储这种索引**，即使其名字是BTREE ; **InnoDB 则使用的是B+Tree**,
各种数据结构和算法的变种不在本书的讨论范围之内。


<a id="markdown-333-索引查询方式" name="333-索引查询方式"></a>
## 33.3. 索引查询方式
可以使用B-Tre e 索引的查询类型。B-Tree 索引适用于全键值、键值范围或键前缀査找。
其中键前缀查找只适用于根据最左前缀的査找ft3。前面所述的索引对如下类型的査询有
效。


```
CREATE TABLE People (
last_name varchar(50) not null,
first_name varchar(50) not null,
dob date not null,
gender enum('m', 'f ')not null,
key(last_name , first_name, dob)
);
```

全值匹配  
全值匹配指的是和索引中的所有列进行匹配，例如前面提到的索引可用于査找姓名
为Cuba Allen、出生于1960-0 1-0 1 的人。

匹配最左前缀  
前面提到的索引可用于査找所有姓为Allen 的人，即只使用索引的第一列。

匹配列前缀  
也可以只匹配某一列的值的开头部分。例如前面提到的索引可用于査找所有以J 开
头的姓的人。这里也只使用了索引的第一列。

匹配范围值  
例如前面提到的索引可用于査找姓在Allen 和Barrymore 之间的人。这里也只使用
了索引的第一列。

精确匹配某一列并范围匹配另外一列  
前面提到的索引也可用于査找所有姓为Allen, 并且名字是字母K 开头（比如Kim、
K arl等）的人。即第一列last_name 全匹配， 第二列first_name 范围匹配。

只访问索引的查询  
B-Tree 通常可以支持“只访问索引的査询”， 即査询只需要访问索引，而无须访问
数据行。


<a id="markdown-334-索引限制" name="334-索引限制"></a>
## 33.4. 索引限制

  * 如果**不是按照索引的最左列开始査找，则无法使用索引**。例如上面例子中的索引无法用于査找名字为Bill 的人，也无法査找某个特定生日的人，因为这两列都不是最左数据列。类似地，也无法査找姓氏以某个字母结尾的人。

  * 不能跳过索引中的列。也就是说，前面所述的索引无法用于査找姓为Smith 并且在某个特定日期出生的人。如果不指定名（first_name), 则MySQL 只能使用索引的第一列。

  * **如果查询中有某个列的范围査询，则其右边所有列都无法使用索引优化査找**。例如有查询WHERE last_name='Smith' AND first_name LIKE 'J%' AND dob = '1976-12-23' , 这个査只能使用索引的前两列，因为这里LIKE 是一个范围条件（ 但是服务器可以把其余列用于其他目的）。如果范围査询列值的数量有限，那么可以通过使用多个等于条件来代替范围条件。

<a id="markdown-335-哈希索引" name="335-哈希索引"></a>
## 33.5. 哈希索引
在MySQL 中，**只有Memory 引擎显式支持哈希索引**。这也是Memory 引擎表的默认索
引类型，**Memory 引擎同时也支持B-Tree 索引**。值得一提的是，Memory 引擎是支持非
唯一哈希索引的，这在数据库世界里面是比较与众不同的。

example  

```
CREATE TABLE testhash (
fname VARCHAR(50) NOT NULL,
lname VARCHAR(50) NOT NULL,
KEY USING HASH(fname)
) ENGINE=MEMORY;
```

```
SELECT lname FROM testhash WHERE fname=' Peter' ;
```

MySQL 先计算'Peter'的哈希值，并使用该值寻找对应的记录指针。因为f('Peter')=
8784, 所以MySQL 在索引中査找8784, 可以找到指向第3 行的指针，最后一步是比较
第三行的值是否为'Peter', 以确保就是要査找的行。


限制  
  * 哈希索引只包含哈希值和行指针，而不存储字段值，所以不能使用索引中的值来避免读取行。不过，访问内存中的行的速度很快，所以大部分情况下这一点对性能的影响并不明显。
  * 哈希索引数据并不是按照索引值顺序存储的，所以也就无法用于排序。
  * **哈希索引也不支持部分索引列匹配査找**，因为哈希索引始终是使用索引列的全部内容来计算哈希值的。例如，在数据列（A,B) 上建立哈希索引，如果査询只有数据列A,则无法使用该索引。
  * **哈希索引只支持等值比较査询**，包括=、IN ()、<=> ( 注意<> 和< = > 是不同的操作)。也不支持任何范围査询，例如WHERE price > 100
  * 访问哈希索引的数据非常快，除非有很多哈希冲突（不同的索引列值却有相同的哈希值）。当出现哈希冲突的时候，存储引擎必须遍历链表中所有的行指针，逐行进行比较，直到找到所有符合条件的行
  * 如果哈希冲突很多的话，一些索引维护操作的代价也会很高。例如， 如果在某个选择性很低（哈希冲突很多）的列上建立哈希索引，那么当从表中删除一行时，存储引擎需要遍历对应哈希值的链表中的每一行，找到并删除对应行的引用，冲突越多，代价越大。


因为这些限制，**哈希索引只适用于某些特定的场合**。而一旦适合哈希索引，则它带来的
性能提升将非常显著。举个例子，在数据仓库应用中有一种经典的'星型'schema , 需
要关联很多査找表，哈希索引就非常适合査找表的需求。

<a id="markdown-336-创建自定义哈希索引" name="336-创建自定义哈希索引"></a>
## 33.6. 创建自定义哈希索引
如果存储引擎不支持哈希索引，则可以**模拟像InnoDB —样创建
哈希索引**，这可以享受一些哈希索引的便利， 例如只需要很小的索引就可以为超长的键
创建索引。

**不要使用SHA1() 和MD5 () 作为哈希函数**。因为这两个函数计算
出来的哈希值是非常长的字符串，会**浪费大量空间**，**比较时也会更慢**。SHA1() 和MD5 (>
是强加密函数，**设计目标是最大限度消除冲突**，但这里并不需要这样高的要求。简单哈
希函数的冲突在一个可以接受的范围，同时又能够提供更好的性能。

如果数据表非常大，CRC32() 会出现大量的哈希冲突，则可以考虑自己实现一个简单的
64 位哈希函数。这个自定义函数要返回整数，而不是字符串。**一个简单的办法可以使用
MD5 () 函数返回值的一部分来作为自定义哈希函数**

```
SELECT C0NV(RIGHT(HD5('http://www.mysql.com/'), 16), 16, 10) AS HASH64;
```

注意必须在WHERE 子句中包含常量
```
SELECT id FROM url WHERE url_crc=CRC32(nhttp://www.mysql.com")
    AND url="http://wmw.mysql.com";
```


一且出现哈希冲突，另一个字符串的哈希值也恰好是1560514994, 则下面的査询是无法正确工作的。
```
SELECT id FROM url WHERE url_crc=CRC32("http://www.nysql.com");
```


还可以使用如FNV64 () 函数作为哈希函数，这是移植自PerconaServer 的函
数，可以以插件的方式在任何MySQL 版本中使用，哈希值为64 位，速度快，且冲突比
CRC32() 要少很多。


<a id="markdown-337-空间数据索引r-tree" name="337-空间数据索引r-tree"></a>
## 33.7. 空间数据索引(R-Tree)
MylSAM 表支持空间索引，可以用作地理数据存储。和B-Tree 索引不同，这类索引无
须前缀査询。**空间索引会从所有维度来索引数据。査询时，可以有效地使用任意维度来
组合査询。**必须使用MySQL 的GIS 相关函数如MBRCONTAINS() 等来维护数据。MySQL
的GIS 支持并不完善，所以大部分人都不会使用这个特性。**开源关系数据库系统中对
GIS 的解决方案做得比较好的是PostgreSQL 的PostGIS。**

<a id="markdown-338-全文索引" name="338-全文索引"></a>
## 33.8. 全文索引
全文索引是一种特殊类型的索引，它査找的是文本中的关键词，而不是直接比较索引中
的值。全文搜索和其他几类索引的匹配方式完全不一样。它有许多需要注意的细节，如
停用词、词干和复数、布尔搜索等。全文索引更类似于搜索引擎做的事情，而不是简单
的WHERE条件匹配。
在相同的列上同时创建全文索引和基于值的B-Tree 索引不会有冲突，全文索引适用于
MATCH AGAINST操作，而不是普通的WHERE条件操作。

<a id="markdown-34-p152-索引的优点" name="34-p152-索引的优点"></a>
# 34. p152-索引的优点
  - 索引大大减少了服务器需要扫描的数据量。
  - 索引可以帮助服务器避免排序和临时表
  - 索引可以将随机I/O 变为顺序I/O。

Lahdemnaki 和Leach 在书中介绍了如何评价一个索引是否适合某个査询的“三星系统”
(t hree-star system) :**索引将相关的记录放到一起则获得一星| 如果索引中的数据顺序和
査找中的排列顺序一致则获得二星，如果索引中的列包含了査询中需要的全部列则获得
“三星”**

<a id="markdown-35-p152-索引并不是最好的解决方案" name="35-p152-索引并不是最好的解决方案"></a>
# 35. p152-索引并不是最好的解决方案
索引并不总是最好的工具。总的来说，只有当索引帮助存储引擎快速查找到记录带
来的好处大于其带来的额外工作时，索引才是有效的。**对于非常小的表，大部分情
况下简单的全表扫描更高效**。**对于中到大型的表，索引就非常有效**。**但对于特大型
的表，建立和使用索引的代价将随之增长**。这种情况下，则需要一种技术可以直接
区分出查询需要的一组数据，而不是一条记录一条记录地匹配

**如果表的数量特别多，可以建立一个元数据信息表**，用来查询需要用到的某些特性。
例如执行那些需要聚合多个应用分布在多个表的数据的查询，则需要记录“哪个用
户的信息存储在哪个表中”的元数据，这样在查询时就可以直接忽略那些不包含指
定用户信息的表。对于大型系统，这是一个常用的技巧。事实上， Infobright 就是
使用类似的实现。**对于TB 级别的数据，定位单条记录的意义不大，所以经常会使
用块级别元数据技术来替代索引。**

<a id="markdown-36-p153-高性能的索引策略" name="36-p153-高性能的索引策略"></a>
# 36. p153-高性能的索引策略
<a id="markdown-361-独立的列" name="361-独立的列"></a>
## 36.1. 独立的列

下面这个査询无法使用actor_id 列的索引：
```
SELECT actor_id FROM sakila.actor WHERE actor_id + 1 = 5；
```
但是MySQL 无法自动解析这个方程式。这完全是用户行为。我们应该养成简化WHERE 条件的习惯，**始终将索引列单独放在比较符号的一侧。**

<a id="markdown-362-前缀索引" name="362-前缀索引"></a>
## 36.2. 前缀索引
对于BLOB、TEXT或者很长的VARCHAR类型的列，必须使用前缀索引，因为MySQL 不允许索引这些列的完整长度。

诀窍在于要选择足够长的前缀以保证较高的选择性，同时又不能太长（ 以便节约空间）。
前缀应该足够长，以使得前缀索引的选择性接近于索引整个列。换句话说，前缀的“基
数”应该接近于完整列的“基数”。

**前缀索引是一种能使索引更小、更快的有效办法，但另一方面也有其缺点：MySQL 无
法使用前缀索引做ORDER BY和GROUP BY**, 也无法使用前缀索引做覆盖扫描。

<a id="markdown-363-多列索引" name="363-多列索引"></a>
## 36.3. 多列索引
一般是由于人们听到一些专家诸如**“把WHERE条件里面的列都建上索引”
这样模糊的建议导致的**。实际上这个建议是非常错误的。**这样一来最好的情况下也只能
是“一星”索引，其性能比起真正最优的索引可能差几个数量级。**有时如果无法设计一
个“三星”索引，那么不如忽略掉WHERE子句，**集中精力优化索引列的顺序，或者创建
一个全覆盖索引。**

<a id="markdown-364-选择合适的索引列顺序" name="364-选择合适的索引列顺序"></a>
## 36.4. 选择合适的索引列顺序

正确的顺序依赖于使用该索引的
査询，并且同时需要考虑如何更好地满足排序和分组的需要（顺便说明，本节内容适用
于B-Tree 索引，**哈希或者其他类型的索引并不会像B-Tree 索引一样按顺序存储数据**）。

当不需要考虑排序和分组时，**将选择性最髙的列放在前面通常是很好的**。这时候索引的
作用只是用于优化WHERE条件的査找。在这种情况下，这样设计的索引确实能够最快地
过滤出需要的行，对于在WHERE子句中只使用了索引部分前缀列的査询来说选择性也更
髙。

```
SELECT * FROM payment WHERE staff_id = 2 AND customer_id = 584
```

是应该创建一个（staff_id , custome_id ) 索引还是应该颠倒一下顺序？可以跑一些査询
来确定在这个表中值的分布情况，并确定哪个列的选择性更高。先用下面的査询预测一下看,
看看各个WHERE条件的分支对应的数据基数有多大：

```
SELECT SUM(staff_id = 2)， SUM(customer—id = 584) FROM payment\G
```

  * SUM(staff_id = 2): 7992
  * SUM(customer_id = 584) ： 30

根据前面的经验法则，应该将索引列cuitome_id 放到前面，因为对应条件值的customer_id 数量更小


最好还是按经验法则来做，因为经验法则考虑的是全局基数和选择性，而不是某个具体査询

```
SELECT COUNT (DISTINCT staff id)/C0UNT(*) AS staff_id_selectivity,
COUNT(DISTINCT customer id) COUNT(*) AS customer_id selectivity,
C0UNT(*)
FROM payment\G
```

  * staff_id_selectivity: 0.0001
  * customer_id_selectivity: 0.0373
  * C0UNT (*) : 16049

custome_id 的选择性更髙，所以答案是将其作为索引列的第一列

尽管关于选择性和基数的经验法则值得去研究和分析，但一定要记住别忘了
WHER E子句中的排序、分组和范围条件等其他因素，这些因素可能对査询的性能造成非
常大的影响

<a id="markdown-365-聚簇索引" name="365-聚簇索引"></a>
## 36.5. 聚簇索引
聚簇索引并不是一种单独的索引类型，而是一种数据存储方式

聚集的数据有一些重要的优点:

  * 可以把相关数据保存在一起。例如实现电子邮箱时，可以根据用户ID 来聚集数据，这样只需要从磁盘读取少数的数据页就能获取某个用户的全部邮件。如果没有使用聚簇索引，则毎封邮件都可能导致一次磁盘I/O。
  * 数据访问更快。聚簇索引将索引和数据保存在同一个B-Tree 中，因此从聚簇索引中获取数据通常比在非聚簇索引中査找要快。
  * 使用覆盖索引扫描的査询可以直接使用页节点中的主键值。

缺点:
  * 聚簇数据最大限度地提高了I/O 密集型应用的性能，但如果数据全部都放在内存中，则访问的顺序就没那么重要了，聚簇索引也就没什么优势了。
  * 插入速度严重依赖于插入顺序。按照主键的顺序插入是加载数据到InnoDB 表中速度最快的方式。但如果不是按照主键顺序加载数据，那么在加载完成后最好使用OPTIMIZE TABLE命令重新组织一下表。
  * 更新聚簇索引列的代价很高，因为会强制InnoDB 将每个被更新的行移动到新的位置。
  * 基于聚簇索引的表在插入新行，或者主键被更新导致需要移动行的时候，可能面临“页分裂（page split)” 的问题。当行的主键值要求必须将这一行插入到某个已满的页中时，存储引擎会将该页分裂成两个页面来容纳该行，这就是一次页分裂操作。页分裂会导致表占用更多的磁盘空间。
  * 聚簇索引可能导致全表扫描变慢，尤其是行比较稀疏，或者由于页分裂导致数据存储不连续的时候。
  * 二级索引（非聚簇索引） 可能比想象的要更大， 因为在二级索引的叶子节点包含了引用行的主键列。
  * 二级索引访问需要两次索引査找，而不是一次。

<a id="markdown-366-覆盖索引" name="366-覆盖索引"></a>
## 36.6. 覆盖索引
如果一个索引包含（或者说覆盖） 所有需要査询的字段的值，我们就称之为“覆盖索引”,好处:

  * 索引条目通常远小于数据行大小，所以如果只需要读取索引，那MySQL 就会极大地减少数据访问量。这对缓存的负载非常重要，因为这种情况下响应时间大部分花费在数据拷贝上。覆盖索引对于I/O 密集型的应用也有帮助，因为索引比数据更小，更容易全部放入内存
  * 因为索引是按照列值顺序存储的（至少在单个页内是如此）， 所以对于I/O 密集型的范围査询会比随机从磁盘读取每一行数据的I/O 要少得多
  * 一些存储引擎如MylSAM 在内存中只缓存索引，数据则依赖于操作系统来缓存，因此要访问数据需要一次系统调用。
  * 由于InnoDB 的聚簇索引，覆盖索引对InnoDB 表特别有用。InnoDB 的二级索引在叶子节点中保存了行的主键值，所以如果二级主键能够覆盖査询，则可以避免对主键索引的二次査询。


<a id="markdown-367-未来的改进56版本索引条件推送" name="367-未来的改进56版本索引条件推送"></a>
## 36.7. 未来的改进(5.6版本索引条件推送)
上面提到的很多限制都是由于存储引擎API 设计所导致的，**目前的API 设计不允
许MySQL 将过滤条件传到存储引擎层**。如果MySQL 在后续版本能够做到这一点，
则可以把查询发送到数据上，而不是像现在这样只能把数据从存储引擎拉到服务器
层，再根据查询条件过滤。在本书写作之际，MySQL 5.6 版本（未正式发布） 包
含了在存储引擎API 上所做的一个重要的改进，其被称为“索引条件推送（i ndex
condition pushdown)”。**这个特性将大大改善现在的查询执行方式，如此一来上面
介绍的很多技巧也就不再需要了。**

<a id="markdown-368-使用索引扫描来做排序" name="368-使用索引扫描来做排序"></a>
## 36.8. 使用索引扫描来做排序
MySQL 可以使用同一个索引既满足排序，又用于査找行。因此，如果可能，设计索引时应该尽可能地同时满足这两种任务，这样是最好的。

如果査询需要关联多张表，则**只有当ORDER BY子句引用的字段全部为第一个表时，才能使用索引做排序**。
ORDER BY子句和查找型査询的限制是一样的：需要满足索引的最左前缀的要求；否则，
MySQL 都需要执行排序操作，而无法利用索引排序。

详细见p175

<a id="markdown-369-压缩前缀压缩索引" name="369-压缩前缀压缩索引"></a>
## 36.9. 压缩（前缀压缩）索引
测试表明，对于CPU 密集型应用，因为扫描需要随机査找，压缩索引使得Myl SAM 在
索引査找上要慢好几倍。压缩索引的倒序扫描就更慢了。压缩索引需要在CPU 内存资源
与磁盘之间做权衡。**压缩索引可能只需要十分之一大小的磁盘空间， 如果是I/O 密集型
应用，对某些査询带来的好处会比成本多很多。**

<a id="markdown-3610-冗余和重复索引" name="3610-冗余和重复索引"></a>
## 36.10. 冗余和重复索引

重复索引  
```
CREATE TABLE test (
ID INT NOT NULL PRIMARY KEY,
A INT NOT NULL,
B INT NOT NULL,
UNIQUE(ID),
INDEX(ID)
) ENGINE=InnoDB;
```

一个经验不足的用户可能是想创建一个主键，先加上唯一限制，然后再加上索引以供査
询使用。**事实上，MySQL 的唯一限制和主键限制都是通过索引实现的**，因此， 上面的
写法实际上在相同的列上创建了三个重复的索引。通常并没有理由这样做，除非是在同
一列上创建不同类型的索引来满足不同的査询需求

冗余索引  
**如果创建了索引（A B), 再创建索引（A) 就是冗余索引，**
因为这只是前一个索引的前缀索引。因此**索引（AB)也可以当作索引（A)** 来使用（ 这种冗
余只是对B-Tree 索引来说的）。**但是如果再创建索引（B，A) , 则不是冗余索引**，索引（B)
也不是，因为B不是索引（A, B) 的最左前缀列。另外，其他不同类型的索引（例如哈希
索引或者全文索引）也不会是B-Tree 索引的冗余索引，而无论覆盖的索引列是什么。

大多数情况下都不需要冗余索引，**应该尽量扩展已有的索引而不是创建新索引**。**但也有
时候出于性能方面的考虑需要冗余索引**，因为扩展已有的索引会导致其变得太大，从而
影响其他使用该索引的査询的性能。


冗余索引的example  

115 QPS
```
SELECT count(*) FROM userinfo WHERE state_id = 5;
```

QPS < 10
```
SELECT state_id, city, address FROM userinfo WHERE state_id = 5;
```

解决方法就是扩展索引
```
ALTER TABLE userinfo DROP KEY state_id,
ADD KEY state_id_2(state_id, city, address);
```

      

未使用的索引  
除了冗余索引和重复索引，可能还会有一些服务器永远不用的索引。这样的索引完全是
累赘，建议考虑删除8。有两个工具可以帮助定位未使用的索引。**最简单有效的办法是
在Percona Server 或者MariaDB 中先打开userstates 服务器变量（默认是关闭的）**，**然
后让服务器正常运行一段时间，再通过査询INF0RMATI0N_SCHEMA. INDEX_STATISTICS 就
能查到每个索引的使用频率。**

另外，还可以使用Percona Toolkit 中的该工具可以读取查询日志， 并
对日志中的每条査询进行EXPLAIN 操作，然后打印出关于索引和査询的报告。**这个工具
不仅可以找出哪些索引是未使用的， 还可以了解査询的执行计划一一例如在某些情况
有些类似的査询的执行方式不一样，**这可以帮助你定位到那些偶尔服务质量差的査询，
优化它们以得到一致的性能表现。该工具也可以将结果写入到MySQL 的表中， 方便査
询结果。

索引和锁  
索引可以让査询锁定更少的行。如果你的査询从不访问那些不需要的行，那么就会锁定
更少的行，从两个方面来看这对性能都有好处。首先，虽然InnoDB 的行锁效率很髙，
内存使用也很少，但是锁定行的时候仍然会带来额外开销.其次，**锁定超过需要的行会
增加锁争用并减少并发性。**

在MySQL 5.1 和更新的版本中, **InnoDB 可以在服务器端过滤掉行后就释放锁**

关于InnoDB、索引和锁有一些很少有人知道的细节：**InnoDB 在二级索引上使用共享
(读）锁**，但**访问主键索引需要排他（写）锁**。这消除了使用覆盖索引的可能性，并且
使得SELECT FOR UPDATE 比LOCK IN SHARE MODE 或非锁定査询要慢很多。

<a id="markdown-37-p192-选择索引时记住三个原则" name="37-p192-选择索引时记住三个原则"></a>
# 37. p192-选择索引时记住三个原则
  * 单行访问是很慢的。特别是在机械硬盘存储中（SSD 的随机I/O 要快很多，不过这一点仍然成立)。如果服务器从存储中读取一个数据块只是为了获取其中一行，那么就浪费了很多工作。最好读取的块中能包含尽可能多所需要的行。使用索引可以创建位置引用以提升效率。

  * 按顺序访问范围数据是很快的，这有两个原因。第一，顺序I/O 不需要多次磁盘寻道，所以比随机I/O 要快很多（特别是对机械硬盘）。第二，如果服务器能够按需要顺序读取数据，那么就不再需要额外的排序操作，并且GROUP BY査询也无须再做排序和将行按组进行聚合计算了。

  * 索引覆盖査询是很快的。如果一个索引包含了査询需要的所有列，那么存储引擎就不需要再回表査找行。这避免了大量的单行访问，而上面的第1 点已经写明单行访问是很慢的。

总的来说，编写査询语句时应该尽可能选择合适的索引以避免单行査找、尽可能地使用
数据原生顺序从而避免额外的排序操作，并尽可能使用索引覆盖査询。这与本章开头提
到的Lahdemnaki 和Leach 的书中的“三星”评价系统是一致的。

那如何判断一个系统创建的索引是合理的呢？一般来说，**我们建议按响应时间来对査询
进行分析。找出那些消耗最长时间的査询或者那些给服务器带来最大压力的査询**（第3
章中介绍了如何测量）， 然后检査这些査询的schema、SQL 和索引结构，判断是否有查
询扫描了太多的行，是否做了很多额外的排序或者使用了临时表，是否使用随机I/O 访
问数据，或者是有太多回表査询那些不在索引中的列的操作。

<a id="markdown-38-p198-简单的衡量查询开销的三个指标" name="38-p198-简单的衡量查询开销的三个指标"></a>
# 38. p198-简单的衡量查询开销的三个指标
  * 响应时间
  * 扫描的行数
  * 返回的行数

响应时间  
响应时间是两个部分之和：**服务时间和排队时间**。服务时间是指数据库处理这个査询
真正花了多长时间。排队时间是指服务器因为等待某些资源而没有真正执行査询的时
间——可能是等I/O 操作完成，也可能是等待行锁

当你看到一个査询的响应时间的时候**，首先需要问问自己，这个响应时间是否是一个
合理的值**。实际上可以使用“快速上限估计”法来估算査询的响应时间，这是由TapioLahdenmaki
 和Mike Leach 编写的一书提到的技术，限于篇幅，在这里不会详细展开。概括地说，了解这
个査询需要哪些索引以及它的执行计划是什么，然后计算大概需要多少个顺序和随机I/O,
再用其乘以在具体硬件条件下一次I/O 的消耗时间。最后把这些消耗都加起来，就可以
获得一个大概参考值来判断当前响应时间是不是一个合理的值。


扫描的行数和返回的行数  
理想情况下扫描的行数和返回的行数应该是相同的。但实际情况中这种“美事”并不多。
例如在做一个关联査询时，服务器必须要扫描多行才能生成结果集中的一行。扫描的行
数对返回的行数的比率通常很小，一般在1:1 和10:1 之间，不过有时候这个值也可能非
常非常大。

扫描的行数和访问类型  
在EXPLAIN语句中的type 列反应了访问类型。访问类型有很多种， 从全表扫描到索引扫
描、范围扫描、唯一索引査询、常数引用等。这里列的这些，速度是从慢到快，扫描的
行数也是从小到大。你不需要记住这些访问类型，但**需要明白扫描表、扫描索引、范围
访问和单值访问的概念。**

如果査询没有办法找到合适的访问类型，那么解决的**最好办法通常就是增加一个合适的
索引，这也正是我们前一章讨论过的问题**。现在应该明白为什么索引对于査询优化如此
重要了。索引让MySQL 以最髙效、扫描行数最少的方式找到需要的记录。

<a id="markdown-39-p204-mysql请求应答的流程" name="39-p204-mysql请求应答的流程"></a>
# 39. p204-mysql请求应答的流程

客户端 -> 查询缓存 -> 解析器 -> 解析树 -> 预处理器 -> 查询优化器 -> 查询执行计划 -> 查询执行引擎 -> 存储引擎 -> 数据


  - 客户端发送一条查询给服务器
  - 服务器先检查查询缓存,如果命中了缓存,则立刻返回存储在缓存中的结果,否则进入下一阶段
  - 服务器端进行SQL 解析、预处理，再由优化器生成对应的执行计划
  - MySQL 根据优化器生成的执行计划，调用存储引擎的API 来执行査询
  - 将结果返回给客户

上面的每一步都比相像的要复杂.

<a id="markdown-40-p207-查询状态" name="40-p207-查询状态"></a>
# 40. p207-查询状态

Sleep  
线程正在等待客户端发送新的请求。

Query  
线程正在执行査询或者正在将结果发送给客户端。

Locked  
在MySQL 服务器层，该线程正在等待表锁。在存储引擎级别实现的锁，例如
InnoDB 的行锁，并不会体现在线程状态中。对于MylSAM 来说这是一个比较典型
的状态，但在其他没有行锁的引擎中也经常会出现。

Analyzing and statistics  
线程正在收集存储引擎的统计信息，并生成査询的执行计划。

Copying to tmp table [on disk]  
线程正在执行査询，并且将其结果集都复制到一个临时表中，这种状态一般要么是
在做GROUP BY 操作，要么是文件排序操作，或者是UNION 操作。如果这个状态后面
还有“on disk”标记，那表示MySQL 正在将一个内存临时表放到磁盘上。

Sorting result  
线程正在对结果集进行排序。

Sending data  
这表示多种情况：线程可能在多个状态之间传送数据，或者在生成结果集， 或者在向客户端返回数据。


<a id="markdown-41-p259-分区表" name="41-p259-分区表"></a>
# 41. p259-分区表
**分区的一个主要目的是将数据按照一个较粗的粒度分在不同的表中**。这样做可以将相关
的数据存放在一起，另外，如果想一次批量删除整个分区的数据也会变得很方便。

  * 表非常大以至于无法全部都放在内存中，或者只在表的最后部分有热点数据，其他均是历史数据。
  * 分区表的数据更容易维护。例如，想批量删除大量数据可以使用清除整个分区的方式。另外，还可以对一个独立分区进行优化、检査、修复等操作。
  * 分区表的数据可以分布在不同的物理设备上，从而高效地利用多个硬件设备。
  * 可以使用分区表来避免某些特殊的瓶颈，例如InnoD B 的单个索引的互斥访问、ext3文件系统的inode 锁竞争等。
  * 如果需要，还可以备份和恢复独立的分区，这在非常大的数据集的场景下效果非常好。

分区重要的特点  
  * 一个表最多只能有1024 个分区。
  * 在MySQL 5.1 中，分区表达式必须是整数，或者是返回整数的表达式。在MySQL 5.5中，某些场景中可以直接使用列来进行分区。
  * 如果分区字段中有主键或者唯一索引的列，那么所有主键列和唯一索引列都必须包含进来。
  * 分区表中无法使用外键约束。

分区表的原理  

SELECT 查询  
当査询一个分区表的时候，分区层先打开并锁住所有的底层表，优化器先判断是否
可以过滤部分分区，然后再调用对应的存储引擎接口访问各个分区的数据。

INSERT 操作  
当写入一条记录时，分区层先打开并锁住所有的底层表，然后确定哪个分区接收这条记录，再记录写入对应底层表。

DELETE 操作  
当删除一条记录时，分区层先打儿并锁住所有的底层表，然后确定数据对应的分区，最后对相应底层表进行删除操作。

UPDATE 操作  
当更新一条记录时，分区层先打开并锁住所有的底层表，MySQL 先确定需要更新的记录在哪个分区，然后取出数据并更新，再判断更新后昀数据应该放在哪个分区，最后对底层表进行写入操作，并对原数据所在的底层表进行删除操作。

其他分区技术包括  
  * 根据键值进行分区，来减少InnoDB 的互斥量竞争。
  * 使用数学模函数来进行分区，然后将数据轮询放人不同的分区。例如，可以对日期做模7 的运算，或者更简单地使用返回周几的函数，如果只想保留最近几天的数据，这样分区很方便。
  * 假设表有一个自增的主键列id, 希望根据时间将最近的热点数据集中存放。& 么必须将时间戳包含在主键当中才行，而这和主键本身的意义相矛盾。这种情况下也可以使用这样的分区表达式来实现相同的目的：HASH(id DIV 1000000), 这将为100
万数据建立一个分区。这样一方面实现了当初的分区目的，另一方面比起使用时间范围分区还避免了一个问题，就是当超过一定阈值时，如果使用时间范围分区就必须新增分区。

分区表的一个example  
假设我们希望从一个非常大的表中査询出一段时间的记录，而这个表中包含了很多年的
历史数据，数据是按照时间排序的，例如，希望査询最近几个月的数据，这大约有10 亿
条记录。可能过些年本书会过时，不过我们还是假设使用的是2012 年的硬件设备，**而
原表中有10TB 的数据，这个数据量远大于内存，并且使用的是传统硬盘，不是闪存（多
数SSD 也没有这么大的空间）**。**你打算如何査询这个表？如何才能更髙效？**

因为数据量巨大，**肯定不能在每次査询的时候都扫描全表**。考虑到索引在
空间和维护上的消耗，也不希望使用索引。**即使真的使用索引，你会发现数据并不是按
照想要的方式聚集的，而且会有大量的碎片产生，最终会导致一个査询产生成千上万的
随机I/O, 应用程序也随之僵死。**情况好一点的时候，也许可以通过一两个索引解决一
些问题。不过多数情况下，索引不会有任何作用。

这时候只有两条路可选：让所有的査询都只在数据表上做顺序扫描，或者将数据表和索引全部都缓存在内存里。

这里需要再陈述一遍：**在数据量超大的时候，B-Tree 索引就无法起作用了。**除非是索
引覆盖査询，否则数据库服务器需要根据索引扫描的结果回表，査询所有符合条件的
记录，如果数据量巨大，这将产生大量随机I/O.

为了保证大数据量的可扩展性， 一般有下面两个策略：

全量扫描数据不要任何索引 

可以使用简单的分区方式存放表，不要任何索引，根据分区的规则大致定位需要的
数据位置。**只要能够使用WHERE条件，将需要的数据限制在少数分区中，则效率是
很高的。**

索引数据,并分离热点  

如果数据有明显的"热点",而且除了这部分数据，其他数据很少被访问到，那么可
以将这部分热点数据单独放在一个分区中，让这个分区的数据能够有机会都缓存在
内存中。**这样査询就可以只访问一个很小的分区表，能够使用索引，也能够有效地
使用缓存。**

分区实现中的一些其他的限制  
  * 所有分区都必须使用相同的存储引擎
  * 分区函数中可以使用的函数和表达式也有一些限制。
  * 某些存储引擎不支持分区
  * 对于MylSAM 的分区表，不能再使用LOAD INDEX INTO CACHE 操作。
  * 对于Myl SAM 表，使用分区表时需要打开更多的文件描述符。虽然看起来是一个表，其实背后有很多独立的分区， 每一个分区对于存储引擎来说都是一个独立的表。这样即使分区表只占用一个表缓存条目，文件描述符还是需要多个。

<a id="markdown-42-p270-视图" name="42-p270-视图"></a>
# 42. p270-视图
MySQL 5.0 版本之后开始引入视图。**视图本身是一个虚拟表，不存放任何数据。在使用
SQL 语句访问视图的时候，它返回的数据是MySQL 从其他表中生成的。**视图和表是在
同一个命名空间，MySQL 在很多地方对于视图和表是同样对待的。不过视图和表也有
不同，例如，不能对视图创建触发器，也不能使用DROP TABLE命令删除视图。

视图对于性能的影响  
多数人认为视图不能提升性能，实际上，在MySQL 中某些情况下视图也可以帮助提升
性能。**而且视图还可以和其他提升性能的方式叠加使用。**例如， 在重构schema 的时候
可以使用视图，使得在修改视图底层表结构的时候，应用代码还可能继续不报错的运行。

并不总是优化的实现  
我们看到过这样的案例，**复杂的视图和高并发的査
询导致査询优化器花了大量时间在执行计划生成和统计数据阶段，这甚至会导致MySQL
服务器僵死**，后来通过将视图转换成等价的査询语句解决了问题。这也说明视图—— 即
使是使用合并算法实现的——并不总是有很优化的实现。


<a id="markdown-43-p275-外键约束" name="43-p275-外键约束"></a>
# 43. p275-外键约束
**IrmoDB 是目前MySQL 中唯一支持外键的内置存储引擎**，所以如果需要外键支持那选择就不多了（PBXT 也有外键支持）。

不过，在某些场景下，外键会提升一些性能。**如果想确保两个相关表始终有一致的数据,
那么使用外键比在应用程序中检査一致性的性能要髙得多**，此外，外键在相关数据的删
除和更新上，也比在应用中维护要更高效，不过，外键维护操作是逐行进行的，所以这
样的更新会比批量删除和更新要慢些。

外键约束使得査询需要额外访问一些别的表，这也意味着需要额外的锁。如果向子表中
写入一条记录，**外键约束会让InnoDB 检査对应的父表的记录**，也就需要对父表对应记
录进行加锁操作，来确保这条记录不会在这个事务完成之时就被删除了。这会导致额外
的锁等待，甚至会导致一些死锁。因为没有直接访问这些表，所以这类死锁问题往往难
以排査。

外键的性能消耗  
**如果只是使用外键做约束，那通常在应用程序里实现该约束会更好**。**外键会带来很大的
额外消耗。**这里没有相关的基准测试的数据，不过我们碰到过很多案例， 在对性能进行
剖析时发现外键约束就是瓶颈所在,**删除外键后性能立即大幅提升。**


<a id="markdown-44-p276-在mysql内部存储代码" name="44-p276-在mysql内部存储代码"></a>
# 44. p276-在MySQL内部存储代码
MySQL 允许通过**触发器**、**存储过程**、**函数**的形式来存储代码,还可以在定时任务中存放代码，这个定时任务也被称为“事件”。存储过程和存储函数都被统称为“存储程序”。

因为**不同的关系数据库都有各自的语法规则**，所以不同的数据库很难复用这些存储代码（DB2 是一个例外，它和MySQL 基于相同的标准，有着非常类似的语法）

存储代码的优点  
  * 它在服务器内部执行，离数据最近，另外在服务器上执行还可以节省带宽和网络延迟。
  * 这是一种代码重用。可以方便地统一业务规则，保证某些行为总是一致，所以也可以为应用提供一定的安全性。
  * 它可以简化代码的维护和版本更新。
  * 它可以帮助提升安全，比如提供更细粒度的权限控制。一个常见的例子是银行用于转移资金的存储过程：这个存储过程可以在一个事务中完成资金转移和记录用于审计的日志。应用程序也可以通过存储过程的接口访问那些没有权限的表。
  * 服务器端可以缓存存储过程的执行计划，这对于需要反复调用的过程，会大大降低消耗。
  * 因为是在服务器端部署的，所以备份、维护都可以在服务器端完成。所以存储程序的维护工作会很简单。它没什么外部依赖，例如，不依赖任何Perl 包和其他不想在服务器上部署的外部软件。
  * 它可以在应用开发和数据库开发人员之间更好地分工。不过最好是由数据库专家来开发存储过程，因为**不是每个应用开发人员都能写出高效的SQL 査询**。

存储代码的缺点  
  * MySQL 本身没有提供好用的开发和调试工具，所以编写MySQL 的存储代码比其他的数据库要更难些。
  * 较之应用程序的代码，存储代码效率要稍微差些。例如，存储代码中可以使用的函数非常有限，所以使用存储代码很难编写复杂的字符串维护功能，也**很难实现太复杂的逻辑**。
  * 存储代码可能会给应用程序代码的部署带来**额外的复杂性**。原本只需要部署应用代码和库表结构变更，现在还需要额外地部署MySQL 内部的存储代码
  * 因为存储程序都部署在服务器内，所以可能有安全隐患。如果将非标准的加密功能放在存储程序中，那么若数据库被攻破，数据也就泄漏了。但是若将加密函数放在应用程序代码中，那么攻击者必须同时攻破程序和数据库才能获得数据
  * 存储过程会给数据库服务器增加额外的压力，而数据库服务器的扩展性相比应用服务器要差很多
  * MySQL 并没有什么选项可以控制存储程序的资源消耗，所以在存储过程中的一个小错误，可能直接把服务器拖死
  * 存储代码在MySQL 中的实现也有很多限制——执行计划缓存是连接级别的，游标的物化和临时表相同，在MySQL 5.5 版本之前，异常处理也非常困难，等等。（我<1D们会在介绍它的各个特性的同时介绍相关的限制）。简而言之，较之T-SQL 或者PL/
SQL, MySQL 的存储代码功能还非常非常弱

  * 调试MySQL 的存储过程是一件很困难的事情。如果慢日志只是给出CALL XYZ(_A_) ，通常很难定位到底是什么导致的问题，这时不得不看看存储过程中的SQL 语句是如何编写的。（这在Percona Server 中可以通过参数控制。）
  * 它和基于语句的二进制日志复制合作得并不好。在基于语句的复制中，使用存储代码通常有很多的陷阱，除非你在这方面的经验非常丰富或者非常有耐心排査这类问题，否则需要谨慎使用

使用存储代码时要问问自己  
最后，存储代码是一种帮助应用隐藏复杂性，使得应用开发更简单的方法。不过，**它的
性能可能更低，而且会给MySQL 的复制等增加潜在的风险**。所以当你打算使用存储过
程的时候，需要问问自己，到底希望程序逻辑在哪儿实现:是数据库中还是应用代码中？
这两种做法都可以，也都很流行。**只是当你编写存储代码的时候，你需要明白这是将程
序逻辑放在数据库中。**

存储过程的example  
我们通常会希望**存储程序越小、越简单越好**。**希望将更加复杂的处理逻辑交给上层的应
用实现**，通常这样会使代码更易读、易维护，也会更灵活。这样做也会让你拥有更多的
计算资源，潜在的还会让你拥有更多的缓存资源

不过，**对于某些操作，存储过程比其他的实现要快得多——特别是当一个存储过程调用
可以代替很多小査询的时候**。如果査询很小，相比这个査询执行的成本， 解析和网络开
销就变得非常明显。

写入一百万数据所花费的总时间  


写入方式 | 总消耗时间 
 -|-
存储过程 | 101sec 
客户端程序 | 279sec 
使用MySQL Proxy的客户端程序 | 307sec 

可以看到存储过程要快很多，很大程度因为**它无须网络通信开销、解析开销和优化器开销等。**


触发器  
触发器可以让你在执行**INSERT、UPDATE或者DELETE**的时候，执行一些特定的操作

触发器可以简化应用逻辑，还可以提髙性能。另外，还可以用于自动更新反范式化数据或者汇总表数据。例如，在示例数据库Sakila 中，我们可以使用触发器来维护film_tex t 表。

MySQL 触发器的实现非常简单，所以功能也有限。如果你在其他数据库产品中已经重
度依赖触发器，那么在使用MySQL 的时候需要注意，很多时候MySQL 触发器的表现
和预想的并不一样。特别需要注意以下几点：

  * 对每一个表的每一个事件，最多只能定义一个触发器（换句话说，不能在AFTERINSERT 上定义两个触发器） 
  * MySQL 只支持“基于行的触发”——也就是说，触发器始终是针对一条记录的，而不是针对整个SQL 语句的。如果变更的数据集非常大的话，效率会很低

触发器本身的限制  
  * 触发器可以掩盖服务器背后的工作，一个简单的SQL 语句背后，因为触发器，可能包含了很多看不见的工作。例如，触发器可能会更新另一个相关表， 那么这个触发器会让这条SQL 影响的记录数翻一倍
  * 触发器的问题也很难排査，如果某个性能问题和触发器相关，会很难分析和定位
  * 触发器可能导致死锁和锁等待。如果触发器失败，那么原来的SQL 语句也会失败。如果没有意识到这其中是触发器在搞鬼，那么很难理解服务器抛出的错误代码是什么意思

事件  
指定MySQL 在某个时候执行一段SQL 代码，或者毎隔一个时间间隔执行一段SQL 代码。通常，我们会把复杂的SQL 都封装到一个存储过程中，这样事件在执行的时候只需要做一个简单的CALL调用

事件的缺点  
类似的，一些适用于存储过程的考虑也同样适用于事件。首先，**创建事件意味着给服务
器带来额外工作。**事件实现机制本身的开销并不大，但是事件需要执行SQL, 则可能会
对性能有很大的影响。更进一步，事件和其他的存储程序一样，在和基于语句的复制一
起工作时，也可能会触发同样的问题。事件的一些典型应用包括定期地维护任务、重建
缓存、构建汇总表来模拟物化视图，或者存储用于监控和诊断的状态值

当前事件还未结束,下一个事件又开始了  
最后，如果一个定时事件执行需要很长的时间，那么有可能会出现这样的情况，即前面
一个事件还未执行完成，下一个时间点的事件又开始了。MySQL 本身不会防止这种并发，
所以需要用户自己编写这种情况下的防并发代码。你可以使用函数GET_L0CK() 来确保当
前总是只有一个事件在被执行

<a id="markdown-45-p283-游标" name="45-p283-游标"></a>
# 45. p283-游标
MySQL 在服务器端提供只读的、单向的游标，而且只能在存储过程或者更底层的客户
端API 中使用。因为MySQL 游标中指向的对象都是存储在临时表中而不是实际査询到
的数据，**所以MySQL 游标总是只读的。它可以逐行指向査询结果，**然后让程序做进一
步的处理。在一个存储过程中，可以有多个游标，也可以在循环中“嵌套”地使用游标。

这个案例告诉我们，如果在关闭游标的时候你只是扫描一个大结果集的一小部分，那么
存储过程可能不仅没有减少开销，相反带来了大量的额外开销。这时，你需要考虑使用
LIMIT来限制返回的结果集。

**游标也会让MySQL 执行一些额外的I/O 操作，而这些操作的效率可能非常低。**因为临
时内存表不支持BLOB和TEXT 类型，如果游标返回的结果包含这样的列的话， MySQL
就必须创建临时磁盘表来存放，这样性能可能会很糟。即使没有这样的列，当临时表大
于tmp_table_size 的时候， MyQL 也还是会在磁盘上创建临时表。

<a id="markdown-46-p284-绑定变量" name="46-p284-绑定变量"></a>
# 46. p284-绑定变量

因为如下的原因，MySQL 在使用绑定变量的时候可以更髙效地执行大量的重复语句

  * 在服务器端只需要解析一次SQL 语句
  * 在服务器端某些优化器的工作只需要执行一次，因为它会缓存一部分的执行计划。
  * 以二进制的方式只发送参数和句柄，比起毎次都发送ASCII 码文本效率更高，一个二进制的日期字段只需要三个字节，但如果是ASCII 码则需要十个字节。不过最大的节省还是来自于BLOB和TEXT字段，绑定变量的形式可以分块传输，而无须一次性传输。二进制协议在客户端也可能节省很多内存，减少了网络开销，另外，还节省了将数据从存储原始格式转换成文本格式的开销。
  * 仅仅是参数——而不是整个査询语句——需要发送到服务器端，所以网络开销会更小。
  * MySQL 在存储参数的时候，直接将其存放到缓存中，不再需要在内存中多次复制。

绑定变量相对也更安全。无须在应用程序中处理转义，一则更简单了，二则也**大大减少
了SQL 注入和攻击的风险**。（任何时候都不要信任用户输入，即使是使用绑定变量的时
候


绑定会话的限制  
  * 绑定变量是会话级别的，所以连接之间不能共用绑定变量句柄。同样地， 一旦连接断开，则原来的句柄也不能再使用了。（连接池和持久化连接可以在一定程度上缓解这个问题
  * 在MySQL 5.1 版本之前，绑定变量的SQL 是不能使用査询缓存的
  * 并不是所有的时候使用绑定变量都能获得更好的性能。如果只是执行一次SQL，那m> 么使用绑定变量方式无疑比直接执行多了一次额外的准备阶段消耗，而且还需要一次额外的网络开销
  * 当前版本下，还不能在存储函数中使用绑定变量（但是存储过程中可以使用）
  * 如果总是忘记释放绑定变量资源，则在服务器端很容易发生资源“泄漏”。绑定变量SQL 总数的限制是一个全琴限制， 所以某一个地方的错误可能会对所有其他的线程都产生影响
  * 有些操作，如BEGIN, 无法在绑定变量中完成。

<a id="markdown-47-p309-查询缓存" name="47-p309-查询缓存"></a>
# 47. p309-查询缓存
MySQL査询缓存保存査询返回的完整结果。当査询命中该缓存，MySQL会立刻返回结果，跳过了解析、优化和执行阶段。


査询缓存对应用程序是完全透明的。应用程序无须关心MySQL 是通过査询缓存返回的
结果还是实际执行返回的结果。事实上，这两种方式执行的结果是完全相同的。换句话说，
査询缓存无须使用任何语法。无论是MySQL 开启或关闭査询缓存，对应用程序都是**透
明**的.

<a id="markdown-48-p321-特性总结" name="48-p321-特性总结"></a>
# 48. p321-特性总结

<a id="markdown-481-分区表" name="481-分区表"></a>
## 48.1. 分区表
**分区表是一种粗粒度的、简易的索引策略，适用于大数据量的过滤场景**。最适合的
场景是，在没有合适的索引时，对其中几个分区进行全表扫描，或者是只有一个分
区和索引是热点，而且这个分区和索引能够都在内存中；限制单表分区数不要超过
150 个，并且注意某些导致无法做分区过滤的细节，分区表对于单条记录的查询并
没有什么优势， 需要注意这类査询的性能。

<a id="markdown-482-视图" name="482-视图"></a>
## 48.2. 视图
对好几个表的复杂査询，使用视图有时候会大大简化问题。当视图使用临时表时，
无法将WHERE 条件下推到各个具体的表，也不能使用任何索引，需要特别注意这类
査询的性能。**如果为了便利，使用视图是很合适的。**


<a id="markdown-483-外键" name="483-外键"></a>
## 48.3. 外键
外键限制会将约束放到MySQL 中，这对于必须维护外键的场景，性能会更高。不
过这也会**带来额外的复杂性和额外的索引消耗**，还会**增加多表之间的交互**，会**导致
系统中更多的锁和竞争**。**外键可以被看作是一个确保系统完整性的额外的特性，但
是如果设计的是一个高性能的系统，那么外键就显得很臃肿了**。很多人在更在意系
统的性能的时候都不会使用外键，而是通过应用程序来维护。


<a id="markdown-484-存储过程" name="484-存储过程"></a>
## 48.4. 存储过程
MySQL 本身实现了**存储过程、触发器、存储函数和事件**，老实说，这些特性并没什
么特别的。而且对于基于语句的复制还有很多问题。通常，使用这些特性可以帮你
**节省很多的网络开销——很多情况下，减少网络开销可以大大提升系统的性能**。在
某些经典的场景下你可以使用这些特性(例如中心化业务逻辑、绕过权限系统，等等），
但需要注意在MySQL 中，**这些特性并没有别的数据库系统那么成熟和全面**

<a id="markdown-485-绑定变量" name="485-绑定变量"></a>
## 48.5. 绑定变量
**当査询语句的解析和执行计划生成消耗了主要的时间，那么绑定变量可以在一定程
度上解决问题**。因为只需要解析一次，对于大量重复类型的査询语句，性能会有很
大的提高。另外，执行计划的缓存和传输使用的二进制协议，这都使得绑定变量的
方式比普通SQL 语句执行的方式要更快。

<a id="markdown-486-插件" name="486-插件"></a>
## 48.6. 插件
使用C 或者C+ + 编写的插件可以让你最大程度地扩展MySQL 功能。插件功能非常
强大，我们已经编写了很多UDF 和插件，在MySQL 中解决了很多问题。

<a id="markdown-487-字符集" name="487-字符集"></a>
## 48.7. 字符集
字符集是一种字节到字符之间的映射，而校对规则是指一个字符集的排序方法。很
多人都使用Latinl (默认字符集，对英语和某些欧洲语言有效）或者UTF-8。如**果
使用的是UTF- 8, 那么在使用临时表和缓冲区的时候需要注意：MySQL 会按照每个
字符三个字节的最大占用空间来分配存储空间，这可能消耗更多的内存或者磁盘空
间。**注意让字符集和MySQL 字符集配置相符，否则可能会由于字符集转换让某些
索引无法正常使用。


<a id="markdown-488-全文索引" name="488-全文索引"></a>
## 48.8. 全文索引
在本书编写的时候只有MylSAM 支持全文索引，**不过据说从MySQL 5.6 开始，
InnoDB 也将支持全文索引。**MylSAM 因为在锁粒度和崩溃恢复上的缺点， 使得在
大型全文索引场景中基本无法使用。这时，我们通常帮助客户构建和使用Sphinx 来
解决全文索引的问题。

<a id="markdown-489-xa-事务" name="489-xa-事务"></a>
## 48.9. XA 事务
很少有人用MySQL 的XA 事务特性。除非你真正明白参数innodb_support_xa的
意义，否则不要修改这个参数的值，并不是只有显式使用XA 事务时才需要设置这
个参数。InnoDB 和二进制日志也是需要使用XA 事务来做协调的，从而确保在系统
崩溃的时候，数据能够一致地恢复。

<a id="markdown-4810-查询缓存" name="4810-查询缓存"></a>
## 48.10. 查询缓存
完全相同的查询在重复执行的时候，査询缓存可以立即返回结果，而无须在数据库
中重新执行一次。根据我们的经验，在高并发压力环境中査询缓存会导致系统性
能的下降，甚至僵死。**如果你一定要使用査询缓存，那么不要设置太大内存，而且
只有在明确收益的时候才使用。**

对应用程序完全透明， 无须任何额外的编码，但是，如果希望有更高的缓存效率，**我们建议使用
memcached 或者其他类似的解决方案**

<a id="markdown-49-p331-mysql配置入门" name="49-p331-mysql配置入门"></a>
# 49. p331-MySQL配置入门
**是把配置文件置于版本控制之下**。无论如何，这是一个很好的做法，因
为它让你有机会撤销变更。要降低管理很多配置文件的复杂性，简单地创建一个从配置
文件到中央版本控制库的符号链接。


你也许期望（或者相信自己会期望）通过建立一套基准测试方案，** 然后不断迭代地验证
对配置项的修改来找到最佳配置方案。通常我们都不建议大家这么做**。这需要做非常多
的工作和研究，并且大部分情况下潜在的收益是非常小的，这可能导致巨大的时间浪费。
而把**时间花在检査备份、监控执行计划的变动之类的事情上，可能会更有意义**


**MySQL 编译的默认设置并不都是靠谱的，虽然其中大部分都比较合适。它们被设计成
不要使用大量的资源，因为MySQL 的使用目标是非常灵活的，**它并没有假设自己是服
务器上唯一的应用。默认情况下， MySQL 只是使用恰好足够的资源来启动，运行一些
少量数据的简单査询。如果有超过几MB 的数据，就一定会需要自己定制MySQL 配置。

这就是本章要做的事情。**实际上MySQL 的可配置性太强也可以说是个弱点**，看起来好
像需要花很多时间在配置上，其实大多数配置的默认值已经是最佳配置了，所以最好不
要改动太多配置，甚至可以忘记某些配置的存在。这就是为什么我们为本书创建了一个
完整的最小的示例配置文件，可以作为自己的服务器配置文件的一个好的起点。有一些
配置项是必选的

我们建议，当配置内存缓冲区的时候，宁可谨慎，而不是把它们配置得过大。如果把缓
冲池配置得比它可以设的值少了20% , 很可能只会对性能产生小的影响，也许就只影响
[W> 几个百分点。**如果设置得大了20% , 则可能会造成更严重的问题：内存交换、磁盘抖动,
甚至内存耗尽和硬件死机。**

<a id="markdown-50-p349-配置mysql-的io-行为" name="50-p349-配置mysql-的io-行为"></a>
# 50. p349-配置MySQL 的I/O 行为
有一些配置项影响着MySQL 怎样同步数据到磁盘以及如何做恢复操作。这些操作对性
能的影响非常大，因为都涉及到昂贵的I/O 操作。它们也表现了性能和数据安全之间的
权衡。通常，**保证数据立刻并且一致地写到磁盘是很昂贵的。如果能够冒一点磁盘写可
能没有真正持久化到磁盘的风险，就可以增加并发性和减少I/O 等待**，但是必须决定可
以容忍多大的风险。

<a id="markdown-51-p350-innodb事务日志" name="51-p350-innodb事务日志"></a>
# 51. p350-InnoDB事务日志
IrnioDB 使用日志来减少提交事务时的开销**。因为日志中已经记录了事务，就无须在每
个事务提交时把缓冲池的脏块刷新（flush) 到磁盘中。**事务修改的数据和索引通常会映
射到表空间的随机位置，所以刷新这些变更到磁盘需要很多随机I/O。InnoDB 假设**使用
的是常规磁盘（机械磁盘）， 随机I/O 比顺序I/O 要昂贵得多，因为一个I/O 请求需要时
间把磁头移到正确的位置，然后等待磁盘上读出需要的部分，再转到开始位置。**

**InnoDB 用日志把随机I/O 变成顺序I/O。** **一旦日志安全写到磁盘，事务就持久化了**，即
使变更还没写到数据文件。如果一些糟糕的事情发生了（例如断电了）， InnoDB 可以重
放日志并且恢复已经提交的事务

innodb_flush_log_at_trx_commit  
控制日志缓冲刷新的频繁程度

级别|说明
-|-
 0  | 把日志缓冲写到日志文件，并且每秒钟刷新一次，但是事务提交时不做任何事。                                                                                                      
 1  | 将日志缓冲写到日志文件，并且每次事务提交都刷新到持久化存储。这是默认的（并 且是最安全的） 设置，该设置能保证不会丢失任何已经提交的事务，除非磁盘或者 操作系统是“伪”刷新
 2  | 每次提交时把日志缓冲写到日志文件，但是并不刷新。InnoDB 每秒钟做一次刷新。 0 与2 最重要的不同是（也是为什么2 是更合适的设置）， 如果MySQL 进程“挂了”， 2 不会丢失任何事务。如果整个服务器“挂了”或者断电了，还是可能会丢失一 些事务。  

了解清楚“把日志缓冲写到日志文件”和“把日志刷新到持久化存储”之间的不同是很
重要的。**在大部分操作系统中，把缓冲写到日志只是简单地把数据从InnoDB 的内存缓
冲转移到了操作系统的缓存**，也是在内存里，并没有真的把数据写到了持久化存储。

因此，如果MySQL 崩溃了或者电源断电了，**设置0 和2 通常会导致最多一秒的数据丢失**，
因为数据可能只存在于操作系统的缓存。我们说“通常”， 因为不论如何InnoDB 会每秒
尝试刷新日志文件到磁盘，但是在一些场景下也可能丢失超过1 秒的事务，例如当刷新
被推迟了。

当innodb_flush_log_at_trx_commit被设置为1 时，可能明显地降
低InnoDB 毎秒可以提交的事务数。**今天的高速驱动器可能毎秒只能执行一两百个磁
盘事务， 受限于磁盘旋转速度和寻道时间。**

高性能事务处理需要的最佳配置是把**innodb_flush_log_at_trx_commit设置为1 且把日
志文件放到一个有电池保护的写缓存的RAID 卷中**。这兼顾了安全和速度。事实上，我
们敢说任何希望能扛过髙负荷工作负载的产品数据库服务器，都需要有这种类型的硬件。

<a id="markdown-52-p367-innodb表空间" name="52-p367-innodb表空间"></a>
# 52. p367-InnoDB表空间
InnoDB 把数据保存在表空间内，**本质上是一个由一个或多个磁盘文件组成的虚拟文件
系统。**InnoDB 用表空间实现很多功能，并不只是存储表和索引。它还保存了**回滚日志（旧
版本行)、插入缓冲（Insert Buffer)、双写缓冲（Doublewrite Buffer)**, 后面的章节里就会
描述）， 以及其他内部数据结构。

<a id="markdown-53-p369-基本配置" name="53-p369-基本配置"></a>
# 53. p369-基本配置

配置|说明
-|-
 tmp_table_size和max_heap_table_size  | 这两个设置控制使用Memory 引擎的内存临时表能使用多大的内存                                                                                                  
 max_connections                     | 若认为正常情况将有300 或者更多连接，则可以设置为500 或者更多。如果不知道将会有多少连接， 500 也不是一个不合理 的起点。默认值是100 , 对大部分应用来说这都不够           
 thread_cache_size                   | 若Threads_connected 状态从150 变化到175, 可以设置线程 缓存为75。但是也不用设置得非常大，因为保持大量等待连接的空闲线程并没有什 么真正的用处。250 的上限是个不错的估算值
 table_cache_size                    | 这个缓存（ 或者在MySQL 5.1 中被分成两个缓存区） 应该被设置得足够大，以避 免总是需要重新打开和重新解析表的定义首先，MySQL 没有一个很有效的方法来检査缓存， 所以如果真的太大了，可能效率 会下降。在大部分情况下，不应该把它设置得大于10 000, 或者是10 240, 如果喜 欢使用2 的# 次方的话


<a id="markdown-54-p371-安全和稳定的设置" name="54-p371-安全和稳定的设置"></a>
# 54. p371-安全和稳定的设置
配置|说明
-|-
 expire_logs_days                                     | 如果启用了二进制日志，应该打开这个选项，可以让服务器在指定的天数之后清理 旧的二进制日志。如果不启用， 最终服务器的空间会被耗尽，导致服务器卡住或崩溃。 我们建议把这个选项设置得足够从两个备份之前恢复( 在最近的备份失败的情况下） 。 即使每天都做备份，还是建议留下7 ~ 14 天的二进制日志
 max_allowed_packet                                   | 这个设置防止服务器发送太大的包，也会控制多大的包可以被接收。默认值可能太 小了，但设置得太大也可能有危险。如果设置得太小，有时复制上会出问题，通常 表现为备库不能接收主库发过来的复制数据。你也许需要增加这个设置到16MB 或 者更大。  
 max_connect_errors                                   | 如果知道服务器可以充分抵御蛮力攻击，可以把这个值设得非常大， 以有效地禁用主机黑名单     
 skip_name_resolve                                    | 我们强烈建议设置这个选项，在验证时关闭DNS査找。
 sql_mode                                             | 我们不建议只是为了好玩而改变这个值最好在大多数情况下让MySQL 像MySQL, 不要尝试让它的行为像其他 数据库服务器
 sysdate_is_now                                       | 这是另一个可能导致与应用预期向后不兼容的选项
 read_only                                            | 这个选项禁止没有特权的用户在备库做变更，只接受从主库传输过来的变更，不接 受从应用来的变更。我们强烈建议把备库设置为只读模式。
 skip_slave_start                                     | 这个选项阻止MySQL 试图自动启动复制。因为在不安全的崩溃或其他问题后，启 动复制是不安全的，所以需要禁用自动启动，用户需要手动检査服务器，并确定它 是安全的之后再开始复制。
 slave_net_timeout                                    | 这个选项控制备库发现跟主库的连接已经失败并且需要重连之前等待的时间。默认 值是一个小时， 太长了。设置为一分钟或更短。                                            
 sync_master_info,sync_relay_log,sync_relay_log_info  | 在MySQL 5.5 以及更新版本中可用，解决了复制中备库长期存在的问题: 不把它们的状态文件同步到磁盘                                                                                              

<a id="markdown-55-p383-随机io和顺序io" name="55-p383-随机io和顺序io"></a>
# 55. p383-随机I/O和顺序I/O

数据库服务器同时使用顺序和随机I/O, **随机I/O从缓存中受益最多**。


典型的情况是“热点”数据随机分布。因此，**缓存这些数据将有助于避免昂贵的磁盘寻道**。
相反，顺序读取一般只需要扫描一次数据，所以缓存对它是没用的，除非能完全放在内.

顺序读取不能从缓存中受益的另一个原因是它们比随机读快。这有以下两个原因：

顺序I/O 比随机I/O 快  
顺序操作的执行速度比随机操作快，无论是在内存还是磁盘上。假设磁盘每秒可以
做100 个随机I/O 操作，并且可以完成每秒**50MB 的顺序读取**（这大概是消费级磁
盘现在能达到的水平）。如果每行100 字节，**随机读每秒可以读100 行**，相比之下**顺
序读可以每秒读560 000 行——是随机读的5 000 倍**，或几个数量级的差异。因此，
在这种情况下随机I/O 可以从缓存中获得很多好处。
顺序访问内存行的速度也快于随机访问。现在的内存芯片通常毎秒可以随机访问约
250 000 次100 字节的行，或者每秒500 万次的顺序访向。**请注意，内存随机访问
速度比磁盘随机访问快了2 500 倍，而内存中顺序访问只有磁盘10 倍的速度。**

存储引擎执行顺序读比随机读快  
一个随机读一般意味着存储引擎必须执行索引操作。（这个规则也有例外，但对
InnoDB 和MylSAM 都是对的）。通常需要通过B 树的数据结构査找，并且和其他
值比较。相反，连续读取一般需要遍历一个简单的数据结构，例如链表。这样就少
了很多工作，反复这样操作，连续读取的速度就比随机读取要快了。


<a id="markdown-56-p385-预写日志" name="56-p385-预写日志"></a>
# 56. p385-预写日志

事实上，除了允许写入被延迟，缓存可以允许它们被集中操作，主要通以下两个重要途径：

多次写入，一次刷新  
一片数据可以在内存中改变很多次，而不需要把所有的新值写到磁盘。当数据最终
被刷新到磁盘后，最后一次物理写之前发生的修改都被持久化了。例如，许多语句
可以更新内存中的计数器。如果计数器递增100 次，然后写入到磁盘，100 次修改
就被合并为一次写。

I/O 合并  
许多不同部分的数据可以在内存中修改，并且这些修改可以合并在一起，通过一次
磁盘操作完成物理写入。

写入缓存  

**这就是为什么许多交易系统使用预写日志（WAL) 策略**。**预写日志采用在内存中变更页
面，而不马上刷新到磁盘上的策略，因为刷新磁盘通常需要随机I/O, 这非常慢**。相反，
如果把变化的记录写到一个连续的日志文件，这就很快了。后台线程可以稍后把修改的
页面刷新到磁盘；并在刷新过程中优化写操作。


**写入从缓冲中大大受益，因为它把随机I/O 更多地转换到连续I/O**。异步（缓冲） 写通常
是由操作系统批量处理，使它们能以更优化的方式刷新到磁盘。同步（无缓冲）写必须
在写入到磁盘之后才能完成。这就是为什么它们受益于**RAID** 控制器中电池供电的回写
(Write-Back) 高速缓存（ 我们稍后讨论RAID)。

<a id="markdown-57-p386-缓存命中率" name="57-p386-缓存命中率"></a>
# 57. p386-缓存命中率
缓存命中率实际上也会决定使用了多少CPU, 所以评估缓存命中率的最好方法是査看
CPU 使用率。例如，**若CPU 使用了99% 的时间工作，用了1% 的时间等待I/O, 那缓存
命中率还是不错的。**

<a id="markdown-58-p389-固态存储的好处" name="58-p389-固态存储的好处"></a>
# 58. p389-固态存储的好处
  * 相比硬盘有更好的随机读写性能。闪存设备通常读明显比写要快。
  * 相比硬盘有更好的顺序读写性能。但是相比而言不如随机I/O 的改善那么大，因为硬盘随机I/O 比顺序I/O 要慢得多。入门级固态硬盘的顺序读取实际上还可能比传统硬盘慢。
  * 相比硬盘能更好地支持并发。闪存设备可以支持更多的并发操作，事实上，只有大量的并发请求才能真正实现最大吞吐量。

最重要的事情是提升随机I/O 和并发性。**闪存记忆体可以在髙并发下提供很好的随机I/O
性能**，这正是范式化的数据库所需要的。设**计非范式化的Schema 最常见的原因之一是
为了避免随机I/O, 并且使得査询可能转化为顺序I/O。**

<a id="markdown-59-p394-用ssd-做raid" name="59-p394-用ssd-做raid"></a>
# 59. p394-用SSD 做RAID
我们建议对SATA SSD 盘使用RAID (Redundant Array of Inexpensive Disks , 磁盘冗余
阵列）。单一驱动器的数据安全是无法让人信服的。


<a id="markdown-60-p405-raid等级之间的比较" name="60-p405-raid等级之间的比较"></a>
# 60. p405-RAID等级之间的比较

 等级      | 概要          | 冗余   | 盘数      | 读快   | 写快       
 -|-|-|-|-|-
 RAID0   | 便宜,快速,安全    | No   | N       | Yes  | Yes     
 RAID1   | 高速度,简单,安全   | Yes  | 2(通常)   | Yes  | No       
 RAID5   | 安全(速度)成本折中  | Yes  | N+1     | Yes  | 依赖于最慢的盘  
 RAID10  | 昂贵,告诉,安全    | Yes  | 2N      | Yes  | Yes      
 RAID50  | 为极大的数据存储服务  | Yes  | 2(N+1)  | Yes  | Yes      


<a id="markdown-61-p414-mysql创建的多种类型的文件" name="61-p414-mysql创建的多种类型的文件"></a>
# 61. p414-mysql创建的多种类型的文件
  * 数据和索引文件
  * 事务日志文件
  * 二进制日志文件
  * 常规日志（例如，错误日志、査询日志和慢査询日志）
  * 临时文件和临时表


<a id="markdown-62-p418-修改配置提高tcp的吞吐量" name="62-p418-修改配置提高tcp的吞吐量"></a>
# 62. p418-修改配置提高tcp的吞吐量
搜索TCP tuning guide

<a id="markdown-63-p421-常见文件系统对比" name="63-p421-常见文件系统对比"></a>
# 63. p421-常见文件系统对比

 文件系统          | 操作系统             | 支持日志  | 大目录    
 -|-|-|-
 ext2          | GNU/Linux        | 否     | 否      
 ext3          | GNU/Linux        | 可选    | 可选/部分  
 ext4          | GNU/Linux        | 是     | 是     
 HFS Plus      | Mac OS           | 可选    | 是      
 JFS           | GNU/Linux        | 是     | 否      
 NTFS          | windows          | 是     | 是      
 ReiserFS      | GNU/Linux        | 是     | 是      
 UFS(Solaris)  | FreeBSD          | 否     | 可选/部分  
 UFS2          | FreeBSD          | 否     | 可选/部分  
 XFS           | GNU/Linux        | 是     | 是     
 ZFS           | Solaris,FreeBSD  | 是     | 是      


<a id="markdown-64-p428-操作系统性能诊断工具" name="64-p428-操作系统性能诊断工具"></a>
# 64. p428-操作系统性能诊断工具
refer: https://www.tecmint.com/command-line-tools-to-monitor-linux-performance/


cpu密集型关注  

CPU 密集型服务器的输出通常在us 列会有一个很髙的值， 报告了花费在非内核
代码上的CPU 时钟，也可能在sy列有很高的值，表示系统CPU 利用率，超过20% 就
足以令人不安了。在大部分情况下，也会有进程队列排队时间（在r 列报告的）。

io密集型关注  
在I/O 密集型工作负载下，**CPU 花费大量时间在等待I/O 请求完成**。这意味着会
显示很多处理器在非中断休眠（b 列）状态，并且在wa 这一列的值很高

<a id="markdown-65-p431-操作系统以及硬件优化总结" name="65-p431-操作系统以及硬件优化总结"></a>
# 65. p431-操作系统以及硬件优化总结

我们通常建议大部分人**在性能和成本之间找到一个好的平衡点**。首先，出于多种原因，
我们喜欢使用廉价服务器。举个例子，如果在使用服务器的过程中遇到了麻烦， 并且在
诊断时需要停止服务，或者希望只是简单地把出问题的服务器用另一台替换，如果使用
的是一台$5 000 的廉价服务器，肯定比使用一台超过$50 000 或者更贵的服务器要简单
得多。**MySQL 通常也更适应廉价服务器，不管是从软件自身而言还是从典型的工作负
载而言。**

MySQL 需要的四种基本资源是：**CPU、内存、硬盘以及网络资源。**网络一般不会作为
很严重的瓶颈出现，而CPU、内存和磁盘通常是主要的瓶颈所在。

持久化存储的选择本质上归结为三个选项，以提高性能的次序排序：**SAN、传统硬盘以及固态存储设备**

设备|说明
-|-
 SAN   | 当需要功能和纯粹的容量时， SAN 是不错的。它们对许多工作负载都运行得不错， 但缺点是很昂贵，并且对小的随机I/O 操作有很大的延时，尤其是使用更慢的互联 方式（如NFS) 或工作集太大不足以匹配SAN 内存的缓存时，延时会更大。要注 意SAN 的性能突变的情况，并且要非常小心避免灾难的场景
 传统硬盘  | 很大，便宜，但是**对随机读很慢**。对大部分场景，**最好的选择是服务器硬 盘组成RAID 10** 卷。通常应该使用带有电池保护单元的RAID 控制器，并且设置写 缓存为WriteBack 策略。这样一个配置对大部分工作负载都可以运行良好。
 固态盘   | 相对比较小并且昂贵，但是**随机I/O 非常快**。一般分为两类：SSD 和PCIe 设 备。广泛地来说， SSD 更便宜，更慢，但缺少可靠性验证。需要对SSD 做RAID 以 提升可靠性，但是大多数硬件RAID 控制器不擅长这个任务。PCIe 设备很昂贵并 且有容量限制，但是非常快并且可靠，而且不需要RAID。  

<a id="markdown-66-p433-mysql复制概述" name="66-p433-mysql复制概述"></a>
# 66. p433-mysql复制概述
复制解决的基本问题是让一台服务器的数据与其他服务器保持同步。**一台主库的数据可
以同步到多台备库上**，备库本身也可以被配置成另外一台服务器的主库。主库和备库之
间可以有多种不同的组合方式。

MySQL 支持两种复制方式：**基于行的复制和基于语句的复制**.

在同一时间点备库上的数据可能与主库存在不一致，并
且无法保证主备之间的延迟。**一些大的语句可能导致备库产生几秒、几分钟甚至几个小
时的延迟。**

<a id="markdown-67-p434-复制解决的问题" name="67-p434-复制解决的问题"></a>
# 67. p434-复制解决的问题

  * 数据分布
  * 负载均衡
  * 备份
  * 高可用性和故障切换
  * MySQL升级测试

<a id="markdown-68-p442-服务器克隆备份的方法" name="68-p442-服务器克隆备份的方法"></a>
# 68. p442-服务器克隆备份的方法

使用冷备份  
最基本的方法是关闭主库，把数据复制到备库（高效复制文件的方法参考附录
C)。重启主库后，会使用一个新的二进制日志文件，我们在备库通过执行CHANGE
MASTER TO指向这个文件的起始处。这个方法的缺点很明显：**在复制数据时需要关
闭主库。**

使用热备份  
如果仅使用了MylSAM 表， 可以在主库运行时使用mysqlhotcopy或rsync来复制数
据

使用mysqldump  

使用快照或备份  
只要知道对应的二进制日志坐标，就可以使用主库的快照或者备份来初始化备库（如
果使用备份，需要确保从备份的时间点开始的主库二进制日志都要存在）。只需要
把备份或快照恢复到备库，然后使用CHANGE MASTER TO指定二进制日志的坐标

使用Percona Xtrabackup  
它能够在备份时不阻塞服务器的操作， **因此可以在不影响主库的情况下设置备库**。可以通过
克隆主库或另一个已存在的备库的方式来建立备库。


<a id="markdown-69-p445-基于语句的复制的优缺点" name="69-p445-基于语句的复制的优缺点"></a>
# 69. p445-基于语句的复制的优缺点

优点  
  * 实现相当简单
  * 不会使用太多带宽,一条更新好几兆数据的语句在二进制日志里可能只占几十个字节
  * 出现问题时可以很好地去定位

缺点  
  * 同一条SQL 在主库和备库上执行的时间可能稍微或很不相同
  * 更新必须是串行的。这需要更多的锁
  * 如果正在使用触发器或者存储过程，就不要使用基于语句的复制模式，除非能够清楚地确定不会碰到复制问题

<a id="markdown-70-p446-基于行的复制的优缺点" name="70-p446-基于行的复制的优缺点"></a>
# 70. p446-基于行的复制的优缺点

优点  
  * 复制数据更高效(如果基于语句,可能在备库表会被重新扫一遍)
  * 几乎没有基于行的复制模式无法处理的场景,对于所有的SQL 构造、触发器、存储过程等都能正确执行(适用性强)
  * 基于行的复制占用更少的CPU

缺点  
  * 全表更新时,复制开销会很大(每一行数据都记录在二进制日志事件中)
  * 执行基于行的变化的过程就像一个黑盒子，你无法知道服务器正在做什么(当出现问题时，可能很难找到问题所在)


<a id="markdown-71-p446-哪种方式更优" name="71-p446-哪种方式更优"></a>
# 71. p446-哪种方式更优?

**理论上基于行的复制模式整体上更优**，并且在实际应用中也适用于大多数场景。但这种
方式太新了以至于没有将一些特殊的功能加入到其中来满足数据库管理员的操作需求。
因此一些人直到现在还没有开始使用。

<a id="markdown-72-p452-一主库多备库" name="72-p452-一主库多备库"></a>
# 72. p452-一主库多备库
在有少量写和大量读时，这种配置是非常有用的。可以把读分摊到多个备库上，直到备
库给主库造成了太大的负担，或者主备之间的带宽成为瓶颈为止

  * 为不同的角色使用不同的备库（例如添加不同的索引或使用不同的存储引擎）
  * 把一台备库当作待用的主库，除了复制没有其他数据传输
  * 将一台备库放到远程数据中心，用作灾难恢复
  * 延迟一个或多个备库，以备灾难恢复
  * 使用其中一个备库，作为备份、培训、开发或者测试使用服务器

<a id="markdown-73-p469-测量备库延迟" name="73-p469-测量备库延迟"></a>
# 73. p469-测量备库延迟
一个比较普遍的问题是如何监控备库落后主库的延迟有多大。虽然 SHOW SLAVE STATUS
输出的Seconds_behind_master列理论上显示了备库的延时,但出于各种各样的原因,并不总是准确的:

  * 备库 Seconds_behind_master 值是通过将服务器当前的时间戳与二进制日志中的事件的时间戳相对比得到的，所以只有在执行事件时才能报告延迟
  * 如果备库复制线程没有运行， 就会报延迟为 NULL
  * 一些错可能中断复制并且/ 或者停止复制线程,但Seconds_behind_master将显示为0 而不是显示错误
  * 即使备库线程正在运行，备库有时候可能无法计算延时.如果发生这种情况,备库会报0 或者 NULL
  * 一个大事务可能会导致延迟波动
  * 如果分发主库落后了，并且其本身也有已经追赶上它的备库，备库的延迟将显示为0, 而事实上和源主库之间是有延迟的

解决这些问题的办法是忽略Seconds_behind_master并使用一些可以直接观察和衡量的方式来监控备库延迟。
最好的解决办法是使用 heartbeat record 这是一个在主库上会每秒更新一次的时间戳.为了计算延时，可以直接用备库当前的时间戳减去心跳记
录的值.


<a id="markdown-74-p469-确定主备一致日常工作" name="74-p469-确定主备一致日常工作"></a>
# 74. p469-确定主备一致(日常工作)
在理想情况下，备库和主库的数据应该是完全一样的。但事实上备库可能发生错误并导
致数据不一致。即使没有明显的错误，备库同样可能因为MySQL 自身的特性导致数据
不一致，例如**MySQL 的Bug、网络中断、服务器崩溃，非正常关闭或者其他一些错误**。

**pt-table-checksum**是唯一能够有效地比较主备一致性的工具

当发现不同步时,使用**pt-table-sync**解决同步问题


<a id="markdown-75-p496-其他复制技术" name="75-p496-其他复制技术"></a>
# 75. p496-其他复制技术
Tungsten Relicator是第一个提供MySQL 并行复制支持的虽然我们还没有看到其被应用到生产环境中，但它声称能够提供最多三倍的复制速度改善，具体取决于负载特性。基于该架构以及我们对该产品的了解，这看起来是可信的。

优点  
  * 它提供了内建的数据一致性检査
  * 提供了插件特性，因此你可以编写自己的函数。MySQL 的复制源代码非常难以理解并且很难去修改。即使非常聪明的程序员在试图修改时，也会引入新的Bug。因而能有种途径去修改复制而无须修改MySQL 的复制代码，是非常理想的
  * 拥有全局事务ID, 能够帮助你了解每个服务器相互之间的状态而无须去匹配二进制日志名和偏移量
  * 它是一个高可用的解决方案，能够快速地将一台备库提升为主库
  * 提供异构数据复制(例如，在MySQL 和PostgreSQL 之间或者MySQL 和Oracle 之间
  * 支持不同版本的MySQL 复制，以防止MySQL 复制不能反向兼容。这对某些升级的场景非常有用。当升级运行得不理想时，你可能无法设计一个可行的回滚方案，或者必须升级服务器到一个并不是你期望的版本
  * 并行复制的设计非常适用于共享应用程序或多任务应用程序
  * Java 应用能够明确地写入主库并从备库读取
  * 得益于Giuseppe Maxia 作为QA 主管的大量工作，现在比以往M加简单并且更加容易配置和管理


缺点  

  * 它比内建的MySQL 复制更加复杂，有更多可变动的地方需要配置和管理，毕竟它是一个中间件。
  * 在你的应用栈中需要多学习和理解一个新的工具。
  * 它并不像内建的MySQL 复制那样轻量级，并且没有同样的性能。使用TungstenReplicator 进行单线程复制比MySQL 的单线程复制要慢。
  * 作为MySQL 复制并没有经过广泛的测试和部署，所以Bug 和问题的风险很高。

<a id="markdown-76-p501-什么是可扩展性" name="76-p501-什么是可扩展性"></a>
# 76. p501-什么是可扩展性

用汽车来进行类比:
  * 性能是汽车的时速
  * 容量是车道数乘以最大安全时速。
  * 可扩展性就是在不减慢交通的情况下，能增加更多车和车道的程度。

可扩展性的关键概念:
划算的等同提升 equal bang for the buck,当增加资源以处理负栽和增加容量时系统能够获得的投资产出率


<a id="markdown-77-p509-向上扩展" name="77-p509-向上扩展"></a>
# 77. p509-向上扩展
向上扩展（有时也称为垂直扩展）意味着购买更多性能强悍的硬件，对很多应用来说这
是唯一需要做的事情。这种策略有很多好处。例如，**单台服务器比多台服务器更加容易
维护和开发，能显著节约开销。**在单台服务器上备份和恢复应用同样很简单，因为无须
关心一致性或者哪个数据集是权威的。当然，还有一些别的原因。从**复杂性的成本来说，
向上扩展比向外扩展更简单。
**

但是如果应用变得非常庞大,向上扩展可能就没有办法了.第一个原因是钱,无论服务器上运行什么样的软件，从某种角度来看，向上扩展都是个糟糕的财务决策，当超出硬件能够提供的
最优性价比时，就会**需要非同寻常的特殊配置的硬件，这样的硬件往往非常昂贵。****这意
味着能向上扩展到什么地步是有实际的限制的.**如果使用了复制，那么当主库升级到髙
端硬件后，**一般是不太可能配置出一台能够跟上主库的强大备库的**。一个高负载的主库
通常可以承担比拥有同样配置的备库更多的工作，因为备库的复制线程无法高效地利用
多核CPU 和磁盘资源。


最后，向上扩展不是无限制的，即使最强大的计算机也有限制。单服务器应用通常会首
先达到读限制，特别是执行复杂的读査询时。**类似这样的査询在MySQL 内部是单线程的，
因此只能使用一个CPU，这种情况下花钱也无法提升多少性能。**即使购买最快的CPU
也仅仅会是商用CPU 的几倍速度。增加更多的CPU 或CPU 核数并不能使慢査询执行得
更快。当数据变得庞大以至于无法有效缓存时，内存也会成为瓶颈，这通常表现为很高
的磁盘使用率，而磁盘是现代计算机中最慢的部分.

**无法使用向上扩展最明显的场景是云计算**。在大多数公有云中都无法获得性能非常强的
服务器，如果应用肯定会变得非常庞大，就不能选择向上扩展的方式。


<a id="markdown-78-p501-向外扩展" name="78-p501-向外扩展"></a>
# 78. p501-向外扩展
可以把向外扩展（有时也称为横向**扩展或者水平扩展**）策略划分为三个部分:**复制、拆分，
以及数据分片.**

在MySQL 架构中，一个节点（node) 就是一个功能部件。如果设计的是能够故障转移的冗余系统，那么一个
节点通常可能是下面的某一种：

  * 一个主一主复制双机结构，拥有一个主动服务器和被动服务器
  * 一个主库和多个备库
  * 一个主动服务器，并使用分布式复制块设备（DRBD) 作为备用服务器
  * 一个基于存储区域网络（SAN) 的“集群”

大多数情况下，一个节点内的所有服务器应该拥有相同的数据。我们倾向于把**主一主复
制架构作为两台服务器的主动一被动节点。
**


<a id="markdown-781-按功能拆分" name="781-按功能拆分"></a>
## 78.1. 按功能拆分
按功能拆分，或者说按职责拆分，意味着不同的节点执行不同的任务。我们之前已经提
到了一些类似的实现， 在前一章我们描述了如何为OLTP 和OLAP 工作负载设计不同的
服务器。按功能拆分采取的策略比这些更进一步，将独立的服务器或节点分配给不同的
应用，这样每个节点只包含它的特定应用所需要的数据。

门户网站常常把不同
的栏目放在一起;在门户网站，可以浏览**网站新闻、论坛，寻求支持和访问知识库**，等等。
这些不同功能区域的数据可以放到专用的MySQL 服务器中

<a id="markdown-782-数据分片" name="782-数据分片"></a>
## 78.2. 数据分片
在目前用于扩展大型MySQL 应用的方案中，数据分片是最通用且最成功的方法。它
**把数据分割成一小片，或者说一块， 然后存储到不同的节点中**

数据分片在和某些类型的按功能划分联合使用时非常有用。大多数分片系统也有一些“全
局的”数据不会被分片（ 例如城市列表或者登录数据）。全局数据一般存储在单个节点上，
并且通常保存在类似memchched 这样的缓存里。

事实上，大多数应用只会对需要的数据做分片—— 通常是那些将会增长得非常庞大的数
据。假设正在构建的博客服务，预计会有1000 万用户，这时候就无须对注册用户进行分片，
因为完全可以将所有的用户（或者其中的活跃用户）放到内存中。**假如用户数达到5 亿,
那么就可能需要对用户数据分片。用户产生的内容，例如发表的文章和评论，几乎肯定
需要进行数据分片，因为这些数据非常庞大，并且还会越来越多。**

分片技术和大多数应用的最初设计有着显著的差异，并且很难将应用从单一数据存储转
换为分片架构。**如果在应用设计初期就已经预计到分片，那实现起来就容易得多。**

如果事先知道应用会扩大到很大的规模，并且清楚按功能划分的局限性，就可以跳过中
间步骤，直接从单个节点升级为分片数据存储。**事实上，这种前瞻性可以帮你避免由于
租糙的分片方案带来的挑战.**

**采用分片的应用常会有一个数据库访问抽象层**，用以降低应用和分片数据存储之间通信
的复杂度，但无法完全隐藏分片。因为相比数据存储，应用通常更了解跟査询相关的一
些信息。**太多的抽象会导致低效率，例如査询所有的节点，可实际上需要的数据只在单
一节点上。**

分片数据存储看起来像是优雅的解决方案，但很难实现。那为什么要选择这个架构呢？
答案很简单：如果想扩展写容量，就必须切分数据。如果只有单台主库，那么不管有多
少备库，写容量都是无法扩展的。**对于上述缺点而言，数据分片是我们首选的解决方案。**

这是一个问题，对吧？答案很简单：**如非必要，尽量不分片。**首先看是否能通过性
能调优或者更好的应用或数据库设计来推迟分片。如果能足够长时间地推迟分片，
也许可以直接购买更大的服务器，升级MySQL 到性能更优的版本，然后继续使用
单台服务器，也可以增加或减少复制。
简单的说，对单台务器而言，数据大小或写负载变得太大时，分片将是不可避免
的。如果不分片，而是尽可能地优化应用，系统能扩展到什么程度呢？答案可能会
让你很惊讶。有些非常受欢迎的应用，你可能以为从一开始就分片了，但实际上直
到已经值数十亿美元并且流量极其巨大也还没有采用分片的设计。分片不是城里唯
一的游戏，在没有必要的情况下采用分片的架构来构建应用会步履維艰。

<a id="markdown-783-选择分区键partitioning-key" name="783-选择分区键partitioning-key"></a>
## 78.3. 选择分区键(partitioning key)

数据分片最大的挑战是査找和获取数据：如何査找数据取决于如何进行分片。有很多方
法，其中有一些方法会比另外一些更好。

**我们的目标是对那些最重要并且频繁査询的数据减少分片**（记住，可扩展性法则的其中
一条就是要避免不同节点间的交互）。这其中最重要的是如何为数据选择一个或多个分
区键。**分区键决定了每一行分配到哪一个分片中**。如果知道一个对象的分区键，就可以
回答如下两个问题：
  * 应该在哪里存储数据？
  * 应该从哪里取到希望得到的数据？

一个好的分区键常常是数据库中一个非常重要的实体的主键。这些键值决定了分片单元。
例如，如果通过用户ID 或客户端ID 来分割数据，**分片单元就是用户或者客户端。**

如果应用只在美国使用，并且希望将数据
集分割为20 个分片，则可能不应该按照州来划分，因为加利福尼亚的人口非常多。但
可以按照县或者电话区号来划分，因为尽管并不是均匀分布的，但足以选择20 个集合
以粗略地表示等同的密集程度，并且基本上避免跨分片査询

<a id="markdown-784-多个分区键" name="784-多个分区键"></a>
## 78.4. 多个分区键
复杂的数据模型会使数据分片更加困难。许多应用拥有多个分区键，特别是存在两个或
更多个“维度”的时候。换句话说，应用需要从不同的角度看到有效且连贯的数据视图。
这意味着某些数据在系统内至少需要存储两份。

<a id="markdown-785-跨分片查询" name="785-跨分片查询"></a>
## 78.5. 跨分片查询
大多数分片应用多少都有一些査询需要对多个分片的数据进行聚合或关联操作。例如，
**一个读书俱乐部网站要显示最受欢迎或最活跃的用户，就必须访问每一个分片**。如何让
这类査询很好地执行，是实现数据分片的架构中最困难的部分。虽然从应用的角度来看，
这是一条査询，但实际上需要拆分成多条并行执行的査询，每个分片上执行一条。一个
设计良好的数据库抽象层能够减轻这个问题，但类似的査询仍然会比分片内査询要慢并
且更加昂贵，所以通常会更加依赖缓存。

**跨分片査询并不是数据分片面临的唯一难题。维护数据一致性同样困难**。外键无法在分
片间工作，因此需要由应用来检査参照一致性，或者只在分片内使用外键，因为分片内
的内部一致性可能是最重要的。还可以使用XA 事务，但由于开销太大，现实中使用浪少

<a id="markdown-786-分配数据分片和节点" name="786-分配数据分片和节点"></a>
## 78.6. 分配数据、分片和节点
分片和节点不一定是一对一的关系，**应该尽可能地让分片的大小比节点容量小很多，这
样就可以在单个节点上存储多个分片。**

保持分片足够小更容易管理。这将使数据的备份和恢复更加容易，如果表很小， 那么像
更改表结构这样的操作会更加容易。例如，**假设有一个100GB 的表，你可以直接存储，
也可以将其划分为100 个1GB 的分片，并存储在单个节点上。现在假如要向表上增加
一个索引，在单个100GB 的表上的执行时间会比100 个1GB 分片上执行的总时间更长，
因为1GB 的分片更容易全部加载到内存中。**并且在执行ALTER TABLE 时还会导致数
据不可用，阻塞1GB 的数据比阻塞100GB 的数据要好得多。


<a id="markdown-787-在节点上部署分片" name="787-在节点上部署分片"></a>
## 78.7. 在节点上部署分片
以下是常用的办法:

  * 每个分片使用单一数据库，并且数据库名要相同。典型的应用场景是需要每个分片都能镜像到原应用的结构。这在部署多个应用实例，并且每个实例对应一个分片时很有用。
  * 将多个分片的表放到一个数据库中，在每个表名上包含分片号（例如bookclub.comments_23)。这种配置下，单个数据库可以支持多个数据分片。
  * 为每个分片使用一个数据库，并在数据库中包含所有应用需要的表。在数据库名中为每个分片使用一个数据库，并在数据库中包含所有应用需要的表。在数据库名中包含分片号(例如表名可能是bookclub_32.comments或者bookclub_23_users),但表名不包括分片号。当应用连接到单个数据库并且不在査询中指定数据库名时，这种做法很常见。其优点是无须为每个分片专门编写査询，也便于对只使用单个数据库的应用进行分片。
  * 每个分片使用一个数据库，并在数据库名和表名中包含分片号(例如表名可以是bookclub_23.comments_23)
  * 在每个节点上运行多个MySQL 实例，毎个实例上有一个或多个分片，可以使用上面提到的方式的任意组合来安排分片。

构建新应用时，查询模板并不是问题，我们倾向于使用每个分片一个数据库的方式，并把分片号写到数据库名和表名中.这会增加例如ALTER TABLE 这类操作的复杂度，但也有如下一些优点：

  * 如果分片全部在一个数据库中，转移分片会比较容易。
  * 因为数据库本身是文件系统中的一个目录，所以可以很方便地管理一个分片的文件。
  * 如果分片互不关联，则很容易査看分片的大小。
  * 全局唯一表名可避免误操作。如果表名每个地方都相同，很容易因为连接到错误的节点而査询了错误的分片，或者是将一个分片的数据误导入另外一个分片的表中。

<a id="markdown-788-固定分配" name="788-固定分配"></a>
## 78.8. 固定分配
将数据分配到分片中有两种主要的方法：固定分配和动态分配。两种方法都需要一个分
区函数，使用行的分区键值作为输入，返回存储该行的分片

固定分配使用的分区函数仅仅依赖于分区键的值。哈希函数和取模运算就是很好的例子。
**这些函数按照毎个分区键的值将数据分散到一定数量的“桶”中。**

固定分配的主要优点是简单，开销低，甚至可以在应用中直接硬编码。

固定分配的缺点:

  * 如果分片很大并且数量不多，就很难平衡不同分片间的负载。
  * 固定分片的方式无法自定义数据放到哪个分片上，这一点对于那些在分片间负载不均衡的应用来说尤其重要。一些数据可能比其他的更加活跃， 如果这些热点数据都分配到同一个分片中， 固定分配的方式就无法通过热点数据转移的方式来平衡负载。
  * 修改分片策略通常比较困难，因为需要重新分配已有的数据。例如，如果通过模10的哈希函数来进行分片，就会有10 个分片。如果应用增长使得分片变大，如果要拆分成20 个分片，就需要对所
有数据重新哈希，这会导致更新大量数据，并在分片间转移数据。

正是由于这些限制，**我们倾向于为新应用选择动态分配的方式**。但如果是为已有的应用
做分片，使用固定分配策略可能会更容易些，因为它更简单。也就是说，**大多数使用固
定分配的应用最后迟早要使用动态分配策略。**

<a id="markdown-789-动态分配" name="789-动态分配"></a>
## 78.9. 动态分配

动态分配的最大好处是可以对数据存储位置做细粒度的控制。这使得均衡分配数据到分片更加容易，并可提供适应未知改变的灵活性。

动态分配以及灵活地利用分片亲和性有助于减轻规模扩大而带来的跨分片査询问题。假
设一个跨分片査询涉及四个节点，当使用固定分配时，任何给定的査询可能需要访问所
有分片，但动态分配策略则可能只需要在其中的三个节点上运行同样的査询。这看起来
没什么大区别，但**考虑一下当数据存储增加到400 个分片时会发生什么？固定分配策略
需要访问400 个分片，而动态分配方式依然只需要访问3 个**

动态分配可以让分片策略根据需要变得很复杂。固定分配则没有这么多选择。

<a id="markdown-7810-混合动态分配和固定分配" name="7810-混合动态分配和固定分配"></a>
## 78.10. 混合动态分配和固定分配

以一个存储网站链接的系统为例。这样一个站点需要存储数百亿的行，所使用的分区键
是源地址和目的地址URL 的组合。（这两个URL 的任意一个都可能有好几亿的链接，
因此，单独一个URL 并不适合做分区键）。但是在映射表中存储所有的源地址和目的地
址URL 组合并不合理，因为数据量太大了，每个URL 都需要很多存储空间。
一个解决方案是**将URL 相连并将其哈希到固定数目的桶中，然后把桶动态地映射到分
片上。如果桶的数目足够大——例如100 万个——你就能把大多数数据分配到每个分片
上，获得动态分配的大部分好处，而无须使用庞大的映射表。**

<a id="markdown-7811-显式分配" name="7811-显式分配"></a>
## 78.11. 显式分配
显式分配的缺点是分片方式是固定的，**很难做到分片间的负载均衡**。但结合固定分配和
动态分配，该方法就能够很好地工作。不再像之前那样哈希到固定数目的桶里并将其映
射到节点，而是将桶作为对象的一部分进行编码。这样应用就能够控制数据的存储位置,
因此可以将相关联的数据一起放到同样的分片中。

我们讨论了混合分配方式，因为在某些场景下它是有用的。但正常情况下我们并不推荐
这样用。我们倾向于尽可能使用动态分配，避免显式分配。

<a id="markdown-7812-重新均衡分片数据" name="7812-重新均衡分片数据"></a>
## 78.12. 重新均衡分片数据
如有必要，可以通过在分片间移动数据来达到负载均衡。举个例子，许多读者可能听一
些大型图片分享网站或流行社区网站的开发者提到过用于分片间移动用户数据的工具。

在分片间移动数据的好处很明显。例如，当需要升级硬件时，可以将用户数据从旧分片
转移到新分片上，而无须暂停整个分片的服务或将其设置为只读。

一个较好的策略是使用动态分片策略，并将新数据随机分配到分片中。当一个分片快满
时，可以设置一个标志位，告诉应用不要再往这里放数据了。如果来来需要向分片中放
入更多数据，可以直接把标记位清除。

<a id="markdown-7813-生成全局唯一id" name="7813-生成全局唯一id"></a>
## 78.13. 生成全局唯一ID

当希望把一个现有系统转换为分片数据存储时，经常会需要在多台机器上生成全局唯一
ID。**单一数据存储时通常可以使用AUTO_ INCREMENT 列来获取唯一ID。但涉及多台
服务器时就不凑效了。**以下几种方法可以解决这个问题：


使用auto_increment_increment和auto_increment_offset
这两个服务器变量可以让MySQL 以期望的值和偏移量来增加AUTO_INCREMENT列的
值。举一个最简单的场景，只有两台服务器，可以配置这两台服务器自增幅度为2 ,
其中一台的偏移量设置为1，另外一台为2 ( 两个都不可以设置为0 )。这样一台服
务器总是包含偶数，另外一台则总是包含奇数。这种设置可以配置到服务器的每一
个表里。

这种方法简单，并且不依赖于某个节点，因此是生成唯一ID 的比较普遍的方法。但
这需要非常仔细地配置服务器。很容易因为配置错误生成重复数字，特别是当增加
服务器需要改变其角色，或进行灾难恢复时。

全局节点中创建表  
在一个全局数据库节点中创建一个包含AUTO_INCREMENT 列的表，应用可以通过这个
表来生成唯一数字。

使用memcached  
在memcached的API中有一个incr()函数,可以自动增长一个数字并返回结果。另外也可以使用Redis

批量分配数字  
应用可以从一个全局节点中请求一批数字，用完后再申请。

使用复合值  
可以使用一个复合值来做唯一ID，例如分片号和自增数的组合。

使用GUID 值  
可以使用UUID()函数来生成全局唯一值。注意，尽管这个函数在基于语句的复制时
不能正确复制，但可以先获得这个值，再存放到应用的内存中，然后作为数字在查
询中使用。GUID 的值很大并且不连续，因此不适合做IimoDB表的主键


如果使用全局分配器来产生唯一ID, 要注意避免单点争用成为应用的性能瓶颈。

<a id="markdown-7814-分片工具" name="7814-分片工具"></a>
## 78.14. 分片工具
如果没有任何抽象层， **直接让应用访问多个数据源，那绝对是一个很差的设计**，因为这
会增加大量的编码复杂性。最好的办法是将数据源隐藏在抽象层中.

抽象层主要完成以下任务:
  * 连接到正确的分片并执行査询。
  * 分布式一致性校验。
  * 跨分片结果集聚合。
  * 跨分片关联操作。
  * 锁和事务管理。
  * 创建新的数据分片（或者至少在运行时找到新分片）并重新平衡分片（如果有时间实现）.

你可能不需要从头开始构建分片结构。有一些工具和系统可以提供一些必要的功能或专门设计用来实现分片架构。

http://shards.hibernate.org是一个支持分片的数据库抽象层,由google提供

<a id="markdown-79-p525-通过多实例扩展" name="79-p525-通过多实例扩展"></a>
# 79. p525-通过多实例扩展
一个分片较多的架构可能会更有效地利用硬件。我们的研究和经验表明MySQL 并不能
完全发挥现代硬件的性能。**当扩展到超过24 个CPU 核心时，MySQL 的性能开始趋于
平缓，不再上升。** ** 当内存超过128GB 时也同样如此， MySQL 甚至不能完全发挥诸如
Virident 或Fusion-io 卡这样的高端PCIe flash 设备的I/O 性能。**

不要在一台性能强悍的服务器上只运行一个服务器实例，我们还有别的选择。你可以让
数据分片足够小，以使每台机器上都能放置多个分片（这也是我们一直提倡的）， 毎台
服务器上运行多个实例，**然后划分服务器的硬件资源，将其分配给毎个实例。**

将每个MySQL 实例绑定到特定的CPU 核心上。这有两点好处：
第一，由于MySQL 内部的可扩展性限制，当核心数较少时，能够在毎个核心上获得更好的性能;'

第二，当实例在多个核心上运行线程时， 由于需要在多核心上同步共享数据，因而会有
一些额外的开销。这可以避免硬件本身的可扩展性限制。限制MySQL 到少数几个核心
能够帮助减少CPU 核心之间的交互。注意到反复出现的问题了没？将进程绑定到具有相
同物理套接字的核心上可以获得最优的效果。

<a id="markdown-80-p549-通过集群扩展" name="80-p549-通过集群扩展"></a>
# 80. p549-通过集群扩展
理想的扩展方案是单一逻辑数据库能够存储尽可能多的数据，处理尽可能多的査询，并
如期望的那样增长。许多人的第一想法就是建立一个“集群”或者“网格”来无缝处理
这些事情，这样应用就无须去做太多工作，也不需要知道数据到底存在哪台服务器上。
随着云计算的流行，**自动扩展——根据负载或数据大小变化动态地在集群中增加/ 移除
服务器——变得越来越有趣。**

许多关系型数据库集群的高性能设计正
在被构建到系统的更低层，在NoSQL数据库中，特别是使用键一值存储时，这一点很明显。
例如**NDB Cluster 并不是一个SQL 数据库，它是一个可扩展的数据库，使用其原生API**
来控制，通常是使用NoSQL, 但也可以通过在前端使用MySQL 存储引擎来支持SQL。
它是一个完全分布式、非共享高性能、自动分片并且不存在单点故障的事务型数据库服
务器。最近几年正变得更强大、更复杂，用途也更广泛。同时， **NoSQL 数据库也逐渐看
起来越来越像关系型数据库**。有些甚至还开发了类SQL 查询语言。未来典型的集群数据
库可能更像是SQL 和NoSQL 的混合体，有多种存取机制来满足不同的使用需求。所以，
我们在从NoSQL 中汲取优点，但SQL 仍然会保留在集群数据库中。

在写作本书时，和MySQL 结合在一起的集群或分布式数据库技术大致包括：NDB
Cluster、Clustrix、Percona XtraDB Cluster、Galera、Schooner Active Cluster、
Continuent Tungsten、ScaleBase、ScaleArc、dbShards、Xeround、Akiban、VoltDB,
以及GenieDB〇这些或多或少以MySQL 为基础，或通过MySQL 进行控制，或是和
MySQL 相关

<a id="markdown-801-ndb-cluster" name="801-ndb-cluster"></a>
## 80.1. NDB Cluster
NDB 是一个非常复杂的数据库，和MySQL 几乎完全不同。在使用NDB 时甚至可以不
需要MySQL : 你可以把它作为一个独立的键一值数据库服务器。它的亮点包括非常高
的写入和按键査询吞吐量。**NDB 可以基于键的哈希自动决定哪个节点应该存储给定的数
据。当通过MySQL 来控制NDB 时，行的主键就是键，其他的列是值。**


NDB 曾经相对其他MySQL 存储引擎具有完全不同的性能特性，但最近的版本更加通用
化了。它正在成为越来越多应用的更好的解决方案，包括游戏和移动应用。我们必须强
调，NDB 是一项重要的技术，能够支持全球最大的关键应用，这些应用处于极高的负载
下，具有非常严苛的延迟要求以及不间断要求。举个例子，世界上任何一个通过移动电
话网络呼叫的电话使用的就是NDB, 并且不是临时方案——对于许多移动电话提供商而
言，它是一个主要的并且非常重要的数据库。

那么它有什么缺点呢？复杂査询现在支持得还不是很好，例如那些有很多关联和聚合的
査询。所以不要指望用它来做数据仓库。NDB 是一个事务型系统，但不支持MVCC，
所以读操作也需要加锁，也不做任何的死锁检测。如果发生死锁，NDB 就以超时返回的
方式来解决。还有很多你应该知道的要点和警告，可以专门写一本书了。


<a id="markdown-802-clustrix" name="802-clustrix"></a>
## 80.2. Clustrix
支持MySQL 协议，所以它可
以直接替代MySQL。除了协议外,它是一个全新的技术，并非建立在MySQL 的基础之上。
它是一个完全支持ACID, 支持MVCC 的事务型SQL 数据库，主要用于OLTP 负载场景。
Clustrix 在节点间进行数据分片以满足容错性，并对査询进行分发， 在节点上并发执行，
而不是将所有节点上取得的数据集中起来执行。集群可以在线扩展节点来处理更多的数
据或负载。在某些方面<：1118记\和1 8(51 <：11 61'很像；关键的不同点是完
全分布式执行并且缺少顶层的“代理”或者集群前端的査询协调器（query coordinator)。
Clustrix 本身能够理解MySQL 协议，所以无须MySQL 来进行协议转换。相比较而言，
MySQL cluster 是由三个部分组成的：MySQL, NDB 集群存储引擎，以及NDB

<a id="markdown-803-scalebase" name="803-scalebase"></a>
## 80.3. ScaleBase
是一个软件代理，处于应用和多个后端MySQL
服务器之间。它会把发起的査询进行分裂，并将其分发到后端服务器并发执行，然后汇
集结果返回给应用。不过在写作本书时，我们还没有使用该产品的经验

<a id="markdown-804-geniedb" name="804-geniedb"></a>
## 80.4. GenieDB
最开始用于地理上分布部署的NoSQL 文档存储。现
在它也有一个SQL 层，可以通过MySQL 存储引擎进行控制。它包含了很多技术_，包括
本地内存缓存、消息层，以及持久化磁盘数据存储。将这些技术汇集在一起，就可以使
用松散的最终一致性，让应用在本地快速执行査询，或是通过分布式集群（会增加网络
延迟）来保证最新的数据视图。


<a id="markdown-805-akiban" name="805-akiban"></a>
## 80.5. Akiban
通过存储物
理数据来匹配査询模式，使得低开销的跨表关联操作成为可能。


<a id="markdown-81-p530-内向扩展" name="81-p530-内向扩展"></a>
# 81. p530-内向扩展

处理不断增长的数据和负载最简单的办法是对不再需要的数据进行归档和清理。这种操
作可能会带来显著的成效，具体取决于工作负载和数据特性。这种做法并不用来代替其
他策略，但可以作为争取时间的短期策略，也可以作为处理大数据量的长期计划之一

<a id="markdown-811-保持活跃数据独立" name="811-保持活跃数据独立"></a>
## 81.1. 保持活跃数据独立

将表划分为几个部分  
分表是一种比较明智的办法，特别是整张表无法完全加载到内存时。例如，可
以把users 表划分为active_users 和 inactive_users 表。。你可能认为这并不需
要，因为数据库本身只缓存“热”数据，但事实上这取决于存储引擎。如果用的是
InnoDB, 每次缓存一页，而一页能存储100 个用户， 但只有10% 是活跃的，那么
这时候InnoDB 可能认为所有的页都是“热”的—— 因此毎个“热”页的90% 将被
浪费掉。将其拆成两个表可以明显改善内存利用率。

MySQL 分区  
MySQL 5.1 本身提供了对表进行分区的功能，能够帮助把最近的数据留在内存中。


基于时间的数据分区  
如果应用不断有新数据进来，一般新数据总是比旧数据更加活跃。例如，我们知道
博客服务的流量大多是最近七天发表的文章和评论。更新的大部分是相同的数据集。
因此这些数据被完整地保留在内存中，使用复制来保证在主库失效时有一份可用的
备份。其他数据则完全可以放到别的地方去。

我们也看到过这样一种设计，在两个节点的分片上存储用户数据。新数据总是进入
“活跃”节点，该节点使用更大的内存和快速硬盘，另外一个节点存储旧数据，使用
非常大（但比较慢）的硬盘。应用假设不太会需要旧数据。对于很多应用而言这是
合理的假设，依靠10% 的最新数据能够满足90% 或更多的请求。

<a id="markdown-82-p532-负载均衡" name="82-p532-负载均衡"></a>
# 82. p532-负载均衡
负载均衡的基本思路很简单：在一个服务器集群中尽可能地平均负载量。通常的做法是
在服务器前端设置一个负载均衡器（一般是专门的硬件设备）。然后负载均衡器将请求
的连接路由到最空闲的可用服务器。图11-9 显示了一个典型的大型网站负载均衡设置，
其中一个负载均衡器用于HTTP 流量，另一个用于MySQL 访问。

负载均衡有五个常见目的。

可扩展性  
负载均衡对某些扩展策略有所帮助，例如读写分离时从备库读数据。

高效性  
负载均衡有助于更有效地使用资源，因为它能够控制请求被路由到何处。如果服务
器处理能力各不相同，这就尤为重要：你可以把更多的工作分配给性能更好的机器。

可用性  
一个灵活的负载均衡解决方案能够使用时刻保持可用的服务器。

透明性  
客户端无须知道是否存在负载均衡设置，也不需要关心在负载均衡器的背后有多少
机器，它们的名字是什么。负载均衡器给客户端看到的只是一个虚拟的服务器.

一致性  
如果应用是有状态的（数据库事务，网站会话等）， 那么负载均衡器就应将相关的査
询指向同一个服务器，以防止状态丢失。应用无须去跟踪到底连接的是哪个服务器。

在决定如何实现负载均衡时，应该考虑到这些因素。有许多负载均衡解决方案可以使用，
从诸如Wackamole 这样基于端点的（peer-based)实现，到DNS、LVS (Linux Virtual Server, 硬件负载均衡器、TCP 代理、MySQL Proxy, 以及在应用中管理负载均衡

在我们的客户中，最普遍的策略是使用硬件负载均衡器，大多是使用**HA Proxy**,它看起来很流行并且工作得很好。还有一些人使用TCP 代理(Pen)

<a id="markdown-83-p538-负载均衡器" name="83-p538-负载均衡器"></a>
# 83. p538-负载均衡器

在市场上有许多负载均衡硬件和软件，但很少有专门为MySQL 服务器设计的.。Web
服务器通常更需要负载均衡，因此许多多用途的负载均衡设备都会支持HTTP, 而对其
他用途则只有一些很少的基本特性。MySQL 连接都只是正常的TCP/IP 连接，所以可以
在MySQL 上使用多用途负载均衡器。但由于缺少MySQL 专有的特性，因此会多一些
限制。


除非负载均衡器知道MySQL 的真实负载，否则在分发请求时可能无法做到很好的
负载均衡。不是所有的请求都是等同的，但多用途负载均衡器通常对所有的请求一
视同仁。

许多负载均衡器知道如何检査一个HTTP 请求并把会话“固定”到一个服务器上以
保护在Web 服务器上的会话状态。MySQL 连接也是有状态的，但负载均衡器可能
并不知道如何把所有从单个HTTP 会话发送的连接请求“固定”到一个MySQL 服
务器上。这会损失一部分效率。

连接池和长连接可能会阻碍负载均衡器分发连接请求。例如， 假如一个连接池打开
了预先配置好的连接数，负载均衡器在已有的四个MySQL 服务器上分发这些连接。
现在增加了两个以上的MySQL 服务器。由于连接池不会请求新连接，因而新的眼
务器会一直空闲着。池中的连接会在服务器间不公平地分配负载，导致一些服务器
超出负载，一些则几乎没有负载。可以在多个层面为连接设置失效时间来缓解这个
问题，但这很复杂并且很难做到。连接池方案只有它们本身能够处理负载均衡时才
能工作得很好。

许多多用途负载均衡器只会针对HTTP 服务器做健康和负载检査。一个简单的负载
均衡器最少能够核实服务器在一个TCP 端口上接受的连接数。更好的负载均衡器能
够自动发起一个HTTP 请求，并检査返回值以确定这个Web 服务器是否正常运转。
MySQL 并不接受到3306 端口的HTTP 请求，因此需要自己来构建健康检查方法。
你可以在MySQL 服务器上安装一个HTTP 服务器软件，并将负载均衡器指向一个
脚本，这个脚本检査MySQL 服务器的状态并返回一个对应的状态值a 14。最重要的
是检査操作系统负载（通过査看/proc/loadavg)、复制状态，以及MySQL 的连接数。

<a id="markdown-84-p538-负载均衡算法" name="84-p538-负载均衡算法"></a>
# 84. p538-负载均衡算法
算法|说明
-|-
随机| 负载均衡器随机地从可用的服务器池中选择一个服务器来处理请求。
轮询|负载均衡器以循环顺序发送请求到服务器，例如：A，B, C，A, B, C。
最少连接数|下一个连接请求分配给拥有最少活跃连接的服务器。
最快响应|能够最快处理请求的服务器接受下一个连接。当服务器池里同时存在快速和慢速服务器时，这很有效。即使同样的査询在不同的场景下运行也会有不同的表现，例如当査询结果已经缓存在査询缓存中，或者服务器缓脊中已经包含了所需要的数据时。
哈希|负载均衡器通过连接的源IP 地址进行哈希， 将其映射到池中的同一个服务器上。每次从同一个IP 地址发起请求，负载均衡器都会将请求发送给同样的服务器。只有当池中服务器数目改变时这种绑定才会发生变
权重|负载均衡器能够结合使用上述几种算法。例如，你可能拥有单CPU 和双CPU 的机器。双CPU 机器有接近两倍的性能，所以可以让负载均衡器分派两倍的请求给双CPU机器。


<a id="markdown-85-p541-一天不能建成fb" name="85-p541-一天不能建成fb"></a>
# 85. p541-一天不能建成fb
正确地扩展MySQL 并没有看起来那么美好。**从第一天就建立下一个Facebook 架构，这
并不是正确的方式。**最好的策略是实现应用所明确需要的，并为可能的快速增长做好预
先规划，成功的规划是可以为任何必要的措施筹集资金以满足需求。

在MySQL 扩展策略方面，典型的应用在增长到非常庞大时，**通常先从单个服务器转移
到向外扩展的拥有读备库的架构，再到数据分片和/ 或者按功能分区。**我们并**不同意那
些提倡为每个应用“尽早分片，尽量分片”** （shard early, shard often) 的建议。这很复杂
且代价昂贵，并且许多应用可能根本不需要。可以花一些时间去看看新的硬件和新版本
的MySQL 有哪些变化，或者MySQL Cluster 有哪些新的进展，甚至去评估一些专门的
系统，**例如Clustrix。毕竟数据分片是一个手工搭建的集群系统，如果没有必要，最好
不要重复发明轮子。**


<a id="markdown-86-p564-云的优点和缺点" name="86-p564-云的优点和缺点"></a>
# 86. p564-云的优点和缺点

优点  

  * 云是一种将基础设施外包出去无须自己管理的方法。你不需要寻找供应商购买硬件，也不需要维护和供应商之间的关系，更无须替换失效的硬盘驱动器等。
  * 云一般是按照即用即付的方式支付，可以把前期的大量资本支出转换为持续的运营成本。
  * 随着供应商发布新的服务和成本降低，云提供的价值越来越大。你自己无须做任何事情（例如升级服务器），. 就可以从这些提升中获益；随着时间推移你会很容易地获得更多更好的选择并且费用更低。
  * 云能够帮助你轻松地准备好服务器和其他资源，在用完后直接将其关闭，而无须关注怎么处理它们，或者怎么卖掉它们收回成本。
  * 云代表了对基础设施的另一种思考方式——作为通过API 来定义和控制的资源一一支持更多的自动化操作。从“私有云”中也可以获得这些好处。


缺点  

  * 资源是共享并且不可预测的，实际上你可以获得比你支付的更多的资源。这听起很不错，但却导致容量规划很难做。如果你在不知情的情况下获得了比理应享受到的更多的计算资源，那么就存在这样的风险：别人也许会索要他们应得的资源，这会使你的应用性能退化到应有的水平。一般来说，很难确切地知道本来应该得到多少（资源）， 大多数云托管服务提供商不会对此给出确切的答案。
  * 无法保证容量和可用性。你可能以为还可以获得新实例，但如果供应商已经超额销售了呢？这在有很多共享资源的情况下会发生，同样也会发生在云中。
  * 虚拟的共享资源导致排査故障更加困难，特别是在无法访问底层物理硬件的情况下.如果在云平台上出现了性能问题，尤其需要去仔细地分析检测。如果对此并不擅长， 可能就无法确认到底是底层系统性能差，还是你做了什么事情导致应用出现不合理的资源需求。.

总的来说，云平台上对性能、可用性和容量的透明性和控制力都有所下降。最后，还有
一些对云的误解需要记住。

不能误解   

云天生具备更好的可扩展性  
应用、云的架构，以及管理云服务的组织是不是都是可扩展的。云并不是天生可扩
展的，云也仅仅是云而已， 选择一个可扩展的平台并不能自动使应用变得可扩展。
的确，如果云托管提供商没有超售，那么你可以根据需求来购买资源，但在需要时
能够获得资源仅仅是扩展性的一个方面而已。


云可以自动改善甚至保证可用时间  
一般来说，个别在云端托管的服务器比那些经过良好设计的专用基础设施更容易发
生故障或运行中断。但是许多人并没有意识到这一点。例如， 有人这样写道：“我们
将基础设施升级到基于云构建的系统以保证100% 的可用时间和可扩展性”。而就在
这之前AWS 遭受了两次大规模的运行中断故障，导致很大一部分用户受影响。好
的架构能够用不可靠的组件设计出可靠的系统，但通常更可靠的基础设施可以获得
更高的可用性。（当然不可能有100% 的可用时间的系统。）
**另一方面，购买云计算服务，实际上是购买一个由专家构建的平台。他们已经考虑
了许多底层的东西，这意味着你可以更专注于上层工作。****如果构建自己的平台而对
其中的那些细枝末节并不精通，就可能犯一些初学者的错误，早晚会导致一些宕机
时间。**从这一点来说，云计算能够帮助改善可用时间。


云是唯一能提供[ 这里填入任意的优点] 的东西  
事实上，许多云的优点是继承自构建云平台所用到的技术，即使不使用云也可以获得.
例如，通过管理得当的虚拟化和容量规划，可以像任何一个云平台那样简单快速地启动（spin up) —台新的机器。完全没必要专门使用云来做到这一点。


<a id="markdown-87-p582-应用层优化-缓存" name="87-p582-应用层优化-缓存"></a>
# 87. p582-应用层优化-缓存
缓存对髙负载应用来说是至关重要的。一个典型的Web 应用程序会提供大量的内容，直
接生成这些内容的成本比采用缓存要高得多（ 包含检査和缓存超时的开销）， 所以采用
缓存通常可以获得数量级的性能提升。**诀窍是找到正确的粒度和缓存过期策略组合。另
外也需要决定哪些内容适合缓存，缓存在哪里。**

典型的高负载应用会有很多层缓存。缓存并不仅仅发生在服务器上，而是在毎一个环节，
甚至包括用户的Web 浏览器（这就是内容过期头的用处）。**通常，缓存越接近客户端，
就越节省资源并且效率更髙**。从浏览器缓存提供一张图片比从Web 服务器的内存获取快
得多，而从服务器的内存读取又比从服务器的磁盘上读取好得多。毎种类型的缓存有其
不一样的特点，例如容量和延时.

<a id="markdown-88-p584-应用层缓存的策略" name="88-p584-应用层缓存的策略"></a>
# 88. p584-应用层缓存的策略

<a id="markdown-881-本地缓存" name="881-本地缓存"></a>
## 88.1. 本地缓存
这种缓存通常很小，只在进程处理请求期间存在于进程内存中。本地缓存可以有效
地避免对某些资源的重复请求。这种类型的缓存技术并不复杂：通常只是应用代码
中的一个变量或者哈希表.

<a id="markdown-882-本地共享内存缓存" name="882-本地共享内存缓存"></a>
## 88.2. 本地共享内存缓存
这种缓存一般是中等大小（几个GB), 快速，**难以在多台机器间同步。它们对小型
的半静态位数据比较合适。**例如**每个州的城市列表**，分片数据存储的分区函数（映
射表）， 或者使用存活时间（TTL) 策略进行失效的数据等。共享内存最大的好处是
访问非常快——通常比其他任何远程缓存访问都要快不少。

<a id="markdown-883-分布式内存缓存" name="883-分布式内存缓存"></a>
## 88.3. 分布式内存缓存
最常见的分布式内存缓存的例子是**memcached**。分布式缓存比本地共享内存缓存要
大得多，增长也容易。缓存中创建的数据的每一个比特都只有一份副本，这样既不
会浪费内存，也不会因为相同的数据存在不同的地方而引入一致性问题。分布式内
存非常适合存储共享对象，例如用户资料、评论，以及HTML 片段。

当缓存集群增加或减少一台服务器时，一致性缓存对避免性能问题而言是非常重要的。


<a id="markdown-89-p593-备份和恢复" name="89-p593-备份和恢复"></a>
# 89. p593-备份和恢复

**如果没有提前做好备份规划，也许以后会发现已经错失了一些最佳的选择。**例如，在服
务器已经配置好以后，才想起应该使用LVM, 以便可以获取文件系统的快照——但这时
已经太迟了。在为备份配置系统参数时，可能没有注意到某些系统配置对性能有着重要
影响。如果没有计划做定期的恢复演练，当真的需要恢复时， 就会发现并没有那么顺利。


<a id="markdown-891-为什么需要备份" name="891-为什么需要备份"></a>
## 89.1. 为什么需要备份

灾难恢复  
灾难恢复是下列场景下需要做的事情：硬件故障、一个不经意的Bug 导致数据损坏，
或者服务器及其数据由于某些原因不可获取或无法使用等。你需要准备好应付很多
问题：某人偶然连错服务器执行了一个ALTER TABLEttl 的操作，机房大楼被烧毁，
恶意的黑客攻击或MySQL 的Bug等。尽管遭受任何一个特殊的灾难的几率都非常低,
但所有的风险叠加在一起就很有可能会碰到

人们改变想法  
不必惊讶，很多人经常会在删除某些数据后又想要恢复这些数据。

审计  
有时候需要知道数据或Schema 在过去的某个时间点是什么样的。例如，你也许被
卷入一场法律官司，或发现了应用的一个Bug, 想知道这段代码之前千了什么（有
时候，仅仅依靠代码的版本控制还不够） 。

测试  
一个最简单的基于实际数据来测试的方法是，定期用最新的生产环境数据更新测试
服务器。如果使用备份的方案就非常简单:只要把备份文件还原到测试服务器上即可。

<a id="markdown-90-p596-设计mysql备份方案" name="90-p596-设计mysql备份方案"></a>
# 90. p596-设计MySQL备份方案

  * 在生产实践.中，对于大数据库来说，物理备份是必需的：逻辑备份太慢并受到资源限制，从逻辑备份中恢复需要很长时间。基于快照的备份，例如PerconaXtraBackup 和MySQL Enterprise Backup 是最好的选择。对于较小的数据库，逻辑备份可以很好地胜任。
  * 保留多个备份集。
  * 定期从逻辑备份（或者物理备份）中抽取数据进行恢复测试。
  * 保存二进制日志以用于基于故障时间点的恢复。expire_logs_days 参数应该设置得足够长，至少可以从最近两次物理备份中做基于时间点的恢复，这样就可以在保持主库运行且不应用任何二进制日志的情况下创建一个备库。备份二进制日志与过期设置无关，二进制日志备份需要保存足够长的时间，以便能从最近的逻辑备份进行恢复。
  * 完全不借助备份工具本身来监控备份和备份的过程。需要另外验证备份是否正常
  * 通过演练整个恢复过程来测试备份和恢复。测算恢复所需要的资源(CPU、磁盘空间实际时间，以及网络带宽等)。
  * 对安全性要仔细考虑。如果有人能接触生产服务器，他是否也能访问备份服务器？反过来呢？

<a id="markdown-91-p598-逻辑备份还是物理备份" name="91-p598-逻辑备份还是物理备份"></a>
# 91. p598-逻辑备份还是物理备份

<a id="markdown-911-逻辑备份" name="911-逻辑备份"></a>
## 91.1. 逻辑备份

优点  
  * 逻辑备份是可以用编辑器或像grep和sed之类的命令査看和操作的普通文件。当需要恢复数据或只想査看数据但不恢复时，这都非常有帮助。
  * 恢复非常简单。可以通过管道把它们输入到mysql,或者使用mysqllimport
  * 可以通过网络来备份和恢复——就是说，可以在与MySQL 主机不同的另外一台机器上操作。
  * 可以在类似Amazon RDS 这样不能访问底层文件系统的系统中使用。
  * 非常灵活，因为 mysqldump——大部分人喜欢的工具——可以接受许多选项，例如可以用WHERE子句来限制需要备份哪些行。
  * 与存储引擎无关。因为是从MySQL 服务器中提取数据而生成，所以消除了底层数据存储和不同.因此，可以从InnoDB 表中备份，然后只需极小的工作量就可以还原到MylSAM 表中。而对于原始数据却不能这么做。
  * 有助于避免数据损坏。如果磁盘驱动器有故障而要复制原始文件时，你将会得到一个错误并且/ 或生成一个部分或损坏的备份。如果MySQL 在内存中的数据还没有损坏，当不能得到一个正常的原始文件复制时, 有时可以得到一个可以信赖的逻辑备份。

缺点  
  * 必须由数据库服务器完成生成逻辑备份的工作，因此要使用更多的CPU 周期。
  * 逻辑备份在某些场景下比数据库文件本身更大ASCII 形式的数据不总是和存储引擎存储数据一样髙效。例如， 一个整型需要4 字节来存储，但是用ASCII 写入时，可能需要12 个字符。当然也可以压缩文件以得到一个更小的备份文件，但这样会使用更多的CPU 资源。（如果索引比较多，逻辑备份一般要比物理备份小。
  * 无法保证导出后再还原出来的一定是同样的数据。浮点表示的问题、软件Bug 等都会导致问题，尽管非常少见。
  * 从逻辑备份中还原需要MySQL 加载和解释语句，转化为存储格式，并重建索引，所有这一切会很慢。



<a id="markdown-912-物理备份" name="912-物理备份"></a>
## 91.2. 物理备份

优点  

  * 基于文件的物理备份，只需要将需要的文件复制到其他地方即可完成备份。不需要其他额外的工作来生成原始文件。
  * 物理备份的恢复可能就更简单了，这取决于存储引擎。对于MylSAM, 只需要简单地复制文件到目的地即可。对于InrioDB 则需要停止数据库服务，可能还要采取其他一些步骤
  * InnoDB 和MylSAM 的物理备份非常容易跨平台、操作系统和MySQL 版本。（逻辑导出亦如此。这里特别指出这一点是为了消除大家的担心。
  * 从物理备份中恢复会更快，因为MySQL 服务器不需要执行任何SQL 或构建索引。如果有很大的InnoDB表，无法完全缓存到内存中，则物理备份的恢复要快非常多一一**至少要快一个数量级**。事实上，逻辑备份最可怕的地方就是不确定的还原时间。



缺点  
  * InnoDB 的原始文件通常比相应的逻辑备份要大得多。InnoDB 的表空间往往包含很多未使用的空间。还有很多空间被用来做存储数据以外的用途(插入缓冲，回滚段等）。
  * 物理备份不总是可以跨平台、操作系统及MySQL 版本。文件名大小写敏感和浮点格式是可能会遇到麻烦。很可能因浮点格式不同而不能移动文件到另一个系统（虽然主流处理器都使用IEEE 浮点格式。）

值得一提的是物理备份会更易出错；很难像mysqldump一样简单。

<a id="markdown-92-p601-备份什么" name="92-p601-备份什么"></a>
# 92. p601-备份什么

非显著数据  
不要忘记那些容易被忽略的数据：例如，二进制日志和InnoDp 事务日志。

代码  
现代的MySQL 服务器可以存储许多代码，例如触发器和存储过程。如果备份了
mysql 数据库，那么大部分这类代码也备份了，但如果需要还原单个业务数据库会
比较麻烦，因为这个数据库中的部分“数据”，例如存储过程，实际是存放在mysql
数据库中的。

复制配置  
如果恢复一个涉及复制关系的服务器，应该备份所有与复制相关的文件，例如二
进制日志、中继日志、日志索引文件和.info文件。

服务器配置  
假设要从一个实际的灾难中恢复,比如说，地震过后在一个新数据中心中构建服务器，
如果备份中包含服务器配置，你一定会喜出望外。

选定的操作系统文件  
对于服务器配置来说，备份中对生产服务器至关重要的任何外部配置， 都十分重要。
在UNIX 服务器上，这可能包括cron任务、用户和组的配置、管理脚本，以及sudo
规则。


<a id="markdown-93-p633-备份和恢复工具" name="93-p633-备份和恢复工具"></a>
# 93. p633-备份和恢复工具
  * MySQL Enterprise Backup
  * Percona XtraBackUp
  * mvlvmbackup
  * Zmanda Recovery Manager
  * mydumper
  * mysqldump

<a id="markdown-94-p634-备份经验" name="94-p634-备份经验"></a>
# 94. p634-备份经验

毫不夸张地说，一个在几个小时内完成的备份可能需要几周时间来恢复，具体取决于硬件、Schema、索引和数据。


我们最喜欢的两种备份方式， 一种是从文件系统或者SAN 快照中直接复制数据文件， 一种是使用Percona XtraBackUp做热备份.
这样的备份可以通过启动实例检査所有的表进行验证。有时候甚至可以一石二鸟：**可以在开发或者预发环境每天将备份进行还原来执行恢复测试**，然后再将数据导出为逻辑备份。

除了提到的许多开源工具，也有很多很好的商业备份工具，其中最重要的是MySQL Enterprise Backup.


<a id="markdown-95-p635-mysql用户工具" name="95-p635-mysql用户工具"></a>
# 95. p635-MySQL用户工具

<a id="markdown-951-接口工具" name="951-接口工具"></a>
## 95.1. 接口工具

工具|说明
-|-
 MySQL Workbench  | 是一个一站式的工具，可以完成例如管理服务器、写査询、开 发存储过程，以及Schema 设计图相关的工作。可以通过一个插件接口来编写自 己的工具并集成到这个工作平台上，有一些Python 脚本和库就使用了这个插件接 口。MySQL Workbench 有社区版和商业版两个版本，商业版只是增加了其他的一些 髙级特性。免费版对于大部分需要早已足够了
 SQLyog           | 最流行的可视化工具之一，有许多很好的特性。它与MySQL Workbench 是同级别的工具，但两个工具都有一些对方没有的特性。SQLyog 只能在 微软的Windows 下使用，拥有全部特性的版本需要付费，但有限制功能的免费版本。                                                       
 phpMyAdmin       | 是一个流行的管理工具，运行在Web 服务器上，并且提供基于浏览器 的MySQL 服务器访问接口。尽管基于浏览器的访问有时很好，但phpMyAdmin 是 个大而复杂的工具，曾被指责有许多安全问题。对此要格外小心。我们建议不要安 装在任何可以从互联网访问的地方。                               
 Adminer          | 是个基于浏览器的安全的轻量级管理工具，它与phpMyAdmin 同类。其开 发者将其定位为phpMyAdmin 的更好的替代品。尽管它看起来更安全，但我们仍建 议安装在任何可公开访问的地方时要谨慎。


<a id="markdown-952-命令行工具" name="952-命令行工具"></a>
## 95.2. 命令行工具
工具|说明
-|-
 Percona Toolkit      | Percona Toolkit 是MySQL 管理员必备的工具包。它源自Baron 早期的工具包 Maatkit 和Aspersa，很多人认为这两个工具应该是正式的MySQL 部署必须强制要 求使用的。Percona Toolkit 包括许多针对类似日志分析、复制完整性检测、数据同步、 模式和索引分析、査询建议和数据归档目的的工具。如果刚开始接触MySQL，我 们建议首先学习这些关键的工具：pt-mysql-summary,pt-table-checksum,pt-table-sync,pt-query-digest  
 Maatkit and Aspersa  | 这两个工具约从2006 年以某种形式出现，两者都被认为是MySQL 用户的基本工具。 它们现在已经并入Percona Toolkit
 The openark kit      | 包含了可 以用来做一系列管理任务的Python 脚本。
MySQL Workbench 工具集  | MySQL Workbench 工具集中的某些工具可以作为单独的Python 脚本使用
 社区                   | http://forge.mysql.com http://plant.mysql.com 

<a id="markdown-953-sql实用集" name="953-sql实用集"></a>
## 95.3. SQL实用集
工具|说明
-|-
 commo_schema  | 是一套针对服务器脚本化和管理的强大的代码和视图               
 mysql-sr-lib  | 一个存储过程的代码                             
 MySQL UDF 仓库  | MySQL 自定义函数的收藏馆                       
 MySQL Forge   | 可以找到上百个社区贡献的程序、脚本、 代码片断、实用集和技巧及陷阱。  

<a id="markdown-954-开源的监控工具" name="954-开源的监控工具"></a>
## 95.4. 开源的监控工具

工具|说明
-|-
 Nagios                  | 开源世界中最流行的问题检测和告警系统。                                                                                                                     |
 Zabbix                  | 它将所有配置和其他数据存储到数据库而不是配置文件中。它存储了比Nagios 更多的数据类型，因而可以 得到更好的趋势和历史报表。其网络画图和可视能力也比Nagios 更强，配置更简单，更灵活，且更具可扩展性                       
 Zenoss                  | Zenoss 是用Python 写的，拥有一个基于浏览器的用户界面， 使用了Ajax, 这使它 更快和更高效。它可以自动发现网络上的资源，并将监控、告警、趋势、绘图和记录历史数据整合到了一个统一的工具中
 Hyperic HQ              | Hyperic HQ 是一个基于Java 的监控系统，比起同级别的其他大部分系统，它更称得 上是企业级监控。像Zenoss —样，它可以自动发现网络上的资源和支持Nagios 插件， 但它的逻辑组织和架构不同，有点“笨重”。
 OpenNMS                 | OpenNMS 也是用Java 开发，有一个活跃的开发社区。它拥有常规的特性，例如监 控和告警，但同样也增加了绘图和趋势功能。它的目标是高性能、可扩展、自动化 和灵活。像Hyperic —样，它也致力于为大型和关键系统做企业级监控。              
 Groundwork Open Source  | Groundwork Open Source 用一个可移植的接口把Nagios 和其他几个工具整合到了一 个系统中。对于这个工具最好的描述是：如果你是Nagios、Cacti 和其他几个工具方 面的专家，并且花了许多时间将它们整合一起，那很可能你是在闭门造车。  
 MRTG                    | 是典型的基于RRDTool 的系统。最初是为记录网络流量而设计的， 但同样可以扩展到用于对其 他指标进行记录和绘图。
 Cacti                   | 可能是最流行的基于RRDTool 的系统。它米用PHP 网 页来与RRDTool 进行交互，并使用MySQL 数据库来定义服务器、插件、图像等。 因为是模板驱动，故而可以定义模板然后应用到系统上
 Ganglia                 | 但是为监控集群和网格系统 而设计，所以可以汇总査看许多服务器的数据，如果需要也可以细分査看单台服务 器的详细数据。
 Munin                   | 收集数据并存入RRDTool 中，然后以几个 不同级别的粒度生成数据图。它从配置中生成静态HTML 文件，因此可以很容易地 浏览和査看趋势。定义一个图形较容易；只需要创建一个插件脚本，其命令行帮助 输出有一些Munin 可以识别的特别语法的画图指令。     


<a id="markdown-955-商业的监控工具" name="955-商业的监控工具"></a>
## 95.5. 商业的监控工具
工具|说明
-|-
 MySQL Enterp rise Monitor  | MySQL Enterprise Monitor 包含在Oracle 的MySQL 支持服务中。它将监控、指标 和画图、咨询服务和査询分析等特性整合到了一个工具中。
 MONyog                     | 一个运行在桌面上的基于浏览器且无agent 的 监控系统。它会启动一个HTTP 服务器，然后就可以通过浏览器来使用此工具。                                        
 New Relic                  | 甚一个托管式的软件即服务（Saas) 的应用性能管 理系统，它可以分析整个应用的性能，从应用代码（采用Ruby, PHP, Java 和其他 语言）到运行在浏览器上的JavaScript到数据库的SQL 调用，甚至是服务器的磁 盘空间， CPU 利用率和其它指标。
 Circonus                   | 是一个源于OmniTI 的托管式的软件即服务（SaaS) 的指标和告警系统。通过agent 从一个或多个服务器上收集指标并转发到Circonus, 然后就可以通过一个基于浏览器的仪表盘来査看。           
 Monitis                    | 是另外一个云托管式的软件即服务（SaaS) 的监控系 统。它被设计成监控“一切”， 这意味着它有点普遍性
 Splunk                     | 是一个日志聚集器和搜索引擎，可以帮助获得环境 中所有机器生成的数据并进行运营分析。                                                                                
 Pingdom                    | 从世界的多个位置来监控网站的可用性和性能。 实际上有许多像Pingdom —样的服务，我们并不需要特别推荐某一个这样的服务， 但是我们确实建议使用一些外部的监控服务，以便让你在网站不可用时能够及时得 到通知。很多类似的服务远不止Ping 或获取网页
 